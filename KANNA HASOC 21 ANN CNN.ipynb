{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SkzwLeYdvUgm"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Malayalam\n",
    "Mal_train=pd.read_csv(\"kannada_sentiment_full_train.tsv\", sep='\\t')\n",
    "\n",
    "\n",
    "Mal_Dev=pd.read_csv(\"kannada_sentiment_full_dev.tsv\", sep='\\t')\n",
    "\n",
    "\n",
    "Mal_test=pd.read_csv(\"kannada_sentiment_full_test_withoutlabels.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡≤í‡≤Ç‡≤¶‡≥Å ‡≤¶‡≥á‡≤∂‡≤¶ ‡≤Æ‡≥Å‡≤Ç‡≤¶‡≥Å‡≤µ‡≤∞‡≤ø‡≤Ø‡≥Å‡≤µ‡≥Å‡≤¶‡≥Å ‡≤Ö‡≤¶‡≤∞ ‡≤Ü‡≤∞‡≥ç‡≤•‡≤ø‡≤ï ‡≤∏‡≥ç‡≤•‡≤ø‡≤§‡≤ø‡≤Ø‡≤®‡≥ç‡≤®...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡≤ï‡≤®‡≥ç‡≤®‡≤°‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤°‡≥à‡≤≤‡≤ø ‡≤ü‡≥Ü‡≤ï‡≥ç ‡≤Ö‡≤™‡≥ç‡≤°‡≥á‡≤ü‡≥ç‡≤∏‡≥ç ‡≤™‡≤°‡≥Ü‡≤Ø‡≤≤‡≥Å ‡≤∏‡≤¨‡≥ç‡≤∏‡≥ç‡≤ï‡≥ç‡≤∞...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Super sar song</td>\n",
       "      <td>not-Kannada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tiktokers present situation... n‡≤®‡≥ã‡≤°‡≥Å‡≤µ‡≤µ‡≤∞‡≥Å ‡≤Ø‡≤æ‡≤∞‡≥Å ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super ‡≤∏‡≤æ‡≤Ç‡≤ó‡≥ç ‡≤µ‡≥Ü‡≤∞‡≤ø ‡≤®‡≥à‡≤∏‡≥ç....</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6207</th>\n",
       "      <td>@A.R.W   tumbad tanhaji andhadhun aise bahot h...</td>\n",
       "      <td>not-Kannada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6208</th>\n",
       "      <td>‡¥™‡µä‡¥≥‡¥ø ‡¥°‡¥æ‡µª‡¥∏‡µçü•∞ ‡¥∞‡¥ï‡µç‡¥∑‡¥ø‡¥§‡µç ‡¥∑‡µÜ‡¥ü‡µç‡¥ü‡¥ø ‡¥Æ‡¥æ‡¥∏‡µç‡¥∏‡µç</td>\n",
       "      <td>not-Kannada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6209</th>\n",
       "      <td>Bro...nNeen este Roast madudru...China ne beku...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6210</th>\n",
       "      <td>‡≤ï‡≥å‡≤∂‡≤≤‡≥ç‡≤Ø ‡≤á‡≤¶‡≥ç‡≤¶‡≤µ‡≤∞ ‡≤∏‡≤Ç‡≤ñ‡≥ç‡≤Ø‡≥Ü ‡≤ï‡≤°‡≤ø‡≤Æ‡≥Ü ‡≤á‡≤≤‡≥ç‡≤≤ ‡≤∏‡≤∞‡≥ç ‡≤§‡≥Å‡≤Ç‡≤¨‡≤æ ‡≤™‡≥ç‡≤∞‡≤§...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6211</th>\n",
       "      <td>26 M Views</td>\n",
       "      <td>Mixed feelings</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6212 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text        category\n",
       "0     ‡≤í‡≤Ç‡≤¶‡≥Å ‡≤¶‡≥á‡≤∂‡≤¶ ‡≤Æ‡≥Å‡≤Ç‡≤¶‡≥Å‡≤µ‡≤∞‡≤ø‡≤Ø‡≥Å‡≤µ‡≥Å‡≤¶‡≥Å ‡≤Ö‡≤¶‡≤∞ ‡≤Ü‡≤∞‡≥ç‡≤•‡≤ø‡≤ï ‡≤∏‡≥ç‡≤•‡≤ø‡≤§‡≤ø‡≤Ø‡≤®‡≥ç‡≤®...        Negative\n",
       "1     ‡≤ï‡≤®‡≥ç‡≤®‡≤°‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤°‡≥à‡≤≤‡≤ø ‡≤ü‡≥Ü‡≤ï‡≥ç ‡≤Ö‡≤™‡≥ç‡≤°‡≥á‡≤ü‡≥ç‡≤∏‡≥ç ‡≤™‡≤°‡≥Ü‡≤Ø‡≤≤‡≥Å ‡≤∏‡≤¨‡≥ç‡≤∏‡≥ç‡≤ï‡≥ç‡≤∞...        Positive\n",
       "2                                        Super sar song     not-Kannada\n",
       "3     Tiktokers present situation... n‡≤®‡≥ã‡≤°‡≥Å‡≤µ‡≤µ‡≤∞‡≥Å ‡≤Ø‡≤æ‡≤∞‡≥Å ...        Negative\n",
       "4                             Super ‡≤∏‡≤æ‡≤Ç‡≤ó‡≥ç ‡≤µ‡≥Ü‡≤∞‡≤ø ‡≤®‡≥à‡≤∏‡≥ç....        Positive\n",
       "...                                                 ...             ...\n",
       "6207  @A.R.W   tumbad tanhaji andhadhun aise bahot h...     not-Kannada\n",
       "6208                  ‡¥™‡µä‡¥≥‡¥ø ‡¥°‡¥æ‡µª‡¥∏‡µçü•∞ ‡¥∞‡¥ï‡µç‡¥∑‡¥ø‡¥§‡µç ‡¥∑‡µÜ‡¥ü‡µç‡¥ü‡¥ø ‡¥Æ‡¥æ‡¥∏‡µç‡¥∏‡µç     not-Kannada\n",
       "6209  Bro...nNeen este Roast madudru...China ne beku...        Negative\n",
       "6210  ‡≤ï‡≥å‡≤∂‡≤≤‡≥ç‡≤Ø ‡≤á‡≤¶‡≥ç‡≤¶‡≤µ‡≤∞ ‡≤∏‡≤Ç‡≤ñ‡≥ç‡≤Ø‡≥Ü ‡≤ï‡≤°‡≤ø‡≤Æ‡≥Ü ‡≤á‡≤≤‡≥ç‡≤≤ ‡≤∏‡≤∞‡≥ç ‡≤§‡≥Å‡≤Ç‡≤¨‡≤æ ‡≤™‡≥ç‡≤∞‡≤§...        Positive\n",
       "6211                                         26 M Views  Mixed feelings\n",
       "\n",
       "[6212 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mal_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                text     category\n",
       " 0  ‡≤í‡≤Ç‡≤¶‡≥Å ‡≤¶‡≥á‡≤∂‡≤¶ ‡≤Æ‡≥Å‡≤Ç‡≤¶‡≥Å‡≤µ‡≤∞‡≤ø‡≤Ø‡≥Å‡≤µ‡≥Å‡≤¶‡≥Å ‡≤Ö‡≤¶‡≤∞ ‡≤Ü‡≤∞‡≥ç‡≤•‡≤ø‡≤ï ‡≤∏‡≥ç‡≤•‡≤ø‡≤§‡≤ø‡≤Ø‡≤®‡≥ç‡≤®...     Negative\n",
       " 1  ‡≤ï‡≤®‡≥ç‡≤®‡≤°‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤°‡≥à‡≤≤‡≤ø ‡≤ü‡≥Ü‡≤ï‡≥ç ‡≤Ö‡≤™‡≥ç‡≤°‡≥á‡≤ü‡≥ç‡≤∏‡≥ç ‡≤™‡≤°‡≥Ü‡≤Ø‡≤≤‡≥Å ‡≤∏‡≤¨‡≥ç‡≤∏‡≥ç‡≤ï‡≥ç‡≤∞...     Positive\n",
       " 2                                     Super sar song  not-Kannada\n",
       " 3  Tiktokers present situation... n‡≤®‡≥ã‡≤°‡≥Å‡≤µ‡≤µ‡≤∞‡≥Å ‡≤Ø‡≤æ‡≤∞‡≥Å ...     Negative\n",
       " 4                          Super ‡≤∏‡≤æ‡≤Ç‡≤ó‡≥ç ‡≤µ‡≥Ü‡≤∞‡≤ø ‡≤®‡≥à‡≤∏‡≥ç....     Positive,\n",
       "                                                 text        category\n",
       " 0  Binduge saryagi ugithidira good go ahead  we a...  Mixed feelings\n",
       " 1                             yen song guru ...super        Positive\n",
       " 2                                   my fevorat story     not-Kannada\n",
       " 3                                  Super ‡≤§‡≥ã‡≤ó‡≤∞‡≤ø ‡≤§‡≥Ä‡≤™‡≥ç‡≤™        Positive\n",
       " 4  ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤Æ‡≤æ‡≤§‡≥Å‡≤ó‡≤≥‡≥Å ‡≤Ö‡≤ï‡≥ç‡≤∑‡≤∞‡≤∂‡≤É ‡≤∏‡≤§‡≥ç‡≤Ø... ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤à ‡≤∏‡≤æ‡≤Æ‡≤æ‡≤®‡≥ç‡≤Ø ...        Positive)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mal_train[0:5], Mal_Dev[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ml2en import ml2en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converter = ml2en()\n",
    "\n",
    "#desti_lang={\n",
    "#     'malayalam' : 'ml'\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for key,value in desti_lang.items():\n",
    "     #print(transt.translate(Mal_train['text']))\n",
    "     #   Mal_train['text1']=Mal_train['text'].apply(lambda x: converter.transliterate(x))\n",
    "     #   Mal_Dev['text1']=Mal_Dev['text'].apply(lambda x: converter.transliterate(x))\n",
    "     #   Mal_test['text1']=Mal_test['text'].apply(lambda x: converter.transliterate(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>SupernTelugu lo kuda</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Rakshit shetty sir ge jai</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>different but unique &amp; epic song</td>\n",
       "      <td>not-Kannada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Even I had Same feelings..!</td>\n",
       "      <td>not-Kannada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>First time movie nodoru taleli uoohe screenply...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Super................ Song</td>\n",
       "      <td>not-Kannada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Good job..  Goahead mahn</td>\n",
       "      <td>not-Kannada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>En song guruve I love this song K G F bitre ed...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Nimage aa devaru olledu madali Appaji...nNimma...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text     category\n",
       "61                               SupernTelugu lo kuda     Positive\n",
       "62                          Rakshit shetty sir ge jai     Positive\n",
       "63                   different but unique & epic song  not-Kannada\n",
       "64                        Even I had Same feelings..!  not-Kannada\n",
       "65  First time movie nodoru taleli uoohe screenply...     Positive\n",
       "66                         Super................ Song  not-Kannada\n",
       "67                           Good job..  Goahead mahn  not-Kannada\n",
       "68  En song guruve I love this song K G F bitre ed...     Positive\n",
       "69  Nimage aa devaru olledu madali Appaji...nNimma...     Positive"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mal_train[61:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Binduge saryagi ugithidira good go ahead  we a...</td>\n",
       "      <td>Mixed feelings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yen song guru ...super</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my fevorat story</td>\n",
       "      <td>not-Kannada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super ‡≤§‡≥ã‡≤ó‡≤∞‡≤ø ‡≤§‡≥Ä‡≤™‡≥ç‡≤™</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤Æ‡≤æ‡≤§‡≥Å‡≤ó‡≤≥‡≥Å ‡≤Ö‡≤ï‡≥ç‡≤∑‡≤∞‡≤∂‡≤É ‡≤∏‡≤§‡≥ç‡≤Ø... ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤à ‡≤∏‡≤æ‡≤Æ‡≤æ‡≤®‡≥ç‡≤Ø ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        category\n",
       "0  Binduge saryagi ugithidira good go ahead  we a...  Mixed feelings\n",
       "1                             yen song guru ...super        Positive\n",
       "2                                   my fevorat story     not-Kannada\n",
       "3                                  Super ‡≤§‡≥ã‡≤ó‡≤∞‡≤ø ‡≤§‡≥Ä‡≤™‡≥ç‡≤™        Positive\n",
       "4  ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤Æ‡≤æ‡≤§‡≥Å‡≤ó‡≤≥‡≥Å ‡≤Ö‡≤ï‡≥ç‡≤∑‡≤∞‡≤∂‡≤É ‡≤∏‡≤§‡≥ç‡≤Ø... ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤à ‡≤∏‡≤æ‡≤Æ‡≤æ‡≤®‡≥ç‡≤Ø ...        Positive"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mal_Dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kan_1</td>\n",
       "      <td>‡≤à ‡≤π‡≤æ‡≤°‡≤®‡≥ç‡≤®‡≥Å ‡≤π‡≤æ‡≤°‡≤ø‡≤¶ ‡≤µ‡≤ø‡≤ú‡≤Ø ‡≤™‡≥ç‡≤∞‡≤ï‡≤æ‡≤∂ voice ‡≤Ø‡≤æ‡≤∞‡≤ø‡≤ó‡≥Ü‡≤≤‡≥ç‡≤≤‡≤æ ‡≤á...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kan_2</td>\n",
       "      <td>Jai D Boss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kan_3</td>\n",
       "      <td>Signature move</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kan_4</td>\n",
       "      <td>Super song bro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kan_5</td>\n",
       "      <td>Wow  Super agi helidira sir</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text\n",
       "0  Kan_1  ‡≤à ‡≤π‡≤æ‡≤°‡≤®‡≥ç‡≤®‡≥Å ‡≤π‡≤æ‡≤°‡≤ø‡≤¶ ‡≤µ‡≤ø‡≤ú‡≤Ø ‡≤™‡≥ç‡≤∞‡≤ï‡≤æ‡≤∂ voice ‡≤Ø‡≤æ‡≤∞‡≤ø‡≤ó‡≥Ü‡≤≤‡≥ç‡≤≤‡≤æ ‡≤á...\n",
       "1  Kan_2                                         Jai D Boss\n",
       "2  Kan_3                                     Signature move\n",
       "3  Kan_4                                     Super song bro\n",
       "4  Kan_5                        Wow  Super agi helidira sir"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mal_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2146,
     "status": "ok",
     "timestamp": 1609999165830,
     "user": {
      "displayName": "Prasad Joshi",
      "photoUrl": "",
      "userId": "09800632122724335955"
     },
     "user_tz": -330
    },
    "id": "cQqJeR_syJYi",
    "outputId": "058d8c57-49fb-4442-ef55-868a3ea3609f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive          2823\n",
       "Negative          1188\n",
       "not-Kannada        916\n",
       "unknown state      711\n",
       "Mixed feelings     574\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "Mal_train['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2352,
     "status": "ok",
     "timestamp": 1609999166818,
     "user": {
      "displayName": "Prasad Joshi",
      "photoUrl": "",
      "userId": "09800632122724335955"
     },
     "user_tz": -330
    },
    "id": "bchq8x31680D",
    "outputId": "097f0311-3aca-4220-a26f-07bfc9697ef2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive          321\n",
       "Negative          139\n",
       "not-Kannada       110\n",
       "unknown state      69\n",
       "Mixed feelings     52\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Development \n",
    "Mal_Dev['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ZtfvQ60W5mKf"
   },
   "outputs": [],
   "source": [
    "msg=Mal_train['text']\n",
    "\n",
    "msgDev=Mal_Dev['text']\n",
    "\n",
    "msgTest=Mal_test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50    Guru ninge like beku andre kelu Kodthare adu b...\n",
       "51                      super comedy drama togari tippa\n",
       "52                                    @Deekshit Chandra\n",
       "53    Enadru public help ago Vishayada bagge Mathadi...\n",
       "54                        Nammantavrge spoorti nivu sir\n",
       "55             Estu kelidru matte matte kelbeku ansutte\n",
       "56                           Pakka 100 days movie  edu.\n",
       "57                              Nice story togari tippa\n",
       "58         ‡≤∂‡≤Ç‡≤ï‡≤∞‡≥ç ‡≤Ö‡≤∂‡≥ç‡≤µ‡≤•‡≥ç ‡≤∞‡≥ä‡≤Ç‡≤¶‡≤ø‡≤ó‡≥Ü ‡≤Ö‡≤§‡≥ç‡≤Ø‡≤Ç‡≤§ ‡≤∏‡≥Å‡≤Ç‡≤¶‡≤∞‡≤µ‡≤æ‡≤¶ ‡≤∏‡≤Ç‡≤¶‡≤∞‡≥ç‡≤∂‡≤®\n",
       "59                                    Plz make in Hindi\n",
       "60                                      Sooperb concept\n",
       "61             Navu kuri Alla guru kaliyugada kaligallu\n",
       "62                      Ye movie hindi mein hogi k nahi\n",
       "63         Please innodh video maadi bro ticktock bagge\n",
       "64       Nodarappa yaro heludrala ban yak madbeku antha\n",
       "65                           super.nTogari Tippa Comody\n",
       "66                ‡≤è... ‡≤≠‡≥à ‡≤è‡≤®‡≥ã‡≤™ ‡≤®‡≥Ä ‡≤π‡≤ø‡≤Ç‡≤ó ‡≤Æ‡≥à ‡≤§‡≥ä‡≤≥‡≥Ü‡≤¶‡≥Å ‡≤¨‡≤ø‡≤ü‡≥ç‡≤ü‡≤ø\n",
       "67    Kolthogiro kobri mitai mukadavle na..?nYappa d...\n",
       "68                Nav itara iroke karana Congress party\n",
       "69    ‡≤é‡≤≤‡≥ç‡≤≤‡≤æ ‡≤á‡≤∞‡≥ã‡≤®‡≥Å ‡≤í‡≤Ç‡≤¶‡≥á  ‡≤ú‡≥à ‡≤ï‡≤∞‡≥ç‡≤®‡≤æ‡≤ü‡≤ï ‡≤Æ‡≤æ‡≤§‡≥Ü ‡≤ú‡≥à ‡≤≠‡≥Å‡≤µ‡≤®‡≥á‡≤∂‡≥ç‡≤µ‡≤∞...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgDev[50:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "lm3rhwEOyBP3"
   },
   "outputs": [],
   "source": [
    "#Remove Emojis\n",
    "\n",
    "def emoji(msg): \n",
    "    \n",
    "    msg_emoj=msg.str.replace(r'[(\\U0001F600-\\U0001F92F|\\U0001F300-\\U0001F5FF|\\U0001F680-\\U0001F6FF|\\U0001F190-\\U0001F1FF|\\U00002702-\\U000027B0|\\U0001F926-\\U0001FA9F|\\u200d|\\u2640-\\u2642|\\u2600-\\u2B55|\\u23cf|\\u23e9|\\u231a|\\ufe0f)]+','')\n",
    "    \n",
    "    msg_digit=msg_emoj.str.replace(r'[0-9]', ' ')\n",
    "\n",
    "    msg_Spac = msg_digit.str.replace(r'_',' ')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'.','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'!','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'#','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'%','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'&','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'‚Äô','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'(','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r')','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'-','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'/','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r':','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r';','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'<','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'=','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'>','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'?','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'@','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'[','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r']','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'^','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'{','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'}','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'|','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'~','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'+','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'\\s+', ' ')\n",
    "\n",
    "\n",
    "    return msg_Spac\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "3ApjI62l9vRw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \"\"\"\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  import sys\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:47: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:51: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:53: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:55: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:61: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    }
   ],
   "source": [
    "msg_Train=emoji(msg)\n",
    "\n",
    "msg_Dev=emoji(msgDev)\n",
    "\n",
    "msg_Test=emoji(msgTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24322,
     "status": "ok",
     "timestamp": 1609999200406,
     "user": {
      "displayName": "Prasad Joshi",
      "photoUrl": "",
      "userId": "09800632122724335955"
     },
     "user_tz": -330
    },
    "id": "sGXx0i5S_11T",
    "outputId": "58bdc1d4-f8b5-440a-d52f-5dcc777b2b56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78                                           Hi Chi ugh\n",
       " 79                nivu helidu sari nanu follow madthini\n",
       " 80    Sir paisacom adara bagge video madi Open madod...\n",
       " 81    Entha song na dislike madtiralla loafer nan ma...\n",
       " 82                           Pubg kooda ban agbeku guru\n",
       " 83                                  Manju Sonu ‡≤Ö‡≤≠‡≤ø‡≤®‡≤Ç‡≤¶‡≤®‡≥Ü\n",
       " 84                             That making was osm ASN \n",
       " 85                   ‡≤à ‡≤π‡≤æ‡≤°‡≥Å ‡≤∞‡≤∂‡≥ç‡≤Æ‡≤ø‡≤ï ‡≤Æ‡≤Ç‡≤ó‡≤£‡≥ç‡≤£‡≤®‡≤µ‡≤∞‡≤ø‡≤ó‡≥Ü ‡≤Ö‡≤∞‡≥ç‡≤™‡≤£‡≥Ü \n",
       " 86                             Super guru awesome video\n",
       " 87    Nandi Parthasarathi ‡≤ì‡≤π‡≥ã ‡≤®‡≤Ç‡≤¶‡≤ø‡≤®‡≤ø ‡≤®‡≤ø‡≤Ç‡≤¶‡≥Å ‡≤Æ‡≤ø‡≤≤‡≥ç‡≤ï‡≥ç ‡≤™‡≤æ...\n",
       " 88           prithvi nayak Roberrt bangada goth aagutte\n",
       " 89                                One like for hands up\n",
       " Name: text, dtype: object,\n",
       " 50    Guru ninge like beku andre kelu Kodthare adu b...\n",
       " 51                      super comedy drama togari tippa\n",
       " 52                                     Deekshit Chandra\n",
       " 53    Enadru public help ago Vishayada bagge Mathadi...\n",
       " 54                        Nammantavrge spoorti nivu sir\n",
       " 55             Estu kelidru matte matte kelbeku ansutte\n",
       " 56                                 Pakka days movie edu\n",
       " 57                              Nice story togari tippa\n",
       " 58         ‡≤∂‡≤Ç‡≤ï‡≤∞‡≥ç ‡≤Ö‡≤∂‡≥ç‡≤µ‡≤•‡≥ç ‡≤∞‡≥ä‡≤Ç‡≤¶‡≤ø‡≤ó‡≥Ü ‡≤Ö‡≤§‡≥ç‡≤Ø‡≤Ç‡≤§ ‡≤∏‡≥Å‡≤Ç‡≤¶‡≤∞‡≤µ‡≤æ‡≤¶ ‡≤∏‡≤Ç‡≤¶‡≤∞‡≥ç‡≤∂‡≤®\n",
       " 59                                    Plz make in Hindi\n",
       " 60                                      Sooperb concept\n",
       " 61             Navu kuri Alla guru kaliyugada kaligallu\n",
       " 62                      Ye movie hindi mein hogi k nahi\n",
       " 63         Please innodh video maadi bro ticktock bagge\n",
       " 64       Nodarappa yaro heludrala ban yak madbeku antha\n",
       " 65                            supernTogari Tippa Comody\n",
       " 66                   ‡≤è ‡≤≠‡≥à ‡≤è‡≤®‡≥ã‡≤™ ‡≤®‡≥Ä ‡≤π‡≤ø‡≤Ç‡≤ó ‡≤Æ‡≥à ‡≤§‡≥ä‡≤≥‡≥Ü‡≤¶‡≥Å ‡≤¨‡≤ø‡≤ü‡≥ç‡≤ü‡≤ø\n",
       " 67    Kolthogiro kobri mitai mukadavle nanYappa devr...\n",
       " 68                Nav itara iroke karana Congress party\n",
       " 69    ‡≤é‡≤≤‡≥ç‡≤≤‡≤æ ‡≤á‡≤∞‡≥ã‡≤®‡≥Å ‡≤í‡≤Ç‡≤¶‡≥á ‡≤ú‡≥à ‡≤ï‡≤∞‡≥ç‡≤®‡≤æ‡≤ü‡≤ï ‡≤Æ‡≤æ‡≤§‡≥Ü ‡≤ú‡≥à ‡≤≠‡≥Å‡≤µ‡≤®‡≥á‡≤∂‡≥ç‡≤µ‡≤∞‡≤ø...\n",
       " Name: text, dtype: object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_Train[78:90], msg_Dev[50:70], #msg_Test[21:22]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "SUaNKv6xFlNj"
   },
   "outputs": [],
   "source": [
    "Train_Df=pd.DataFrame(msg_Train)\n",
    "Train_Df.columns=['Msg_with_Stopwords']\n",
    "\n",
    "Dev_Df=pd.DataFrame(msg_Dev)\n",
    "Dev_Df.columns=['Msg_with_Stopwords']\n",
    "\n",
    "Test_Df=pd.DataFrame(msg_Test)\n",
    "Test_Df.columns=['Msg_with_Stopwords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25306,
     "status": "ok",
     "timestamp": 1609999202380,
     "user": {
      "displayName": "Prasad Joshi",
      "photoUrl": "",
      "userId": "09800632122724335955"
     },
     "user_tz": -330
    },
    "id": "PdAGnkd4GYQh",
    "outputId": "467cd839-4f5a-41b4-99af-4a6245a87e91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6212, 1), (691, 1), (768, 1))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Df.shape, Dev_Df.shape, Test_Df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "cfybAk87L1Rf"
   },
   "outputs": [],
   "source": [
    "# Removing Null Values\n",
    "\n",
    "Train_Df['Msg_with_Stopwords']=Train_Df['Msg_with_Stopwords'].fillna(\"\")\n",
    "\n",
    "Dev_Df['Msg_with_Stopwords']=Dev_Df['Msg_with_Stopwords'].fillna(\"\")\n",
    "\n",
    "Test_Df['Msg_with_Stopwords']=Test_Df['Msg_with_Stopwords'].fillna(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6212, 2), (691, 2), (6212, 1), (691, 1), (768, 1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mal_train.shape, Mal_Dev.shape,Train_Df.shape, Dev_Df.shape, Test_Df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24536,
     "status": "ok",
     "timestamp": 1609999202387,
     "user": {
      "displayName": "Prasad Joshi",
      "photoUrl": "",
      "userId": "09800632122724335955"
     },
     "user_tz": -330
    },
    "id": "IsNaEIX1QWXp",
    "outputId": "68a6f472-f848-49fd-f9ea-1a997d2c0f8c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Joshi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ovLeV1EDQYeq"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "qlDvZ2m6QwTt"
   },
   "outputs": [],
   "source": [
    "Train_Df['Msg_without_Stopwords']=Train_Df['Msg_with_Stopwords'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "Dev_Df['Msg_without_Stopwords']=Dev_Df['Msg_with_Stopwords'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "Test_Df['Msg_without_Stopwords']=Test_Df['Msg_with_Stopwords'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "2UgF7xDSRAI_"
   },
   "outputs": [],
   "source": [
    "Train_Df['Msg_with_Stopwords_Len'] = [len(x.split()) for x in Train_Df['Msg_with_Stopwords'].tolist()]\n",
    "Train_Df['Msg_without_Stopwords_Len'] = [len(x.split()) for x in Train_Df['Msg_without_Stopwords'].tolist()]\n",
    "\n",
    "Dev_Df['Msg_with_Stopwords_Len'] = [len(x.split()) for x in Dev_Df['Msg_with_Stopwords'].tolist()]\n",
    "Dev_Df['Msg_without_Stopwords_Len'] = [len(x.split()) for x in Dev_Df['Msg_without_Stopwords'].tolist()]\n",
    "\n",
    "Test_Df['Msg_with_Stopwords_Len'] = [len(x.split()) for x in Test_Df['Msg_with_Stopwords'].tolist()]\n",
    "Test_Df['Msg_without_Stopwords_Len'] = [len(x.split()) for x in Test_Df['Msg_without_Stopwords'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "TdI70ZELRKHB"
   },
   "outputs": [],
   "source": [
    "Train_Data=pd.concat([Mal_train, Train_Df], axis=1)\n",
    "\n",
    "Dev_Data=pd.concat([Mal_Dev, Dev_Df], axis=1)\n",
    "\n",
    "Test_Data=pd.concat([Mal_test, Test_Df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3236,
     "status": "ok",
     "timestamp": 1609999217534,
     "user": {
      "displayName": "Prasad Joshi",
      "photoUrl": "",
      "userId": "09800632122724335955"
     },
     "user_tz": -330
    },
    "id": "yQ0eeiJUITpX",
    "outputId": "1811020a-d139-4a9e-c992-eaed5bf5119f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6212, 6), (691, 6), (768, 6))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Data.shape, Dev_Data.shape, Test_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "eb5iWB0DRXE7"
   },
   "outputs": [],
   "source": [
    "Train_Data=Train_Data.drop(['Msg_with_Stopwords','Msg_without_Stopwords_Len', 'Msg_with_Stopwords_Len', 'text'], axis=1)\n",
    "\n",
    "Dev_Data=Dev_Data.drop(['Msg_with_Stopwords','Msg_without_Stopwords_Len', 'Msg_with_Stopwords_Len', 'text'], axis=1)\n",
    "\n",
    "Test_Data=Test_Data.drop(['Msg_with_Stopwords','Msg_without_Stopwords_Len', 'Msg_with_Stopwords_Len', 'text'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3167,
     "status": "ok",
     "timestamp": 1609999220300,
     "user": {
      "displayName": "Prasad Joshi",
      "photoUrl": "",
      "userId": "09800632122724335955"
     },
     "user_tz": -330
    },
    "id": "4fVP3iTOKQvw",
    "outputId": "14c881d6-0970-4f19-ab31-a37fbbf3dcd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6212, 2), (691, 2), (768, 2))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset Train & Dev are : (1) Message_Without_Stopwords and (2) labels\n",
    "# Only Test is : (1) Message_Without_Stopwords\n",
    "Train_Data.shape, Dev_Data.shape, Test_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>Msg_without_Stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>unknown state</td>\n",
       "      <td>Hi Chi ugh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Positive</td>\n",
       "      <td>nivu helidu sari nanu follow madthini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Sir paisacom adara bagge video madi Open madod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Entha song na dislike madtiralla loafer nan ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>unknown state</td>\n",
       "      <td>Pubg kooda ban agbeku guru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>unknown state</td>\n",
       "      <td>Manju Sonu ‡≤Ö‡≤≠‡≤ø‡≤®‡≤Ç‡≤¶‡≤®‡≥Ü</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Positive</td>\n",
       "      <td>That making osm ASN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Negative</td>\n",
       "      <td>‡≤à ‡≤π‡≤æ‡≤°‡≥Å ‡≤∞‡≤∂‡≥ç‡≤Æ‡≤ø‡≤ï ‡≤Æ‡≤Ç‡≤ó‡≤£‡≥ç‡≤£‡≤®‡≤µ‡≤∞‡≤ø‡≤ó‡≥Ü ‡≤Ö‡≤∞‡≥ç‡≤™‡≤£‡≥Ü</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Super guru awesome video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Nandi Parthasarathi ‡≤ì‡≤π‡≥ã ‡≤®‡≤Ç‡≤¶‡≤ø‡≤®‡≤ø ‡≤®‡≤ø‡≤Ç‡≤¶‡≥Å ‡≤Æ‡≤ø‡≤≤‡≥ç‡≤ï‡≥ç ‡≤™‡≤æ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Negative</td>\n",
       "      <td>prithvi nayak Roberrt bangada goth aagutte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>not-Kannada</td>\n",
       "      <td>One like hands</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category                              Msg_without_Stopwords\n",
       "78  unknown state                                         Hi Chi ugh\n",
       "79       Positive              nivu helidu sari nanu follow madthini\n",
       "80       Positive  Sir paisacom adara bagge video madi Open madod...\n",
       "81       Negative  Entha song na dislike madtiralla loafer nan ma...\n",
       "82  unknown state                         Pubg kooda ban agbeku guru\n",
       "83  unknown state                                Manju Sonu ‡≤Ö‡≤≠‡≤ø‡≤®‡≤Ç‡≤¶‡≤®‡≥Ü\n",
       "84       Positive                                That making osm ASN\n",
       "85       Negative                  ‡≤à ‡≤π‡≤æ‡≤°‡≥Å ‡≤∞‡≤∂‡≥ç‡≤Æ‡≤ø‡≤ï ‡≤Æ‡≤Ç‡≤ó‡≤£‡≥ç‡≤£‡≤®‡≤µ‡≤∞‡≤ø‡≤ó‡≥Ü ‡≤Ö‡≤∞‡≥ç‡≤™‡≤£‡≥Ü\n",
       "86       Positive                           Super guru awesome video\n",
       "87       Negative  Nandi Parthasarathi ‡≤ì‡≤π‡≥ã ‡≤®‡≤Ç‡≤¶‡≤ø‡≤®‡≤ø ‡≤®‡≤ø‡≤Ç‡≤¶‡≥Å ‡≤Æ‡≤ø‡≤≤‡≥ç‡≤ï‡≥ç ‡≤™‡≤æ...\n",
       "88       Negative         prithvi nayak Roberrt bangada goth aagutte\n",
       "89    not-Kannada                                     One like hands"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Data[78:90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>Msg_without_Stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mixed feelings</td>\n",
       "      <td>Binduge saryagi ugithidira good go ahead enjoy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>yen song guru super</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not-Kannada</td>\n",
       "      <td>fevorat story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Super ‡≤§‡≥ã‡≤ó‡≤∞‡≤ø ‡≤§‡≥Ä‡≤™‡≥ç‡≤™</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤Æ‡≤æ‡≤§‡≥Å‡≤ó‡≤≥‡≥Å ‡≤Ö‡≤ï‡≥ç‡≤∑‡≤∞‡≤∂‡≤É ‡≤∏‡≤§‡≥ç‡≤Ø ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤à ‡≤∏‡≤æ‡≤Æ‡≤æ‡≤®‡≥ç‡≤Ø ‡≤ú‡≥Ä‡≤µ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Nandi Parthasarathi ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤Ö‡≤™‡≥ç‡≤™ ‡≤¶‡≥ä‡≤°‡≥ç ‡≤ó‡≤æ‡≤Ç‡≤°‡≥Å ‡≤∏‡≥Ç‡≤≥‡≥Ü‡≤Æ‡≤ó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Hugi guru badethawke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Trending wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Troll Stupid Fans naanu adikke kano helthirodu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>Positive</td>\n",
       "      <td>JustAn Opinion ninu Tika mucchuEvattu Kannada ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>691 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           category                              Msg_without_Stopwords\n",
       "0    Mixed feelings  Binduge saryagi ugithidira good go ahead enjoy...\n",
       "1          Positive                                yen song guru super\n",
       "2       not-Kannada                                      fevorat story\n",
       "3          Positive                                  Super ‡≤§‡≥ã‡≤ó‡≤∞‡≤ø ‡≤§‡≥Ä‡≤™‡≥ç‡≤™\n",
       "4          Positive  ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤Æ‡≤æ‡≤§‡≥Å‡≤ó‡≤≥‡≥Å ‡≤Ö‡≤ï‡≥ç‡≤∑‡≤∞‡≤∂‡≤É ‡≤∏‡≤§‡≥ç‡≤Ø ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤à ‡≤∏‡≤æ‡≤Æ‡≤æ‡≤®‡≥ç‡≤Ø ‡≤ú‡≥Ä‡≤µ...\n",
       "..              ...                                                ...\n",
       "686        Negative   Nandi Parthasarathi ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤Ö‡≤™‡≥ç‡≤™ ‡≤¶‡≥ä‡≤°‡≥ç ‡≤ó‡≤æ‡≤Ç‡≤°‡≥Å ‡≤∏‡≥Ç‡≤≥‡≥Ü‡≤Æ‡≤ó\n",
       "687        Negative                               Hugi guru badethawke\n",
       "688        Positive                                       Trending wow\n",
       "689        Positive  Troll Stupid Fans naanu adikke kano helthirodu...\n",
       "690        Positive  JustAn Opinion ninu Tika mucchuEvattu Kannada ...\n",
       "\n",
       "[691 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dev_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Msg_without_Stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kan_1</td>\n",
       "      <td>‡≤à ‡≤π‡≤æ‡≤°‡≤®‡≥ç‡≤®‡≥Å ‡≤π‡≤æ‡≤°‡≤ø‡≤¶ ‡≤µ‡≤ø‡≤ú‡≤Ø ‡≤™‡≥ç‡≤∞‡≤ï‡≤æ‡≤∂ voice ‡≤Ø‡≤æ‡≤∞‡≤ø‡≤ó‡≥Ü‡≤≤‡≥ç‡≤≤‡≤æ ‡≤á...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kan_2</td>\n",
       "      <td>Jai D Boss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kan_3</td>\n",
       "      <td>Signature move</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kan_4</td>\n",
       "      <td>Super song bro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kan_5</td>\n",
       "      <td>Wow Super agi helidira sir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>Kan_764</td>\n",
       "      <td>Thu thukali trailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>Kan_765</td>\n",
       "      <td>Siri gannadam galge haakbitallapa Thu yaro nin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>Kan_766</td>\n",
       "      <td>‡≤®‡≤æ‡≤µ‡≥á‡≤®‡≤æ‡≤¶‡≤∞‡≥Å ‡≤∏‡≥ç‡≤µ‡≤æ‡≤¨‡≤ø‡≤Æ‡≤æ‡≤®‡≤ø‡≤Ø‡≤æ‡≤ó‡≤ø ‡≤¨‡≤¶‡≥Å‡≤ï‡≤®‡≥ç‡≤®‡≥Å ‡≤ï‡≤ü‡≥ç‡≤ü‡≤ø‡≤ï‡≥ä‡≤≥‡≥ç‡≤≥‡≤≤‡≥Å...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>Kan_767</td>\n",
       "      <td>‡≤¶‡≤ø‡≤Ø‡≤æ ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤∏‡≥ã‡≤∑‡≤ø‡≤Ø‡≤≤‡≥ç ‡≤Æ‡≥Ä‡≤°‡≤ø‡≤Ø‡≤æ ‡≤Ö‡≤≤‡≥ç‡≤≤‡≤ø ‡≤ï‡≤æ‡≤£‡≥ç‡≤§‡≤ø‡≤≤‡≥ç‡≤≤n‡≤¶‡≤Ø‡≤µ‡≤ø‡≤ü...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>Kan_768</td>\n",
       "      <td>magaluru kade kalsi avanannu navu avanige madd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                              Msg_without_Stopwords\n",
       "0      Kan_1  ‡≤à ‡≤π‡≤æ‡≤°‡≤®‡≥ç‡≤®‡≥Å ‡≤π‡≤æ‡≤°‡≤ø‡≤¶ ‡≤µ‡≤ø‡≤ú‡≤Ø ‡≤™‡≥ç‡≤∞‡≤ï‡≤æ‡≤∂ voice ‡≤Ø‡≤æ‡≤∞‡≤ø‡≤ó‡≥Ü‡≤≤‡≥ç‡≤≤‡≤æ ‡≤á...\n",
       "1      Kan_2                                         Jai D Boss\n",
       "2      Kan_3                                     Signature move\n",
       "3      Kan_4                                     Super song bro\n",
       "4      Kan_5                         Wow Super agi helidira sir\n",
       "..       ...                                                ...\n",
       "763  Kan_764                                Thu thukali trailer\n",
       "764  Kan_765  Siri gannadam galge haakbitallapa Thu yaro nin...\n",
       "765  Kan_766  ‡≤®‡≤æ‡≤µ‡≥á‡≤®‡≤æ‡≤¶‡≤∞‡≥Å ‡≤∏‡≥ç‡≤µ‡≤æ‡≤¨‡≤ø‡≤Æ‡≤æ‡≤®‡≤ø‡≤Ø‡≤æ‡≤ó‡≤ø ‡≤¨‡≤¶‡≥Å‡≤ï‡≤®‡≥ç‡≤®‡≥Å ‡≤ï‡≤ü‡≥ç‡≤ü‡≤ø‡≤ï‡≥ä‡≤≥‡≥ç‡≤≥‡≤≤‡≥Å...\n",
       "766  Kan_767  ‡≤¶‡≤ø‡≤Ø‡≤æ ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤∏‡≥ã‡≤∑‡≤ø‡≤Ø‡≤≤‡≥ç ‡≤Æ‡≥Ä‡≤°‡≤ø‡≤Ø‡≤æ ‡≤Ö‡≤≤‡≥ç‡≤≤‡≤ø ‡≤ï‡≤æ‡≤£‡≥ç‡≤§‡≤ø‡≤≤‡≥ç‡≤≤n‡≤¶‡≤Ø‡≤µ‡≤ø‡≤ü...\n",
       "767  Kan_768  magaluru kade kalsi avanannu navu avanige madd...\n",
       "\n",
       "[768 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-rc1'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=Train_Data.Msg_without_Stopwords\n",
    "x_dev=Dev_Data.Msg_without_Stopwords\n",
    "x_test=Test_Data.Msg_without_Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "Train_Data['Nlabel']=le.fit_transform(Train_Data['category']) \n",
    "Dev_Data['Nlabel']=le.fit_transform(Dev_Data['category']) \n",
    "\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "y_train=Train_Data['Nlabel']\n",
    "y_dev=Dev_Data['Nlabel']\n",
    "\n",
    "y_train1 = to_categorical(y_train)\n",
    "y_dev1 = to_categorical(y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "num_labels = 5\n",
    "vocab_size = 5000\n",
    "batch_size = 100\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = tokenizer.texts_to_matrix(x_train)\n",
    "\n",
    "X_dev1 = tokenizer.texts_to_matrix(x_dev)\n",
    "\n",
    "X_test1=tokenizer.texts_to_matrix(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6212, 5000), (691, 5000), (6212, 5), (691, 5))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.shape, X_dev1.shape, y_train1.shape, y_dev1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train1), type(y_train1), type(X_dev1), type(y_dev1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Mode / ANN F1 score = 0.61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               2560512   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 2565      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 2,825,733\n",
      "Trainable params: 2,825,733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#let us build a basic model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, input_shape=(vocab_size,)),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(512),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(num_labels),\n",
    "    keras.layers.Activation('softmax')\n",
    "])\n",
    "\n",
    "model.summary()a\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6212 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001B4A7B09E58> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001B4A7B09E58> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "6212/6212 - 5s - loss: 1.3014 - accuracy: 0.4791\n",
      "Epoch 2/10\n",
      "6212/6212 - 2s - loss: 0.8938 - accuracy: 0.6492\n",
      "Epoch 3/10\n",
      "6212/6212 - 2s - loss: 0.6130 - accuracy: 0.7791\n",
      "Epoch 4/10\n",
      "6212/6212 - 2s - loss: 0.3948 - accuracy: 0.8662\n",
      "Epoch 5/10\n",
      "6212/6212 - 2s - loss: 0.2835 - accuracy: 0.8952\n",
      "Epoch 6/10\n",
      "6212/6212 - 2s - loss: 0.2319 - accuracy: 0.9156\n",
      "Epoch 7/10\n",
      "6212/6212 - 2s - loss: 0.1970 - accuracy: 0.9293\n",
      "Epoch 8/10\n",
      "6212/6212 - 2s - loss: 0.1813 - accuracy: 0.9322\n",
      "Epoch 9/10\n",
      "6212/6212 - 2s - loss: 0.1690 - accuracy: 0.9366\n",
      "Epoch 10/10\n",
      "6212/6212 - 2s - loss: 0.1630 - accuracy: 0.9406\n"
     ]
    }
   ],
   "source": [
    "num_epochs =10\n",
    "batch_size = 128\n",
    "history = model.fit(X_train1, y_train1, batch_size=batch_size, epochs=num_epochs,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_dev1,y_dev1,X_test1):\n",
    "    loss, accuracy = model.evaluate(X_dev1,y_dev1,verbose=0)\n",
    "    print('Accuracy: %f' % (accuracy*100))\n",
    "    print('Loss: %f' % (loss*100))\n",
    "    y_pred=model.predict_classes(X_dev1)\n",
    "\n",
    "    # predict \n",
    "    predictions = model.predict(X_dev1, batch_size = 32)\n",
    "    pred = np.argmax(predictions, axis=1)\n",
    "    # label\n",
    "    y_dev1 = np.argmax(y_dev1, axis=1)\n",
    "    \n",
    "    print(classification_report(y_dev1, pred))\n",
    "    \n",
    "    cohen_score = cohen_kappa_score(y_dev1, pred)\n",
    "    print(\"Cohen Score: \",cohen_score)\n",
    "    ##### PREDICTING test values ######\n",
    "    y_pred=model.predict_classes(X_test1)\n",
    "    df = pd.DataFrame(y_pred, columns = ['result'])\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.215627\n",
      "Loss: 179.500824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.19      0.21        52\n",
      "           1       0.59      0.55      0.57       139\n",
      "           2       0.69      0.74      0.72       321\n",
      "           3       0.62      0.59      0.60       110\n",
      "           4       0.49      0.46      0.48        69\n",
      "\n",
      "    accuracy                           0.61       691\n",
      "   macro avg       0.52      0.51      0.52       691\n",
      "weighted avg       0.60      0.61      0.61       691\n",
      "\n",
      "Cohen Score:  0.4390826043761662\n"
     ]
    }
   ],
   "source": [
    "df=predict(X_dev1,y_dev1,X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     result\n",
       "0         4\n",
       "1         2\n",
       "2         2\n",
       "3         3\n",
       "4         2\n",
       "..      ...\n",
       "763       1\n",
       "764       0\n",
       "765       2\n",
       "766       0\n",
       "767       0\n",
       "\n",
       "[768 rows x 1 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Namma galli goo bandiddru ashwatthama</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>‡≤Ö‡≤µ‡≤æ‡≤ó ‡≤ï‡≤¨‡≥ç‡≤ú ‡≤¶‡≤∞‡≥ç‡≤∂‡≤® ‡≤á‡≤µ‡≥ç‡≤∞‡≥Ü‡≤≤‡≥ç‡≤≤‡≤æ ‡≤¨‡≤Ç‡≤¶‡≥Å ‡≤ï‡≥Ü‡≤°‡≤µ‡≤ï‡≥ç‡≤§‡≤æ‡≤∞‡≥Ü</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Hahahaha LoL nIdiot beggar get lost</td>\n",
       "      <td>not-Kannada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>‡≤≤‡≤æ‡≤ï‡≥ç ‡≤°‡≥å‡≤®‡≥ç ‡≤∏‡≤Æ‡≤Ø‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤ï‡≤æ‡≤∞‡≥ç‡≤Æ‡≤ø‡≤ï‡≤∞‡≥Å ‡≤µ‡≤≤‡≤∏‡≤ø‡≤ó‡≤∞‡≥Å ‡≤∞‡≥Ü‡≤∏‡≥ç‡≤§‡≥Ü ‡≤Æ‡≥á...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>‡≤Æ‡≥ç‡≤Ø‡≥Ç‡≤∏‡≤ø‡≤ï‡≥ç ‡≤°‡≥à‡≤∞‡≥Ü‡≤ï‡≥ç‡≤ü‡≤∞‡≥ç ‡≤ó‡≥Ü ‡≤í‡≤Ç‡≤¶‡≥Å ‡≤¶‡≥ä‡≤°‡≥ç‡≤° ‡≤∏‡≤≤‡≤æ‡≤Ç ‡≤Ø‡≤æ‡≤µ‡≥Å‡≤¶‡≥ã ‡≤≤...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Fan war shuru madbeda guru</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>adeno gottilla tumba ista ayta nimage</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>‡≤π‡≥ä‡≤∏ ‡≤™‡≥ç‡≤∞‡≤Ø‡≥ã‡≤ó ‡≤Ø‡≤∂‡≤∏‡≥ç‡≤∏‡≥Å ‡≤∏‡≤ø‡≤ó‡≤≤‡≤ø</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>‡≤π‡≥å‡≤¶‡≥ã ‡≤π‡≥Å‡≤≤‡≤ø‡≤Ø‡≤æ‡≤π‡≤æ‡≤°‡≥Å ‡≤∏‡≥Ç‡≤™‡≤∞‡≥ç</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>≈î√§v√Æ√±ƒë≈ï√• G√∏Wƒë≈ô√∫ neenu beedhi soole maga neene ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Gandu loafer jeena</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text        label\n",
       "76              Namma galli goo bandiddru ashwatthama     Positive\n",
       "77          ‡≤Ö‡≤µ‡≤æ‡≤ó ‡≤ï‡≤¨‡≥ç‡≤ú ‡≤¶‡≤∞‡≥ç‡≤∂‡≤® ‡≤á‡≤µ‡≥ç‡≤∞‡≥Ü‡≤≤‡≥ç‡≤≤‡≤æ ‡≤¨‡≤Ç‡≤¶‡≥Å ‡≤ï‡≥Ü‡≤°‡≤µ‡≤ï‡≥ç‡≤§‡≤æ‡≤∞‡≥Ü     Positive\n",
       "78                Hahahaha LoL nIdiot beggar get lost  not-Kannada\n",
       "79  ‡≤≤‡≤æ‡≤ï‡≥ç ‡≤°‡≥å‡≤®‡≥ç ‡≤∏‡≤Æ‡≤Ø‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤ï‡≤æ‡≤∞‡≥ç‡≤Æ‡≤ø‡≤ï‡≤∞‡≥Å ‡≤µ‡≤≤‡≤∏‡≤ø‡≤ó‡≤∞‡≥Å ‡≤∞‡≥Ü‡≤∏‡≥ç‡≤§‡≥Ü ‡≤Æ‡≥á...     Positive\n",
       "80  ‡≤Æ‡≥ç‡≤Ø‡≥Ç‡≤∏‡≤ø‡≤ï‡≥ç ‡≤°‡≥à‡≤∞‡≥Ü‡≤ï‡≥ç‡≤ü‡≤∞‡≥ç ‡≤ó‡≥Ü ‡≤í‡≤Ç‡≤¶‡≥Å ‡≤¶‡≥ä‡≤°‡≥ç‡≤° ‡≤∏‡≤≤‡≤æ‡≤Ç ‡≤Ø‡≤æ‡≤µ‡≥Å‡≤¶‡≥ã ‡≤≤...     Positive\n",
       "81                         Fan war shuru madbeda guru     Positive\n",
       "82              adeno gottilla tumba ista ayta nimage     Positive\n",
       "83                            ‡≤π‡≥ä‡≤∏ ‡≤™‡≥ç‡≤∞‡≤Ø‡≥ã‡≤ó ‡≤Ø‡≤∂‡≤∏‡≥ç‡≤∏‡≥Å ‡≤∏‡≤ø‡≤ó‡≤≤‡≤ø     Positive\n",
       "84                              ‡≤π‡≥å‡≤¶‡≥ã ‡≤π‡≥Å‡≤≤‡≤ø‡≤Ø‡≤æ‡≤π‡≤æ‡≤°‡≥Å ‡≤∏‡≥Ç‡≤™‡≤∞‡≥ç     Positive\n",
       "85  ≈î√§v√Æ√±ƒë≈ï√• G√∏Wƒë≈ô√∫ neenu beedhi soole maga neene ...     Negative\n",
       "86                                 Gandu loafer jeena     Negative"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINAL=pd.concat([Test_Data.Msg_without_Stopwords, df], axis=1)\n",
    "FINAL=FINAL.rename(columns={\"Msg_without_Stopwords\": \"text\", \"result\": \"label\"})\n",
    "\n",
    "FINAL['label'] = FINAL['label'].map({0 : 'Mixed_feelings', 1 : 'Negative', 2: 'Positive', 3 :'not-Kannada', 4 : 'unknown_state'})\n",
    "FINAL[76:87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL.to_csv(\"ANN_Kannada_HASOC21.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import confusion_matrix, classification_report\n",
    "#from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "\n",
    "#def emoji(y_Dev, X_Dev1, model): \n",
    "  # y_Dev1 = to_categorical(y_Dev)\n",
    " #   loss, accuracy = model.evaluate(X_Dev1,y_Dev, verbose=0)\n",
    "  #  print('Accuracy: %f' % (accuracy*100))\n",
    "   # print('Loss: %f' % (loss*100))\n",
    "    #\n",
    "    #y_pred=model.predict_classes(X_Dev1)\n",
    "\n",
    "    \n",
    "    # predict \n",
    "    #predictions = model.predict(X_Dev1, batch_size = 32)\n",
    "    #pred = np.argmax(predictions, axis=1)\n",
    "    # label\n",
    "    #y_Dev1 = np.argmax(y_Dev, axis=1)\n",
    "    \n",
    "   # print(classification_report(y_Dev1, pred))\n",
    "    \n",
    "    #cohen_score = cohen_kappa_score(y_Dev1, pred)\n",
    "    #print(\"Cohen Score: \",cohen_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.647792\n",
      "Loss: 921.951864\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.36      0.40       102\n",
      "           1       0.60      0.52      0.56       237\n",
      "           2       0.71      0.80      0.75       706\n",
      "           3       0.76      0.52      0.62       141\n",
      "           4       0.65      0.65      0.65       580\n",
      "\n",
      "    accuracy                           0.67      1766\n",
      "   macro avg       0.63      0.57      0.60      1766\n",
      "weighted avg       0.66      0.67      0.66      1766\n",
      "\n",
      "Cohen Score:  0.5158853789727409\n"
     ]
    }
   ],
   "source": [
    "#emoji(y_dev1, X_dev1, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:638: FutureWarning: Pass sampling_strategy=minority as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8461, 10000) (8461, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1 2 3 4] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE('minority')\n",
    "\n",
    "\n",
    "X_sm, y_sm = smote.fit_sample(X_train1, y_train1)\n",
    "print(X_sm.shape, y_sm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8461 samples\n",
      "Epoch 1/10\n",
      "8461/8461 - 4s - loss: 0.1296 - accuracy: 0.9579\n",
      "Epoch 2/10\n",
      "8461/8461 - 4s - loss: 0.1151 - accuracy: 0.9630\n",
      "Epoch 3/10\n",
      "8461/8461 - 4s - loss: 0.1097 - accuracy: 0.9632\n",
      "Epoch 4/10\n",
      "8461/8461 - 4s - loss: 0.1095 - accuracy: 0.9628\n",
      "Epoch 5/10\n",
      "8461/8461 - 4s - loss: 0.1001 - accuracy: 0.9650\n",
      "Epoch 6/10\n",
      "8461/8461 - 4s - loss: 0.0975 - accuracy: 0.9656\n",
      "Epoch 7/10\n",
      "8461/8461 - 4s - loss: 0.0979 - accuracy: 0.9666\n",
      "Epoch 8/10\n",
      "8461/8461 - 4s - loss: 0.0883 - accuracy: 0.9666\n",
      "Epoch 9/10\n",
      "8461/8461 - 4s - loss: 0.0894 - accuracy: 0.9680\n",
      "Epoch 10/10\n",
      "8461/8461 - 4s - loss: 0.0884 - accuracy: 0.9670\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_sm, y_sm, batch_size=batch_size, epochs=num_epochs,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(960, 10000) (960, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1 2 3 4] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_Dev_sm, y_Dev_sm = smote.fit_sample(X_dev1, y_dev1)\n",
    "print(X_Dev_sm.shape, y_Dev_sm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.854169\n",
      "Loss: 245.261377\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.55      0.61       321\n",
      "           1       0.58      0.45      0.50       139\n",
      "           2       0.55      0.74      0.64       321\n",
      "           3       0.62      0.56      0.59       110\n",
      "           4       0.40      0.35      0.37        69\n",
      "\n",
      "    accuracy                           0.59       960\n",
      "   macro avg       0.57      0.53      0.54       960\n",
      "weighted avg       0.60      0.59      0.58       960\n",
      "\n",
      "Cohen Score:  0.4332973664467805\n"
     ]
    }
   ],
   "source": [
    "df_smote=predict(X_Dev_sm,y_Dev_sm,X_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  https://shrikar.com/deep-learning-with-keras-and-python-for-multiclass-classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN F1 score = 0.61\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer= Tokenizer()\n",
    "\n",
    "# Train, Dev, Test\n",
    "word_tokenizer.fit_on_texts(Train_Data.Msg_without_Stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = max([len(s.split()) for s in Train_Data.Msg_without_Stopwords])\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15800"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define vocabulary size\n",
    "\n",
    "vocab_size = len(word_tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeded Sentences of Train\n",
    "Train_Sent = word_tokenizer.texts_to_sequences(Train_Data.Msg_without_Stopwords)\n",
    "\n",
    "# Embeded Sentences of Dev\n",
    "Dev_Sent = word_tokenizer.texts_to_sequences(Dev_Data.Msg_without_Stopwords)\n",
    "\n",
    "# Embeded Sentences of Test\n",
    "Test_Sent = word_tokenizer.texts_to_sequences(Test_Data.Msg_without_Stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train\n",
    "Train_padded_sentences = pad_sequences(Train_Sent, max_length, padding='post')\n",
    "\n",
    "# Dev\n",
    "Dev_padded_sentences = pad_sequences(Dev_Sent, max_length, padding='post')\n",
    "\n",
    "# Test\n",
    "Test_padded_sentences = pad_sequences(Test_Sent, max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([82,\n",
       "  269,\n",
       "  4435,\n",
       "  840,\n",
       "  4436,\n",
       "  4437,\n",
       "  4438,\n",
       "  270,\n",
       "  4439,\n",
       "  326,\n",
       "  4440,\n",
       "  4441,\n",
       "  4442,\n",
       "  1153,\n",
       "  4443,\n",
       "  76,\n",
       "  171,\n",
       "  4444,\n",
       "  194,\n",
       "  4445],\n",
       " array([  82,  269, 4435,  840, 4436, 4437, 4438,  270, 4439,  326, 4440,\n",
       "        4441, 4442, 1153, 4443,   76,  171, 4444,  194, 4445,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Sent[0],Train_padded_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 92, 100)           1580000   \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 90, 64)            19264     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 1,599,589\n",
      "Trainable params: 1,599,589\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_CNN = keras.Sequential([\n",
    "    keras.layers.Embedding(vocab_size, 100, input_length=max_length),\n",
    "   # keras.layers.GlobalAveragePooling1D(),\n",
    "    # convolutional filters=128,  kernel size=3: it means length_long_sentence size of 65 we are luking for 3 words at a time\n",
    "    keras.layers.Conv1D(64, 3, activation='relu'),\n",
    "    keras.layers.GlobalMaxPooling1D(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "model_CNN.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_CNN.summary()\n",
    "\n",
    "\n",
    "\n",
    "#model = Sequential()\n",
    "#model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
    "#model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(10, activation='relu'))\n",
    "#model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "Train_Data['Nlabel']=le.fit_transform(Train_Data['category']) \n",
    "Dev_Data['Nlabel']=le.fit_transform(Dev_Data['category']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train=Train_Data['Nlabel']\n",
    "y_dev=Dev_Data['Nlabel']\n",
    "\n",
    "y_train1 = to_categorical(y_train)\n",
    "y_dev1 = to_categorical(y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6212, 92), (6212, 5), (691, 92), (691, 5), (768, 92))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_padded_sentences.shape, y_train1.shape, Dev_padded_sentences.shape, y_dev1.shape, Test_padded_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train1), type(Train_padded_sentences), type(Dev_padded_sentences), type(y_dev1), type(Test_padded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6212, 92), (6212, 5))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_padded_sentences=np.array(Train_padded_sentences)\n",
    "y_train1=np.array(y_train1)\n",
    "\n",
    "Train_padded_sentences.shape, y_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6212 samples\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001B4AD962E58> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001B4AD962E58> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "6212/6212 - 4s - loss: 1.4687 - accuracy: 0.4240\n",
      "Epoch 2/5\n",
      "6212/6212 - 3s - loss: 1.3323 - accuracy: 0.4731\n",
      "Epoch 3/5\n",
      "6212/6212 - 3s - loss: 1.1211 - accuracy: 0.5658\n",
      "Epoch 4/5\n",
      "6212/6212 - 3s - loss: 0.8743 - accuracy: 0.6937\n",
      "Epoch 5/5\n",
      "6212/6212 - 3s - loss: 0.6639 - accuracy: 0.7986\n"
     ]
    }
   ],
   "source": [
    "num_epochs =5\n",
    "batch_size = 128\n",
    "history = model_CNN.fit(Train_padded_sentences, y_train1, batch_size=batch_size, epochs=num_epochs, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dev_padded_sentences=np.array(Dev_padded_sentences)\n",
    "y_dev1=np.array(y_dev1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_CNN(X_dev1,y_dev1,X_test1):\n",
    "    loss, accuracy = model_CNN.evaluate(X_dev1,y_dev1,verbose=0)\n",
    "    print('Accuracy: %f' % (accuracy*100))\n",
    "    print('Loss: %f' % (loss*100))\n",
    "    y_pred=model_CNN.predict_classes(X_dev1)\n",
    "\n",
    "    # predict \n",
    "    predictions = model_CNN.predict(X_dev1, batch_size = 32)\n",
    "    pred = np.argmax(predictions, axis=1)\n",
    "    # label\n",
    "    y_dev1 = np.argmax(y_dev1, axis=1)\n",
    "    \n",
    "    print(classification_report(y_dev1, pred))\n",
    "    \n",
    "    cohen_score = cohen_kappa_score(y_dev1, pred)\n",
    "    print(\"Cohen Score: \",cohen_score)\n",
    "    ##### PREDICTING test values ######\n",
    "    y_pred=model_CNN.predict_classes(X_test1)\n",
    "    df = pd.DataFrame(y_pred, columns = ['result'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.531113\n",
      "Loss: 95.899139\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.10      0.17        52\n",
      "           1       0.64      0.56      0.60       139\n",
      "           2       0.67      0.83      0.74       321\n",
      "           3       0.60      0.62      0.61       110\n",
      "           4       0.46      0.32      0.38        69\n",
      "\n",
      "    accuracy                           0.64       691\n",
      "   macro avg       0.60      0.48      0.50       691\n",
      "weighted avg       0.63      0.64      0.61       691\n",
      "\n",
      "Cohen Score:  0.4488883262386657\n"
     ]
    }
   ],
   "source": [
    "df_CNN=predict_CNN(Dev_padded_sentences,y_dev1,Test_padded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Namma galli goo bandiddru ashwatthama</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>‡≤Ö‡≤µ‡≤æ‡≤ó ‡≤ï‡≤¨‡≥ç‡≤ú ‡≤¶‡≤∞‡≥ç‡≤∂‡≤® ‡≤á‡≤µ‡≥ç‡≤∞‡≥Ü‡≤≤‡≥ç‡≤≤‡≤æ ‡≤¨‡≤Ç‡≤¶‡≥Å ‡≤ï‡≥Ü‡≤°‡≤µ‡≤ï‡≥ç‡≤§‡≤æ‡≤∞‡≥Ü</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Hahahaha LoL nIdiot beggar get lost</td>\n",
       "      <td>not-Kannada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>‡≤≤‡≤æ‡≤ï‡≥ç ‡≤°‡≥å‡≤®‡≥ç ‡≤∏‡≤Æ‡≤Ø‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤ï‡≤æ‡≤∞‡≥ç‡≤Æ‡≤ø‡≤ï‡≤∞‡≥Å ‡≤µ‡≤≤‡≤∏‡≤ø‡≤ó‡≤∞‡≥Å ‡≤∞‡≥Ü‡≤∏‡≥ç‡≤§‡≥Ü ‡≤Æ‡≥á...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>‡≤Æ‡≥ç‡≤Ø‡≥Ç‡≤∏‡≤ø‡≤ï‡≥ç ‡≤°‡≥à‡≤∞‡≥Ü‡≤ï‡≥ç‡≤ü‡≤∞‡≥ç ‡≤ó‡≥Ü ‡≤í‡≤Ç‡≤¶‡≥Å ‡≤¶‡≥ä‡≤°‡≥ç‡≤° ‡≤∏‡≤≤‡≤æ‡≤Ç ‡≤Ø‡≤æ‡≤µ‡≥Å‡≤¶‡≥ã ‡≤≤...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Fan war shuru madbeda guru</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>adeno gottilla tumba ista ayta nimage</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>‡≤π‡≥ä‡≤∏ ‡≤™‡≥ç‡≤∞‡≤Ø‡≥ã‡≤ó ‡≤Ø‡≤∂‡≤∏‡≥ç‡≤∏‡≥Å ‡≤∏‡≤ø‡≤ó‡≤≤‡≤ø</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>‡≤π‡≥å‡≤¶‡≥ã ‡≤π‡≥Å‡≤≤‡≤ø‡≤Ø‡≤æ‡≤π‡≤æ‡≤°‡≥Å ‡≤∏‡≥Ç‡≤™‡≤∞‡≥ç</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>≈î√§v√Æ√±ƒë≈ï√• G√∏Wƒë≈ô√∫ neenu beedhi soole maga neene ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Gandu loafer jeena</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text        label\n",
       "76              Namma galli goo bandiddru ashwatthama     Positive\n",
       "77          ‡≤Ö‡≤µ‡≤æ‡≤ó ‡≤ï‡≤¨‡≥ç‡≤ú ‡≤¶‡≤∞‡≥ç‡≤∂‡≤® ‡≤á‡≤µ‡≥ç‡≤∞‡≥Ü‡≤≤‡≥ç‡≤≤‡≤æ ‡≤¨‡≤Ç‡≤¶‡≥Å ‡≤ï‡≥Ü‡≤°‡≤µ‡≤ï‡≥ç‡≤§‡≤æ‡≤∞‡≥Ü     Positive\n",
       "78                Hahahaha LoL nIdiot beggar get lost  not-Kannada\n",
       "79  ‡≤≤‡≤æ‡≤ï‡≥ç ‡≤°‡≥å‡≤®‡≥ç ‡≤∏‡≤Æ‡≤Ø‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤ï‡≤æ‡≤∞‡≥ç‡≤Æ‡≤ø‡≤ï‡≤∞‡≥Å ‡≤µ‡≤≤‡≤∏‡≤ø‡≤ó‡≤∞‡≥Å ‡≤∞‡≥Ü‡≤∏‡≥ç‡≤§‡≥Ü ‡≤Æ‡≥á...     Positive\n",
       "80  ‡≤Æ‡≥ç‡≤Ø‡≥Ç‡≤∏‡≤ø‡≤ï‡≥ç ‡≤°‡≥à‡≤∞‡≥Ü‡≤ï‡≥ç‡≤ü‡≤∞‡≥ç ‡≤ó‡≥Ü ‡≤í‡≤Ç‡≤¶‡≥Å ‡≤¶‡≥ä‡≤°‡≥ç‡≤° ‡≤∏‡≤≤‡≤æ‡≤Ç ‡≤Ø‡≤æ‡≤µ‡≥Å‡≤¶‡≥ã ‡≤≤...     Positive\n",
       "81                         Fan war shuru madbeda guru     Positive\n",
       "82              adeno gottilla tumba ista ayta nimage     Positive\n",
       "83                            ‡≤π‡≥ä‡≤∏ ‡≤™‡≥ç‡≤∞‡≤Ø‡≥ã‡≤ó ‡≤Ø‡≤∂‡≤∏‡≥ç‡≤∏‡≥Å ‡≤∏‡≤ø‡≤ó‡≤≤‡≤ø     Positive\n",
       "84                              ‡≤π‡≥å‡≤¶‡≥ã ‡≤π‡≥Å‡≤≤‡≤ø‡≤Ø‡≤æ‡≤π‡≤æ‡≤°‡≥Å ‡≤∏‡≥Ç‡≤™‡≤∞‡≥ç     Positive\n",
       "85  ≈î√§v√Æ√±ƒë≈ï√• G√∏Wƒë≈ô√∫ neenu beedhi soole maga neene ...     Negative\n",
       "86                                 Gandu loafer jeena     Negative"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINAL_CNN=pd.concat([Test_Data.Msg_without_Stopwords, df_CNN], axis=1)\n",
    "FINAL_CNN=FINAL_CNN.rename(columns={\"Msg_without_Stopwords\": \"text\", \"result\": \"label\"})\n",
    "\n",
    "FINAL_CNN['label'] = FINAL_CNN['label'].map({0 : 'Mixed_feelings', 1 : 'Negative', 2: 'Positive', 3 :'not-Kannada', 4 : 'unknown_state'})\n",
    "FINAL[76:87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_CNN.to_csv(\"CNN_Kannada_HASOC21.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emoji(y_dev1, Dev_padded_sentences, model_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings_dictionary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-20a5cc928fcc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# step 2 & step 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0membedding_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membeddings_dictionary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0membedding_vector\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# Words not found in embedding index will be all-zeros.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'embeddings_dictionary' is not defined"
     ]
    }
   ],
   "source": [
    "# step 1\n",
    "embedding_matrix = np.zeros((vocab_size, 300)) #create an array of zeros with word_num rows and embedding_dim columns\n",
    "\n",
    "# step 2 & step 3\n",
    "for word, index in word_tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[index] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_node=32\n",
    "nclasses=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dropout, Dense, Embedding, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 195, 300)          12069000  \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 195, 64)           85248     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 195, 64)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 12,197,005\n",
      "Trainable params: 12,197,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_BiLSTM=keras.Sequential([\n",
    "     # add Embeddign layer\n",
    "keras.layers.Embedding(vocab_size,300, input_length=max_length, trainable=True),\n",
    "    # add birectional \n",
    "keras.layers.Bidirectional(LSTM(lstm_node, return_sequences=True, recurrent_dropout=0.2)),\n",
    "    # add dropout layer after  each lstm\n",
    "keras.layers.Dropout(0.2),\n",
    "        # add birectional \n",
    "keras.layers.Bidirectional(LSTM(lstm_node, recurrent_dropout=0.2)),\n",
    "     # add dropout layer after  each lstm\n",
    "keras.layers.Dropout(0.2),\n",
    "    # Add the fully connected layer with 256 nurons and relu activation\n",
    "keras.layers.Dense(256,activation='relu'),\n",
    "    # Add the output layer with softmax activation since we have 2 classes\n",
    "keras.layers.Dense(nclasses, activation='softmax')\n",
    "])\n",
    "\n",
    "model_BiLSTM.compile(loss='sparse_categorical_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "model_BiLSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  398,   399,     9, ...,     0,     0,     0],\n",
       "        [  179,  3473,  3474, ...,     0,     0,     0],\n",
       "        [  194,   253,   813, ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [ 1871,   696,   787, ...,     0,     0,     0],\n",
       "        [11438,   453,  1582, ...,     0,     0,     0],\n",
       "        [  543,  2190,    25, ...,     0,     0,     0]]), (15888, 195))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_padded_sentences, Train_padded_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.]]), (15888, 5))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train1, y_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15888, 195), (15888, 5))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_padded_sentences.shape, y_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15888, 195), (15888,), numpy.ndarray, pandas.core.series.Series)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_padded_sentences.shape, Train_Data['Nlabel'].shape, type(Train_padded_sentences), type(Train_Data['Nlabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y=Train_Data['Nlabel'].to_numpy()\n",
    "type(train_y), type(y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15888 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-170-093d397dd1f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_BiLSTM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrain_padded_sentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "history = model_BiLSTM.fit(Train_padded_sentences, y_train1, batch_size=batch_size, epochs=num_epochs, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot : Bilstem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[14089,\n",
       "  1935,\n",
       "  6247,\n",
       "  4205,\n",
       "  9451,\n",
       "  15145,\n",
       "  413,\n",
       "  13213,\n",
       "  9181,\n",
       "  6348,\n",
       "  6796,\n",
       "  3009,\n",
       "  9210,\n",
       "  15433,\n",
       "  4628,\n",
       "  1930,\n",
       "  2868,\n",
       "  5087,\n",
       "  5674,\n",
       "  15473],\n",
       " [1279, 1218, 1408, 13058, 6981, 12855, 3774, 14666, 5838],\n",
       " [10706, 5709, 9706],\n",
       " [3541, 14847, 12089, 10652, 5768, 14666, 5743],\n",
       " [10706, 9186, 3644, 15324],\n",
       " [9814,\n",
       "  5174,\n",
       "  14948,\n",
       "  683,\n",
       "  344,\n",
       "  8103,\n",
       "  2285,\n",
       "  6333,\n",
       "  13024,\n",
       "  4043,\n",
       "  1960,\n",
       "  14114,\n",
       "  14805,\n",
       "  6501,\n",
       "  15339,\n",
       "  2433,\n",
       "  6927,\n",
       "  7454,\n",
       "  2285,\n",
       "  3935,\n",
       "  9763,\n",
       "  5925,\n",
       "  11599,\n",
       "  5097,\n",
       "  4074,\n",
       "  1960,\n",
       "  14835],\n",
       " [7691, 5956, 12306, 130, 285, 12005],\n",
       " [10706, 10706, 10706, 7454, 13144, 12737, 2320],\n",
       " [9302, 10672, 14068, 2303, 15115, 3529],\n",
       " [8547, 2515, 10706],\n",
       " [708, 7982, 13430, 15716, 14143],\n",
       " [15319, 685],\n",
       " [4166, 3703, 4990],\n",
       " [1103, 3264, 3078, 10405, 8431, 6309],\n",
       " [72, 15788, 5575, 8243, 12813],\n",
       " [7429, 13904, 5992, 11697, 1990, 13170, 10927],\n",
       " [3949,\n",
       "  11511,\n",
       "  14126,\n",
       "  10166,\n",
       "  8858,\n",
       "  3104,\n",
       "  9189,\n",
       "  1103,\n",
       "  7739,\n",
       "  14702,\n",
       "  14374,\n",
       "  14299],\n",
       " [471, 13069, 1794],\n",
       " [15196, 11850, 8045, 8087, 15168, 15064],\n",
       " [1594, 3529, 15255, 10846, 14512, 4631, 15294, 3805],\n",
       " [11037, 3414],\n",
       " [3529, 14244, 5966],\n",
       " [4736,\n",
       "  14948,\n",
       "  14350,\n",
       "  1523,\n",
       "  14694,\n",
       "  13222,\n",
       "  4021,\n",
       "  8743,\n",
       "  4411,\n",
       "  1337,\n",
       "  13099,\n",
       "  7058,\n",
       "  10268],\n",
       " [2560, 9281, 3104, 1103],\n",
       " [3529, 7429, 8225],\n",
       " [12880, 3264, 4044, 833, 2123, 7728, 13777, 7502],\n",
       " [27, 4135, 12914, 12364, 11731, 3852, 9984, 1219],\n",
       " [10706, 9706, 13836],\n",
       " [2034, 1654, 4930, 3663, 10706, 9342],\n",
       " [1076, 5696, 14838, 3529],\n",
       " [2216, 634, 4158, 8831],\n",
       " [10706, 14857],\n",
       " [11113, 7921, 14119, 466],\n",
       " [3485, 8953, 15462, 7454, 9690, 5349, 7610, 5349, 10600, 10346, 9204],\n",
       " [5875,\n",
       "  1424,\n",
       "  10446,\n",
       "  15068,\n",
       "  15028,\n",
       "  5704,\n",
       "  2557,\n",
       "  7498,\n",
       "  12754,\n",
       "  2509,\n",
       "  10915,\n",
       "  3098,\n",
       "  7760,\n",
       "  2548,\n",
       "  2675,\n",
       "  11142,\n",
       "  4143,\n",
       "  15068,\n",
       "  3106,\n",
       "  3543,\n",
       "  12896,\n",
       "  9665,\n",
       "  14247,\n",
       "  13729,\n",
       "  3487,\n",
       "  6092,\n",
       "  1930,\n",
       "  3912,\n",
       "  5228,\n",
       "  5391,\n",
       "  3098,\n",
       "  6975,\n",
       "  4205,\n",
       "  2525,\n",
       "  14089,\n",
       "  15691,\n",
       "  3774,\n",
       "  13339,\n",
       "  7498,\n",
       "  13894,\n",
       "  2525],\n",
       " [14244, 7030, 3529, 1022],\n",
       " [11111,\n",
       "  1351,\n",
       "  8371,\n",
       "  15277,\n",
       "  10528,\n",
       "  9628,\n",
       "  12914,\n",
       "  13444,\n",
       "  71,\n",
       "  14089,\n",
       "  7415,\n",
       "  12886,\n",
       "  13840,\n",
       "  1449,\n",
       "  2332,\n",
       "  14229,\n",
       "  12879,\n",
       "  11214,\n",
       "  532,\n",
       "  309,\n",
       "  12914,\n",
       "  5248,\n",
       "  2440,\n",
       "  6748,\n",
       "  4507,\n",
       "  3190,\n",
       "  9938,\n",
       "  388,\n",
       "  6456,\n",
       "  3139,\n",
       "  8449,\n",
       "  3794,\n",
       "  13568,\n",
       "  12914,\n",
       "  5248,\n",
       "  12738,\n",
       "  1041],\n",
       " [10553,\n",
       "  7910,\n",
       "  10286,\n",
       "  8373,\n",
       "  13740,\n",
       "  2348,\n",
       "  10399,\n",
       "  8803,\n",
       "  8373,\n",
       "  5782,\n",
       "  9784,\n",
       "  11371,\n",
       "  7085,\n",
       "  14046],\n",
       " [6592, 11561],\n",
       " [12514, 367, 875, 3990, 9706, 3719, 9811, 12317, 864],\n",
       " [202, 11746, 9442, 4627, 6605, 3935, 8373, 10706, 9281],\n",
       " [4888],\n",
       " [2303, 5176, 4822, 14018],\n",
       " [7880, 2123, 8856, 3807],\n",
       " [14948, 15513],\n",
       " [10706, 9706],\n",
       " [12459,\n",
       "  1041,\n",
       "  13983,\n",
       "  4426,\n",
       "  9577,\n",
       "  6719,\n",
       "  12136,\n",
       "  8906,\n",
       "  13582,\n",
       "  2217,\n",
       "  2253,\n",
       "  11955,\n",
       "  12737,\n",
       "  12725,\n",
       "  6274,\n",
       "  1489,\n",
       "  15260,\n",
       "  15260,\n",
       "  2728,\n",
       "  8126,\n",
       "  13672,\n",
       "  5151,\n",
       "  7344,\n",
       "  8455,\n",
       "  2013,\n",
       "  12186,\n",
       "  2641],\n",
       " [10706, 14857, 6909, 15542, 14948, 10706, 14948, 10932, 7004],\n",
       " [9302, 10672, 14894, 4703, 2950, 8560, 6249, 8779],\n",
       " [10706, 14778],\n",
       " [9084, 71, 2013, 6282, 1858, 11380, 5256, 9594],\n",
       " [6909, 15542, 10706, 6662, 15728],\n",
       " [13050, 1021, 7410, 15064],\n",
       " [7486, 10706, 4901],\n",
       " [2666, 3529, 3729],\n",
       " [12205, 1103, 694, 15226, 13396, 3884],\n",
       " [2362, 2285, 9357, 1117],\n",
       " [5575, 8243, 10706],\n",
       " [6927, 12234, 3638, 339],\n",
       " [4052, 15637, 7085, 10395, 13807, 344, 12587, 4123, 3929],\n",
       " [5048, 3703, 3703, 10706, 3529],\n",
       " [12149, 202, 10822],\n",
       " [3104, 5925, 1103, 875, 11085],\n",
       " [2560, 10291, 10121, 9706],\n",
       " [1042, 13144, 6943, 6745],\n",
       " [13498,\n",
       "  11587,\n",
       "  14948,\n",
       "  15070,\n",
       "  4411,\n",
       "  5209,\n",
       "  3841,\n",
       "  647,\n",
       "  10056,\n",
       "  2003,\n",
       "  14299,\n",
       "  14948,\n",
       "  11050,\n",
       "  11702,\n",
       "  9463,\n",
       "  4993,\n",
       "  6054,\n",
       "  15637,\n",
       "  2594,\n",
       "  11742],\n",
       " [10706, 9706],\n",
       " [634, 3567, 4311, 9618],\n",
       " [4457,\n",
       "  9706,\n",
       "  4906,\n",
       "  13144,\n",
       "  12005,\n",
       "  9706,\n",
       "  3703,\n",
       "  8745,\n",
       "  5550,\n",
       "  10935,\n",
       "  1972,\n",
       "  10706,\n",
       "  14948,\n",
       "  1627],\n",
       " [13624,\n",
       "  7085,\n",
       "  10086,\n",
       "  1597,\n",
       "  7909,\n",
       "  9349,\n",
       "  13420,\n",
       "  10694,\n",
       "  14242,\n",
       "  6921,\n",
       "  2077,\n",
       "  12322,\n",
       "  12762,\n",
       "  1774],\n",
       " [9929, 25, 14841],\n",
       " [746, 3916, 5761, 2396, 9706, 8685, 578, 6358, 8791, 9941],\n",
       " [6542, 3741, 900, 7433, 10575, 12382],\n",
       " [7429, 1692, 2437],\n",
       " [4052, 7108, 3386, 7868],\n",
       " [3579, 4593, 13248],\n",
       " [11542, 15656, 2362, 4284, 10706, 15637],\n",
       " [11085, 3680, 1743],\n",
       " [2216, 6735, 11035],\n",
       " [7108, 1370, 14800, 694, 12119, 8003],\n",
       " [1103,\n",
       "  13216,\n",
       "  194,\n",
       "  10216,\n",
       "  3663,\n",
       "  683,\n",
       "  15684,\n",
       "  15636,\n",
       "  11168,\n",
       "  4518,\n",
       "  15636,\n",
       "  11168,\n",
       "  5671,\n",
       "  14453,\n",
       "  1103],\n",
       " [10510, 9706, 11542, 15196, 6771, 7429, 13548, 2324, 4222, 4930, 11436],\n",
       " [9227, 1375, 15381, 8684, 15637],\n",
       " [5288, 8035, 9166],\n",
       " [4909, 13814, 5355, 5343],\n",
       " [2253, 11955, 6390, 14708, 7415],\n",
       " [10706, 15637, 186, 3663],\n",
       " [2904, 6001, 13126, 6750, 3008, 2746, 6450, 1376, 5800],\n",
       " [5705, 9660, 12371, 13823, 7235, 5854],\n",
       " [2760, 7004, 15728],\n",
       " [2123, 8121, 7162, 9508, 9721, 4466, 11565, 10357, 10000],\n",
       " [5576, 10462, 15075, 12142],\n",
       " [13656, 2157, 5450, 6528],\n",
       " [9970, 2277, 11798, 9306, 3821],\n",
       " [3885,\n",
       "  10237,\n",
       "  14805,\n",
       "  3822,\n",
       "  3886,\n",
       "  7157,\n",
       "  6317,\n",
       "  1720,\n",
       "  8711,\n",
       "  10962,\n",
       "  6931,\n",
       "  13024,\n",
       "  9843,\n",
       "  14327,\n",
       "  14912,\n",
       "  6896,\n",
       "  10746,\n",
       "  957,\n",
       "  13144],\n",
       " [14146, 1964, 9837],\n",
       " [6697, 10286, 7831, 15084, 14586, 857],\n",
       " [6380, 10706, 14870],\n",
       " [3264,\n",
       "  12914,\n",
       "  13218,\n",
       "  12725,\n",
       "  14535,\n",
       "  2253,\n",
       "  1351,\n",
       "  5958,\n",
       "  2123,\n",
       "  1754,\n",
       "  3581,\n",
       "  9916,\n",
       "  10996,\n",
       "  6748,\n",
       "  15421,\n",
       "  3190,\n",
       "  4507,\n",
       "  9457,\n",
       "  11343,\n",
       "  7414],\n",
       " [1686, 4332, 7733, 11747, 2843, 11419, 3529, 5355],\n",
       " [900, 12725, 9700, 14922, 12725, 14715, 14647],\n",
       " [14230, 7600, 9706, 14299, 9811, 7004, 10166],\n",
       " [1103, 10706, 1964],\n",
       " [14343, 8215, 13284],\n",
       " [10706, 9706, 8373],\n",
       " [3476, 2833, 12062, 4143],\n",
       " [10165, 7774, 9909, 15691, 2123, 10832, 1964, 9938, 9781, 9453],\n",
       " [15728, 7004, 683],\n",
       " [1686, 10674, 12512, 6823],\n",
       " [15765,\n",
       "  13971,\n",
       "  3832,\n",
       "  5087,\n",
       "  12375,\n",
       "  7472,\n",
       "  5736,\n",
       "  14953,\n",
       "  8446,\n",
       "  11072,\n",
       "  5736,\n",
       "  11,\n",
       "  14953],\n",
       " [9117, 9117, 1720, 5104, 4401, 14857, 1432],\n",
       " [10706, 5300, 9706],\n",
       " [14948, 5284, 8705, 14299],\n",
       " [6921, 9609],\n",
       " [15742, 4846, 8953, 2880, 14367, 12148, 14299, 15776, 118, 1720],\n",
       " [14009, 10550, 15381, 5737, 14242, 15226, 15226, 8479, 10266, 2843],\n",
       " [5253, 14948, 3258, 6709],\n",
       " [7398, 9706, 11870, 7830, 15462, 9706, 15672, 5065],\n",
       " [4166, 7004, 3104, 15548, 4263, 7004],\n",
       " [9600, 441, 9270, 10387, 14532, 9600],\n",
       " [6921, 285, 2938, 10010, 14594, 6727, 8791],\n",
       " [6896, 6932, 10737, 5415, 1883, 15738, 3430, 10737, 11841],\n",
       " [10165, 7774, 9909, 15691, 2123, 10832, 1964, 9938, 9781, 9453],\n",
       " [13953, 12914, 9186, 9852],\n",
       " [7166, 2508, 10706],\n",
       " [5705,\n",
       "  8483,\n",
       "  4906,\n",
       "  12423,\n",
       "  9371,\n",
       "  15064,\n",
       "  8373,\n",
       "  6662,\n",
       "  14747,\n",
       "  10130,\n",
       "  7004,\n",
       "  207,\n",
       "  13352,\n",
       "  4204,\n",
       "  15738,\n",
       "  9003],\n",
       " [15787, 15787, 1787],\n",
       " [2741, 8456, 9886, 10266],\n",
       " [10165, 7774, 9909, 15691, 2123, 10832, 1964, 9938, 9781, 9453],\n",
       " [7891, 5425, 10706],\n",
       " [12258,\n",
       "  7965,\n",
       "  9775,\n",
       "  9648,\n",
       "  8373,\n",
       "  7454,\n",
       "  344,\n",
       "  10589,\n",
       "  3990,\n",
       "  6865,\n",
       "  15408,\n",
       "  6090,\n",
       "  11301,\n",
       "  1227,\n",
       "  7352,\n",
       "  4218,\n",
       "  875,\n",
       "  3379,\n",
       "  1032,\n",
       "  14647,\n",
       "  5504,\n",
       "  8373,\n",
       "  7454,\n",
       "  344,\n",
       "  10362,\n",
       "  9399],\n",
       " [6921, 1888, 13931, 8705],\n",
       " [12800, 8243, 10706],\n",
       " [2253, 9628, 337, 11166, 9838, 3505, 6873, 9630, 6719],\n",
       " [10706, 9706, 8252, 8045],\n",
       " [5596, 14009, 10550],\n",
       " [10086,\n",
       "  2052,\n",
       "  12574,\n",
       "  2938,\n",
       "  9775,\n",
       "  6097,\n",
       "  10302,\n",
       "  15206,\n",
       "  8424,\n",
       "  9775,\n",
       "  12714,\n",
       "  7833,\n",
       "  6017,\n",
       "  3773,\n",
       "  10180,\n",
       "  777,\n",
       "  6490,\n",
       "  4822,\n",
       "  3062,\n",
       "  11538,\n",
       "  3680,\n",
       "  2853],\n",
       " [71, 8856, 7815, 8221, 15075, 15075, 14715, 10798],\n",
       " [4302, 5806],\n",
       " [71, 6660, 2013, 15564, 1858],\n",
       " [13159, 11418],\n",
       " [12425, 8989, 13995],\n",
       " [11085, 1240, 8953],\n",
       " [13539, 5423, 14948, 13771, 15168, 11220],\n",
       " [3990, 9886, 14359, 2445, 5523],\n",
       " [6995,\n",
       "  5925,\n",
       "  202,\n",
       "  15709,\n",
       "  13490,\n",
       "  10818,\n",
       "  14414,\n",
       "  6262,\n",
       "  6507,\n",
       "  4930,\n",
       "  1960,\n",
       "  6793,\n",
       "  8288],\n",
       " [3529, 4930, 14922, 11299, 7160, 5768, 3529, 12927, 14922, 3529],\n",
       " [10165, 7774, 9909, 15691, 2123, 10832, 1964, 9938, 9781, 9453],\n",
       " [11066, 9929, 12065, 5925, 10706],\n",
       " [2904, 6001, 1997, 8407, 15766, 8344, 4004, 7914, 3495, 14545, 6960, 1628],\n",
       " [7456, 11883, 1596, 15381, 8684, 14009, 10550],\n",
       " [13635,\n",
       "  15637,\n",
       "  13487,\n",
       "  14493,\n",
       "  4153,\n",
       "  7751,\n",
       "  8749,\n",
       "  10699,\n",
       "  14299,\n",
       "  6896,\n",
       "  7401,\n",
       "  14483,\n",
       "  4823,\n",
       "  11127],\n",
       " [4930, 875, 1916, 7520, 13756],\n",
       " [11155, 3350, 15050, 14666, 15068, 15028, 10771],\n",
       " [10706, 3529, 13548, 13938, 14126, 5381],\n",
       " [12700, 5412, 9159, 3529],\n",
       " [12725, 2803, 8136, 11788, 5141, 3979, 15396, 13297],\n",
       " [10706, 15637, 8351, 15637],\n",
       " [10706, 3663],\n",
       " [7113, 15235, 254, 3264, 12194, 9700, 7374, 7500],\n",
       " [4959, 15509, 4740, 15719, 8669],\n",
       " [14593, 3759, 15637],\n",
       " [8831, 3734, 14948, 11973],\n",
       " [3297, 10410, 14691, 10694, 15226, 3116],\n",
       " [263,\n",
       "  3078,\n",
       "  13417,\n",
       "  11253,\n",
       "  7376,\n",
       "  15082,\n",
       "  15258,\n",
       "  1499,\n",
       "  10446,\n",
       "  9404,\n",
       "  1527,\n",
       "  10383,\n",
       "  10081,\n",
       "  14666,\n",
       "  8140,\n",
       "  6348,\n",
       "  14106,\n",
       "  8152,\n",
       "  857,\n",
       "  14047,\n",
       "  8641,\n",
       "  10187,\n",
       "  15342,\n",
       "  13355,\n",
       "  14873,\n",
       "  2253,\n",
       "  9131,\n",
       "  12334,\n",
       "  5339,\n",
       "  3593,\n",
       "  8683,\n",
       "  9875,\n",
       "  3850,\n",
       "  3805,\n",
       "  3850,\n",
       "  4924,\n",
       "  658],\n",
       " [12670, 11981, 10977, 10068, 8163, 14666, 12373],\n",
       " [2099,\n",
       "  10446,\n",
       "  12103,\n",
       "  6330,\n",
       "  10446,\n",
       "  14047,\n",
       "  13188,\n",
       "  10692,\n",
       "  2335,\n",
       "  3852,\n",
       "  7774,\n",
       "  13497,\n",
       "  925,\n",
       "  9186,\n",
       "  1476,\n",
       "  13873,\n",
       "  4389,\n",
       "  15082,\n",
       "  4959,\n",
       "  4740],\n",
       " [14666,\n",
       "  1935,\n",
       "  7024,\n",
       "  14047,\n",
       "  5291,\n",
       "  8335,\n",
       "  8830,\n",
       "  12553,\n",
       "  2106,\n",
       "  11815,\n",
       "  15068,\n",
       "  1571,\n",
       "  6423,\n",
       "  6002,\n",
       "  343,\n",
       "  7401],\n",
       " [1686, 624, 7454, 9886, 9957, 3638],\n",
       " [14146, 14146, 14146, 14146, 8510, 15637],\n",
       " [7426, 15344, 3344, 4558],\n",
       " [2904, 6001, 6002, 5370, 14873, 13830, 14511, 7041],\n",
       " [14993, 9706, 14860, 15548, 13701, 8953],\n",
       " [15462, 9706, 13498, 11587, 10668, 3231, 13161, 7004, 683],\n",
       " [14242,\n",
       "  15462,\n",
       "  3414,\n",
       "  14948,\n",
       "  11387,\n",
       "  54,\n",
       "  8667,\n",
       "  2938,\n",
       "  1022,\n",
       "  6424,\n",
       "  1862,\n",
       "  14327,\n",
       "  8140,\n",
       "  7160],\n",
       " [10165, 7774, 9909, 15691, 2123, 10832, 1964, 9938, 9781, 9453],\n",
       " [8759, 5709, 3699, 8373, 2058, 8454, 11809, 10706, 15637],\n",
       " [12994,\n",
       "  4845,\n",
       "  8373,\n",
       "  5689,\n",
       "  1236,\n",
       "  12308,\n",
       "  3633,\n",
       "  8831,\n",
       "  4930,\n",
       "  12949,\n",
       "  7454,\n",
       "  875,\n",
       "  5299,\n",
       "  10266,\n",
       "  12308,\n",
       "  11542,\n",
       "  546,\n",
       "  8756,\n",
       "  7182,\n",
       "  8143,\n",
       "  1088,\n",
       "  1252,\n",
       "  7454,\n",
       "  13291,\n",
       "  15738,\n",
       "  15064,\n",
       "  13024,\n",
       "  2640,\n",
       "  6810,\n",
       "  8788,\n",
       "  6687],\n",
       " [5284, 1720, 11160, 11160, 15070, 2741, 14427, 9201, 6695, 579],\n",
       " [3310, 12574, 9545, 5448, 14902, 3685, 508, 15293, 3995, 2253, 11300],\n",
       " [14684, 11263, 13973, 3529],\n",
       " [857, 9814, 1692, 13189],\n",
       " [9109, 9702, 3104, 5925, 1021, 5832, 14145, 6122, 2417],\n",
       " [10706, 3663],\n",
       " [12721, 15257, 3028, 9564, 14126, 10166, 9442, 2054],\n",
       " [9875, 7320, 8883, 3710, 13497],\n",
       " [13144, 7004, 15637, 10117, 15088, 14766, 6333, 13705],\n",
       " [13430, 10052, 11747, 14948],\n",
       " [13622, 13562, 11589],\n",
       " [10706, 11085, 13562, 8953],\n",
       " [1016, 8373, 9622, 4790, 8992, 3440],\n",
       " [12607, 3517, 1667, 11141, 12436, 15371],\n",
       " [11061, 7108, 10706, 3529, 3645, 13159, 5207],\n",
       " [10706, 3663, 11062],\n",
       " [7113, 1641, 15468, 14689, 12194, 12964],\n",
       " [3852,\n",
       "  7774,\n",
       "  14666,\n",
       "  12914,\n",
       "  12645,\n",
       "  1945,\n",
       "  10726,\n",
       "  12712,\n",
       "  2941,\n",
       "  653,\n",
       "  9909,\n",
       "  14343,\n",
       "  14089,\n",
       "  13355,\n",
       "  15260,\n",
       "  12812,\n",
       "  14552,\n",
       "  1279,\n",
       "  10465,\n",
       "  10442,\n",
       "  10749,\n",
       "  3850,\n",
       "  4924,\n",
       "  658],\n",
       " [1285,\n",
       "  1285,\n",
       "  3838,\n",
       "  6091,\n",
       "  1762,\n",
       "  7401,\n",
       "  7756,\n",
       "  11160,\n",
       "  11160,\n",
       "  10846,\n",
       "  3109,\n",
       "  3109,\n",
       "  5068,\n",
       "  4656,\n",
       "  1022,\n",
       "  9060,\n",
       "  279,\n",
       "  9811,\n",
       "  12481,\n",
       "  13144,\n",
       "  12005,\n",
       "  14451,\n",
       "  15538,\n",
       "  2594],\n",
       " [1562, 1103, 2741, 10816, 6956],\n",
       " [13390, 2325, 6929, 9811, 3312, 12033, 9663, 1103],\n",
       " [624,\n",
       "  12067,\n",
       "  9505,\n",
       "  3663,\n",
       "  3316,\n",
       "  9843,\n",
       "  10218,\n",
       "  14242,\n",
       "  10266,\n",
       "  4312,\n",
       "  10584,\n",
       "  10632,\n",
       "  14980,\n",
       "  11160,\n",
       "  11160,\n",
       "  5774,\n",
       "  4664,\n",
       "  9912,\n",
       "  9772,\n",
       "  8235,\n",
       "  12401,\n",
       "  6890,\n",
       "  12258,\n",
       "  14107,\n",
       "  12779,\n",
       "  1902,\n",
       "  598,\n",
       "  11159,\n",
       "  3822,\n",
       "  8668,\n",
       "  6683,\n",
       "  593,\n",
       "  12779,\n",
       "  11240,\n",
       "  732,\n",
       "  11542,\n",
       "  8896,\n",
       "  13626,\n",
       "  12162,\n",
       "  13027,\n",
       "  7342,\n",
       "  1301,\n",
       "  13015,\n",
       "  538,\n",
       "  13307,\n",
       "  13111,\n",
       "  10562,\n",
       "  5898,\n",
       "  9342,\n",
       "  11747,\n",
       "  7224,\n",
       "  11358,\n",
       "  6904,\n",
       "  3469,\n",
       "  6929,\n",
       "  9505,\n",
       "  3663,\n",
       "  14138,\n",
       "  3805,\n",
       "  15574,\n",
       "  11301,\n",
       "  2390,\n",
       "  5671,\n",
       "  2617],\n",
       " [11556, 8464, 15637, 5729, 11514, 9218, 1502, 10393, 713],\n",
       " [1596,\n",
       "  7755,\n",
       "  3353,\n",
       "  12037,\n",
       "  7454,\n",
       "  6466,\n",
       "  1064,\n",
       "  10166,\n",
       "  2556,\n",
       "  3613,\n",
       "  2108,\n",
       "  13159,\n",
       "  3414],\n",
       " [15788, 11514, 3529],\n",
       " [10706, 1629, 10706, 14948],\n",
       " [15514, 10286, 14635, 11085],\n",
       " [3414, 14948, 1204, 5175, 7655, 5559, 14948, 12813, 6944, 14065],\n",
       " [11085, 13402, 9281],\n",
       " [6895, 202, 10706],\n",
       " [10706, 9979, 13144, 8953],\n",
       " [14009, 10550, 10372, 8681, 8681, 11085, 8088, 11085, 13701],\n",
       " [10699, 5123, 15421, 10740, 3863, 1103, 7689, 9811, 7796, 15493, 2644, 1103],\n",
       " [5689,\n",
       "  1053,\n",
       "  4990,\n",
       "  14327,\n",
       "  439,\n",
       "  12559,\n",
       "  7593,\n",
       "  6927,\n",
       "  12707,\n",
       "  4354,\n",
       "  7004,\n",
       "  10166,\n",
       "  7004,\n",
       "  10166,\n",
       "  9819],\n",
       " [4225, 8953, 15064],\n",
       " [10706, 1103, 9706],\n",
       " [5705, 9660, 11085, 12371],\n",
       " [12435, 6921, 8749],\n",
       " [1972, 437, 875, 4114, 5274, 11093, 3613, 8275, 15381, 14140, 7185],\n",
       " [15706,\n",
       "  3302,\n",
       "  2956,\n",
       "  10493,\n",
       "  5461,\n",
       "  8685,\n",
       "  15670,\n",
       "  1745,\n",
       "  9650,\n",
       "  694,\n",
       "  15670,\n",
       "  15462,\n",
       "  15670,\n",
       "  1720,\n",
       "  14411,\n",
       "  15305,\n",
       "  12210,\n",
       "  14697,\n",
       "  9982,\n",
       "  1950,\n",
       "  14411,\n",
       "  1008,\n",
       "  2792,\n",
       "  13540,\n",
       "  15305],\n",
       " [13144, 12737, 12670, 6921],\n",
       " [4457, 10706, 6728, 3529, 9811, 5403, 4332],\n",
       " [140, 10924, 14692, 2941, 1788, 5466, 14816, 1854, 3507],\n",
       " [9706, 10706, 3296, 15728, 683],\n",
       " [9371, 15064, 1960, 3909, 15474, 3501, 10020, 1103],\n",
       " [3990, 14857, 13809, 8953, 519, 15633, 4527, 11305, 7004, 9910],\n",
       " [10706, 9706, 13144, 7004, 5628],\n",
       " [13159,\n",
       "  5893,\n",
       "  8217,\n",
       "  11597,\n",
       "  3990,\n",
       "  14948,\n",
       "  875,\n",
       "  14126,\n",
       "  540,\n",
       "  13807,\n",
       "  8373,\n",
       "  14948,\n",
       "  8087,\n",
       "  5250,\n",
       "  875,\n",
       "  8532],\n",
       " [12647, 10954, 12130, 2123],\n",
       " [10706, 5300, 4263],\n",
       " [13888, 14948, 6009, 14019],\n",
       " [10706, 15371, 7377, 4104],\n",
       " [9662, 4262, 9662, 3732, 9662, 5750, 3732, 7273, 3683],\n",
       " [15402, 9600, 7454],\n",
       " [7231, 6811],\n",
       " [10706, 1103],\n",
       " [15480, 10325, 3792],\n",
       " [10706, 15230, 15230, 1480],\n",
       " [8719, 12122, 10706, 3529],\n",
       " [1353, 3563, 10706, 15637, 2788, 15637],\n",
       " [15196, 5515, 15574, 6122, 2417, 15064, 10153],\n",
       " [9187, 8953, 7685, 6471],\n",
       " [11580,\n",
       "  7363,\n",
       "  3678,\n",
       "  15260,\n",
       "  5674,\n",
       "  14080,\n",
       "  8167,\n",
       "  3734,\n",
       "  12690,\n",
       "  12675,\n",
       "  13709,\n",
       "  2405,\n",
       "  736,\n",
       "  5497,\n",
       "  15342,\n",
       "  12062,\n",
       "  12130,\n",
       "  10462,\n",
       "  4748,\n",
       "  13346,\n",
       "  370,\n",
       "  2253,\n",
       "  13185,\n",
       "  6612],\n",
       " [15462, 9706, 8049, 4866, 875, 9957, 6011],\n",
       " [186,\n",
       "  3916,\n",
       "  14800,\n",
       "  5269,\n",
       "  5494,\n",
       "  14800,\n",
       "  15276,\n",
       "  4716,\n",
       "  9038,\n",
       "  14857,\n",
       "  9999,\n",
       "  12771,\n",
       "  7004,\n",
       "  7898],\n",
       " [10706, 8766, 3578, 14376],\n",
       " [15226, 6927, 8791],\n",
       " [8627, 9966, 3931, 921, 7004, 10166],\n",
       " [6095, 11268, 11153],\n",
       " [2330,\n",
       "  14948,\n",
       "  2867,\n",
       "  8723,\n",
       "  11994,\n",
       "  7429,\n",
       "  4742,\n",
       "  9594,\n",
       "  9474,\n",
       "  12400,\n",
       "  10850,\n",
       "  12914,\n",
       "  1373,\n",
       "  776,\n",
       "  12606,\n",
       "  7621,\n",
       "  13497],\n",
       " [1353,\n",
       "  3663,\n",
       "  11299,\n",
       "  5846,\n",
       "  13635,\n",
       "  3529,\n",
       "  126,\n",
       "  12423,\n",
       "  14126,\n",
       "  10020,\n",
       "  9811,\n",
       "  15462,\n",
       "  9886,\n",
       "  14922,\n",
       "  11542,\n",
       "  9762,\n",
       "  10335,\n",
       "  10110,\n",
       "  227,\n",
       "  6053,\n",
       "  3132,\n",
       "  15689],\n",
       " [7429, 13067],\n",
       " [10706, 11085, 14122],\n",
       " [1594, 13701, 10107, 14551, 15064],\n",
       " [12725, 8525, 3190, 7359, 11955],\n",
       " [11139, 6901, 994, 15484, 9966, 10216, 3773, 3663, 683, 1103],\n",
       " [10706, 15637],\n",
       " [1131, 4263, 14948, 11085, 13701],\n",
       " [13144, 6673, 9869],\n",
       " [10706, 11514, 15637],\n",
       " [12647, 15203, 10229, 417, 2253, 15281, 9248, 12194, 15082],\n",
       " [2253,\n",
       "  14922,\n",
       "  2011,\n",
       "  15180,\n",
       "  10706,\n",
       "  4263,\n",
       "  12014,\n",
       "  12130,\n",
       "  8608,\n",
       "  288,\n",
       "  11668,\n",
       "  15094,\n",
       "  14356],\n",
       " [7602, 8745, 2535, 6515, 15082, 11328],\n",
       " [5800, 5925, 8446, 8252, 4924],\n",
       " [7429, 3529, 8802, 11714, 5123, 12949],\n",
       " [10706, 10706, 8953],\n",
       " [12174, 7318, 10706],\n",
       " [8373, 11442, 6476, 2814, 7664, 14420, 5950, 7004, 683],\n",
       " [2904, 6001, 2616, 8102, 58, 10801, 7469, 9334],\n",
       " [2868, 12538, 5339, 9273, 432, 1930],\n",
       " [1953, 12907, 8974, 12514, 6804, 14500, 7962, 15081],\n",
       " [10706, 1103, 5108],\n",
       " [14894, 5578, 1949, 845, 11140],\n",
       " [15680, 10706, 14009, 10550, 15381, 12734],\n",
       " [5288, 4958, 13675, 14835, 1208, 1967, 1621, 4238],\n",
       " [9131, 2093, 11042, 11747, 5423, 8146, 1337, 1552, 3774, 11306],\n",
       " [5476, 9306, 6612, 5768, 7726, 4031, 7004, 10166],\n",
       " [5855,\n",
       "  4672,\n",
       "  5793,\n",
       "  2715,\n",
       "  15767,\n",
       "  3335,\n",
       "  10005,\n",
       "  5855,\n",
       "  875,\n",
       "  5962,\n",
       "  5855,\n",
       "  5384,\n",
       "  13373,\n",
       "  5274,\n",
       "  10195,\n",
       "  15371],\n",
       " [14585, 3852, 7774, 8750, 10446, 12567, 14499],\n",
       " [3529, 7085, 14244, 11220, 8809],\n",
       " [8468, 2921],\n",
       " [11466, 1103, 13144, 573, 13144, 2843],\n",
       " [1103, 10706, 8225],\n",
       " [8373, 12896, 15144, 6562],\n",
       " [15064, 13706, 8217, 13807, 8373, 8411, 9564, 2889, 7004, 683],\n",
       " [2880, 4021, 4174, 4835, 5846],\n",
       " [10706, 9706, 3529],\n",
       " [15371, 10706, 15371],\n",
       " [2904, 6001, 4960, 2633, 12109, 416, 14873, 2253, 5448, 15408, 381],\n",
       " [9617, 7283, 1760, 11966, 8040, 15064],\n",
       " [2904, 6001, 14863, 15525, 9165, 3922, 8673, 3177, 5025],\n",
       " [10706, 3529],\n",
       " [14948, 14299, 15728, 683],\n",
       " [2820,\n",
       "  10651,\n",
       "  13807,\n",
       "  8723,\n",
       "  1720,\n",
       "  6975,\n",
       "  15371,\n",
       "  13348,\n",
       "  4056,\n",
       "  9972,\n",
       "  2064,\n",
       "  2362,\n",
       "  7431,\n",
       "  13348,\n",
       "  10651,\n",
       "  10005,\n",
       "  10651,\n",
       "  10664],\n",
       " [14393, 11747, 2843, 3529, 10706, 15637, 9642, 11747, 2843, 3529],\n",
       " [9526, 9233, 29, 3774],\n",
       " [13144, 12005, 14119],\n",
       " [2491, 14632, 2666, 851],\n",
       " [13807,\n",
       "  15625,\n",
       "  4056,\n",
       "  9326,\n",
       "  6927,\n",
       "  14259,\n",
       "  9706,\n",
       "  875,\n",
       "  14126,\n",
       "  9519,\n",
       "  8468,\n",
       "  1418,\n",
       "  11567,\n",
       "  9706,\n",
       "  8485,\n",
       "  15245,\n",
       "  5515],\n",
       " [10165, 7774, 9909, 15691, 2123, 10832, 1964, 9938, 9781, 9453],\n",
       " [15788, 10706],\n",
       " [11085, 8088, 11085, 3862, 1918, 9706, 3529],\n",
       " [10268, 9706, 6795, 7610, 8611, 10706, 12547, 1103],\n",
       " [3485, 9060, 9159, 9060],\n",
       " [8719, 12122, 3529, 13498, 5031, 8953, 6020, 3886, 8809, 3193, 10795, 4199],\n",
       " [15173, 14948, 7019, 12972, 14948, 6513, 1353, 14403, 14577, 8601],\n",
       " [4452, 4705, 11780, 2346],\n",
       " [14558, 9706],\n",
       " [3104, 5925, 1103, 10706],\n",
       " [13446, 5931, 959, 14922],\n",
       " [15637, 10706],\n",
       " [3529, 13144, 7004, 15350, 14830],\n",
       " [10706, 9706, 15637],\n",
       " [11994, 10706, 13920],\n",
       " [10706, 3529],\n",
       " [345, 3703, 5553, 9581, 8693, 1952],\n",
       " [11562, 15637, 2548],\n",
       " [15580, 89],\n",
       " [10706, 5425, 14381],\n",
       " [10706, 9604, 9706],\n",
       " [15738, 9159, 13769, 9928, 11521, 2163, 1496],\n",
       " [14393, 8911, 7898, 7004, 12813],\n",
       " [8501, 10706, 14948],\n",
       " [15151, 10268, 9706],\n",
       " [3353, 3857, 13918, 12758],\n",
       " [1496, 14830, 11145, 13561, 6913, 6300],\n",
       " [6921, 6088, 1469],\n",
       " [8988,\n",
       "  4265,\n",
       "  11861,\n",
       "  2640,\n",
       "  4638,\n",
       "  13183,\n",
       "  2163,\n",
       "  3521,\n",
       "  11521,\n",
       "  9253,\n",
       "  2354,\n",
       "  5449,\n",
       "  1285,\n",
       "  1366,\n",
       "  5247,\n",
       "  11035,\n",
       "  5238,\n",
       "  9677,\n",
       "  10501,\n",
       "  3241,\n",
       "  14994,\n",
       "  2652,\n",
       "  7852,\n",
       "  1880,\n",
       "  3319,\n",
       "  1930,\n",
       "  7483,\n",
       "  348,\n",
       "  2359,\n",
       "  7120,\n",
       "  5439,\n",
       "  2553,\n",
       "  7183,\n",
       "  8170,\n",
       "  2013,\n",
       "  6282,\n",
       "  5033,\n",
       "  11333,\n",
       "  8360,\n",
       "  2755,\n",
       "  4470,\n",
       "  11961,\n",
       "  13846,\n",
       "  10996,\n",
       "  14726,\n",
       "  9998,\n",
       "  4838,\n",
       "  10922,\n",
       "  11945,\n",
       "  13723,\n",
       "  10424,\n",
       "  3720,\n",
       "  1702,\n",
       "  1169,\n",
       "  7224,\n",
       "  15407,\n",
       "  6305,\n",
       "  8857,\n",
       "  12429,\n",
       "  14201,\n",
       "  5791],\n",
       " [12827, 15226, 2755, 10266],\n",
       " [3925, 7518, 13456],\n",
       " [6895, 7396, 10706],\n",
       " [2595, 3310, 10259, 15710],\n",
       " [708, 7835, 10436],\n",
       " [2450,\n",
       "  7450,\n",
       "  12436,\n",
       "  1166,\n",
       "  11791,\n",
       "  3922,\n",
       "  14042,\n",
       "  7121,\n",
       "  8484,\n",
       "  7085,\n",
       "  10922,\n",
       "  10822,\n",
       "  6455,\n",
       "  4580,\n",
       "  8831,\n",
       "  4932,\n",
       "  1191,\n",
       "  2599,\n",
       "  11082],\n",
       " [3104, 7608],\n",
       " [4073, 11263, 1510, 12558, 4799],\n",
       " [5536, 8953, 14532],\n",
       " [12574, 2697, 13213, 4563, 12181, 13582, 9852, 4454, 13355, 3774],\n",
       " [3498, 14584, 14697, 3529],\n",
       " [11585, 14948],\n",
       " [2253, 12677, 9604, 7501, 5392, 12725, 254, 7496, 12737, 7106, 15362],\n",
       " [2042, 4387, 2042, 4387, 5139],\n",
       " [5966,\n",
       "  2540,\n",
       "  2640,\n",
       "  10216,\n",
       "  3062,\n",
       "  683,\n",
       "  1022,\n",
       "  8217,\n",
       "  11949,\n",
       "  13159,\n",
       "  10224,\n",
       "  13159,\n",
       "  5785,\n",
       "  1021,\n",
       "  1720,\n",
       "  7576],\n",
       " [5714, 15766, 1390, 9788, 5800, 7914, 14873, 14103, 591, 3264, 1107, 9401],\n",
       " [15788, 3825, 7471],\n",
       " [10706, 8953, 15064, 7004],\n",
       " [15479, 15122, 15462, 3773, 11141, 1170, 3529, 8373, 344, 875, 14126],\n",
       " [3529, 14244, 11220, 5465],\n",
       " [15496, 2453, 2216, 428],\n",
       " [15788, 2584, 3529],\n",
       " [7429, 9706],\n",
       " [9154, 4541, 6931, 6320, 7401, 14290, 12549],\n",
       " [15767, 11638, 9517, 458],\n",
       " [3852, 6693, 5844, 2219],\n",
       " [6687, 1930, 2253, 11955],\n",
       " [2253, 11955, 3072, 15235, 254],\n",
       " [14690, 4554, 15719],\n",
       " [14242,\n",
       "  6785,\n",
       "  4150,\n",
       "  1260,\n",
       "  634,\n",
       "  694,\n",
       "  11760,\n",
       "  4774,\n",
       "  3625,\n",
       "  15476,\n",
       "  6980,\n",
       "  11511,\n",
       "  13931,\n",
       "  10373,\n",
       "  694,\n",
       "  9153,\n",
       "  8827,\n",
       "  15105,\n",
       "  12205,\n",
       "  11511],\n",
       " [8373, 11966, 10881, 6909, 15542],\n",
       " [3943, 2005, 1103, 13814],\n",
       " [15637, 6907],\n",
       " [12737,\n",
       "  3344,\n",
       "  5732,\n",
       "  15635,\n",
       "  5732,\n",
       "  15481,\n",
       "  3072,\n",
       "  361,\n",
       "  10749,\n",
       "  1442,\n",
       "  13448,\n",
       "  9296,\n",
       "  2253,\n",
       "  12194],\n",
       " [8431, 9706, 3529],\n",
       " [2904,\n",
       "  6001,\n",
       "  11387,\n",
       "  2245,\n",
       "  12492,\n",
       "  1194,\n",
       "  5546,\n",
       "  5448,\n",
       "  6301,\n",
       "  3098,\n",
       "  2889,\n",
       "  959,\n",
       "  11970,\n",
       "  3159,\n",
       "  14873,\n",
       "  3276],\n",
       " [5248, 11138, 2233, 5905, 14106, 7593, 2253],\n",
       " [6510, 2936, 11387, 3477, 11699, 15428, 10180, 11699, 6348, 14589, 12675],\n",
       " [6921, 8340, 12795, 10952],\n",
       " [8988, 4265, 1464, 2640, 4638, 13183],\n",
       " [9371, 5393, 5501, 13024],\n",
       " [5529, 14107, 2332, 9141],\n",
       " [224, 9206, 10775, 11542, 10699, 2129, 14837],\n",
       " [6890,\n",
       "  1058,\n",
       "  3685,\n",
       "  12671,\n",
       "  4295,\n",
       "  2468,\n",
       "  15024,\n",
       "  10541,\n",
       "  8592,\n",
       "  9798,\n",
       "  14106,\n",
       "  11727,\n",
       "  7211,\n",
       "  5870,\n",
       "  6890,\n",
       "  8360,\n",
       "  11466],\n",
       " [8719, 12122, 14650, 3008, 10760],\n",
       " [14061, 12194, 15281],\n",
       " [1951, 12660, 15718],\n",
       " [1103,\n",
       "  3874,\n",
       "  14126,\n",
       "  683,\n",
       "  1103,\n",
       "  2034,\n",
       "  2681,\n",
       "  12306,\n",
       "  7451,\n",
       "  10216,\n",
       "  8809,\n",
       "  1302,\n",
       "  683,\n",
       "  1103,\n",
       "  1596,\n",
       "  5403,\n",
       "  13561,\n",
       "  4199,\n",
       "  7223,\n",
       "  6785,\n",
       "  3353,\n",
       "  10266],\n",
       " [6109, 4650, 11163],\n",
       " [14298, 2046, 15303, 5297, 6927, 14948, 875, 3006, 9941, 2048, 14298],\n",
       " [12994,\n",
       "  4845,\n",
       "  8373,\n",
       "  10561,\n",
       "  12544,\n",
       "  5957,\n",
       "  1523,\n",
       "  9917,\n",
       "  10500,\n",
       "  12420,\n",
       "  7888,\n",
       "  278,\n",
       "  2548,\n",
       "  6215,\n",
       "  5552,\n",
       "  13946],\n",
       " [11397, 13144, 11558, 10706],\n",
       " [12018, 14948, 2938, 3990, 9886, 2390],\n",
       " [708, 7982, 1089, 8792, 3529, 12894, 8391, 1686, 9600],\n",
       " [15788, 12813],\n",
       " [13456, 1286, 11765],\n",
       " [6948, 7763, 7072, 3663, 7239],\n",
       " [186, 9706],\n",
       " [9474,\n",
       "  10595,\n",
       "  8819,\n",
       "  2482,\n",
       "  14355,\n",
       "  10919,\n",
       "  8819,\n",
       "  1616,\n",
       "  12914,\n",
       "  6171,\n",
       "  15164,\n",
       "  14527,\n",
       "  1983,\n",
       "  11955,\n",
       "  9799,\n",
       "  2312,\n",
       "  15719,\n",
       "  14073],\n",
       " [1916, 8685, 3805, 7004, 2219, 1972, 4643, 9391],\n",
       " [13144, 12005],\n",
       " [15765, 6508, 4784, 6634, 6662, 2348, 5896],\n",
       " [6763, 10339, 6259, 1671, 11153, 2625],\n",
       " [8532, 13931, 6665, 4778, 8092],\n",
       " [7689, 10706, 1103],\n",
       " [727, 2677, 1499],\n",
       " [5711, 10706, 8766, 1103],\n",
       " [11858, 211, 13508, 15637],\n",
       " [11468, 12047, 14166, 12047, 12593, 3833, 10397, 8820],\n",
       " [14666, 8140, 9119, 6612, 7899, 11731],\n",
       " [14766, 7269, 3104, 5925],\n",
       " [12479, 9117, 11542, 14912],\n",
       " [5144, 4158, 10130],\n",
       " [10706, 15637, 11528],\n",
       " [6818, 10145, 14800, 2163, 12775, 466],\n",
       " [11085, 8953],\n",
       " [7136, 10195, 5671, 13290, 7007, 8726],\n",
       " [14584, 15350, 6733],\n",
       " [10706, 14948, 15637],\n",
       " [4502, 15122, 8515, 8998, 8840, 2157, 11664, 12150],\n",
       " [10706, 15637, 11387, 13069, 7417, 4543],\n",
       " [13562, 8953, 196, 4355, 1591, 15542, 12638, 1021],\n",
       " [6036, 6895, 12062, 14948, 11542],\n",
       " [2656, 10954, 1085, 7993, 8271, 10283, 1021],\n",
       " [10850, 5804, 10720, 14715, 14647],\n",
       " [4490, 11858, 5571, 15637, 14376],\n",
       " [5113, 9284, 3526, 10706, 14948, 1131],\n",
       " [6526, 3619, 5417, 7024, 4998, 11981, 10977],\n",
       " [9084, 3264, 3078, 2407, 7672, 14230, 9253],\n",
       " [10706,\n",
       "  5534,\n",
       "  1280,\n",
       "  15088,\n",
       "  5225,\n",
       "  14558,\n",
       "  7454,\n",
       "  2253,\n",
       "  3306,\n",
       "  6528,\n",
       "  9996,\n",
       "  12675,\n",
       "  15547,\n",
       "  6456,\n",
       "  15409,\n",
       "  1289,\n",
       "  7742,\n",
       "  14835,\n",
       "  12435,\n",
       "  3414,\n",
       "  1740],\n",
       " [1951, 2681, 1170, 2972, 3751, 3929, 14940, 9376],\n",
       " [9344,\n",
       "  9344,\n",
       "  13484,\n",
       "  15646,\n",
       "  14922,\n",
       "  683,\n",
       "  14859,\n",
       "  1367,\n",
       "  8940,\n",
       "  12301,\n",
       "  5869,\n",
       "  15114,\n",
       "  683,\n",
       "  281,\n",
       "  13771,\n",
       "  14859],\n",
       " [2987, 3529, 3217, 11858, 12815, 8879, 11858, 9019, 8738, 2987, 3529],\n",
       " [7396, 1366, 6240, 13832, 9627, 8694],\n",
       " [7955, 1317, 10706],\n",
       " [14437, 15637, 14912, 11673, 8373, 11966, 11327, 5389],\n",
       " [345, 5553, 7341, 6122, 2417, 15064],\n",
       " [7085, 8333, 2839, 10296, 14857, 15788],\n",
       " [5575, 8243, 11587, 9604, 780],\n",
       " [14801, 14922, 2301, 15371, 9620, 12237],\n",
       " [4888],\n",
       " [11072,\n",
       "  2253,\n",
       "  950,\n",
       "  5056,\n",
       "  10446,\n",
       "  1289,\n",
       "  12159,\n",
       "  5413,\n",
       "  375,\n",
       "  15691,\n",
       "  12812,\n",
       "  13592,\n",
       "  2525,\n",
       "  9346,\n",
       "  1049,\n",
       "  12401,\n",
       "  14081,\n",
       "  5671,\n",
       "  2253,\n",
       "  6970,\n",
       "  10605,\n",
       "  11443,\n",
       "  15704,\n",
       "  11658,\n",
       "  9287,\n",
       "  8730,\n",
       "  2795,\n",
       "  4350,\n",
       "  3075,\n",
       "  8085],\n",
       " [1103,\n",
       "  3773,\n",
       "  11141,\n",
       "  14242,\n",
       "  4541,\n",
       "  1916,\n",
       "  12717,\n",
       "  14826,\n",
       "  13410,\n",
       "  7923,\n",
       "  1568,\n",
       "  13410,\n",
       "  476,\n",
       "  10996,\n",
       "  10446],\n",
       " [7236, 2013, 12186, 164, 9959, 8216, 13355, 3774],\n",
       " [12065, 13819, 8022, 15371, 10442, 15456, 10706],\n",
       " [12914, 11955, 11147, 12824, 5965, 3850, 4924, 658],\n",
       " [634, 14948, 1467, 1103],\n",
       " [71, 2013, 6282, 36],\n",
       " [12005, 9929, 3529],\n",
       " [13144, 7004, 9929],\n",
       " [8684, 12957, 13196, 8883, 13355, 3774],\n",
       " [10245, 3703, 11970, 12498, 12869, 11786, 2611, 11253, 13986, 11761],\n",
       " [12606, 920, 13717, 51],\n",
       " [15637,\n",
       "  8886,\n",
       "  6901,\n",
       "  13069,\n",
       "  3132,\n",
       "  1481,\n",
       "  2453,\n",
       "  13840,\n",
       "  2453,\n",
       "  4414,\n",
       "  6901,\n",
       "  3132,\n",
       "  12549,\n",
       "  11571,\n",
       "  3929,\n",
       "  5603],\n",
       " [8953, 5355],\n",
       " [11523, 13701],\n",
       " [9852, 3852, 7774, 10446],\n",
       " [10653, 10691, 10861, 4579, 1191],\n",
       " [10706, 15637, 3929, 6763, 5920, 2476, 13108, 15637, 7108, 12005, 1103],\n",
       " [10706, 7944, 3257, 2502, 11973, 14168, 11602, 8252],\n",
       " [3519, 7336, 9306, 2090, 10701, 9706],\n",
       " [14666,\n",
       "  3825,\n",
       "  8913,\n",
       "  14047,\n",
       "  14089,\n",
       "  10462,\n",
       "  6837,\n",
       "  14850,\n",
       "  5674,\n",
       "  9329,\n",
       "  8631,\n",
       "  14519,\n",
       "  14840,\n",
       "  12243,\n",
       "  9120,\n",
       "  5493,\n",
       "  2910,\n",
       "  6674,\n",
       "  8371,\n",
       "  2910,\n",
       "  6674,\n",
       "  8137,\n",
       "  9907,\n",
       "  13610],\n",
       " [15742, 3529],\n",
       " [9451, 13562, 8953],\n",
       " [14948, 12193, 683, 5465],\n",
       " [12005, 13701],\n",
       " [13807, 15637, 6662, 6090, 2560],\n",
       " [7265, 9706, 15193],\n",
       " [3529, 10706, 3529, 10268, 14830],\n",
       " [10706, 3529, 8107, 14009, 10550, 4172, 11747, 4572],\n",
       " [7265, 5425, 2880],\n",
       " [12062, 6995, 11521],\n",
       " [284, 4345, 4208],\n",
       " [9493, 9281, 5097, 15064, 7004],\n",
       " [5126, 15637, 14252, 7449, 14795, 4936],\n",
       " [12725, 8856, 6970, 3040, 10446, 1219, 7672],\n",
       " [10706, 9763, 5925, 1103],\n",
       " [9919, 7004, 556],\n",
       " [9568, 3529, 1042, 13144, 8802, 14465, 3063],\n",
       " [12725, 254, 9176],\n",
       " [6818, 10145, 14800, 6825],\n",
       " [9852, 9970, 3963],\n",
       " [6921],\n",
       " [7410, 8953, 10387, 1103],\n",
       " [14666,\n",
       "  6330,\n",
       "  10446,\n",
       "  10321,\n",
       "  8482,\n",
       "  3219,\n",
       "  12544,\n",
       "  9325,\n",
       "  11120,\n",
       "  12675,\n",
       "  12694,\n",
       "  8656,\n",
       "  1351,\n",
       "  5135,\n",
       "  10295,\n",
       "  7377],\n",
       " [14191, 12648, 7004, 15313, 12648],\n",
       " [1943, 7004, 12443],\n",
       " [6383, 12914, 7925, 15000],\n",
       " [13765,\n",
       "  483,\n",
       "  6496,\n",
       "  3190,\n",
       "  483,\n",
       "  15035,\n",
       "  9325,\n",
       "  2709,\n",
       "  10308,\n",
       "  11933,\n",
       "  8513,\n",
       "  5768,\n",
       "  11933],\n",
       " [12795,\n",
       "  15637,\n",
       "  10340,\n",
       "  1204,\n",
       "  12928,\n",
       "  13467,\n",
       "  3663,\n",
       "  4616,\n",
       "  8685,\n",
       "  4930,\n",
       "  4354,\n",
       "  6512,\n",
       "  4572,\n",
       "  12900,\n",
       "  10706,\n",
       "  1972,\n",
       "  4354,\n",
       "  3663,\n",
       "  14520,\n",
       "  7425],\n",
       " [1103, 13938, 14437, 12085, 11021, 1103],\n",
       " [10373, 13885, 1103, 116, 11599, 3935, 1103, 440, 4691, 5288, 1161],\n",
       " [9852, 7113, 10530, 11522, 2767, 6209, 10419, 3825, 5477, 3850, 10419, 3825],\n",
       " [10706, 3025, 7471],\n",
       " [10165, 7774, 9909, 15691, 2123, 10832, 1964, 9938, 9781, 9453],\n",
       " [6272, 4664, 4449, 11994, 2535],\n",
       " [1351,\n",
       "  14666,\n",
       "  11046,\n",
       "  7979,\n",
       "  7231,\n",
       "  1695,\n",
       "  261,\n",
       "  8877,\n",
       "  13269,\n",
       "  10686,\n",
       "  9459,\n",
       "  75,\n",
       "  14089,\n",
       "  5870],\n",
       " [3529, 10706],\n",
       " [12771, 7004, 9371, 5553, 9371, 13159],\n",
       " [6831],\n",
       " [10706,\n",
       "  3529,\n",
       "  598,\n",
       "  14009,\n",
       "  10550,\n",
       "  608,\n",
       "  10782,\n",
       "  11189,\n",
       "  13807,\n",
       "  7456,\n",
       "  14475,\n",
       "  1279,\n",
       "  5523,\n",
       "  13807,\n",
       "  9775,\n",
       "  4332,\n",
       "  14945,\n",
       "  15738,\n",
       "  8418,\n",
       "  5123,\n",
       "  11542,\n",
       "  1887,\n",
       "  7201],\n",
       " [10544, 1936, 9706],\n",
       " [11424, 9706, 7004, 8338],\n",
       " [10706, 9706],\n",
       " [4230, 15245, 5096],\n",
       " [3254,\n",
       "  2868,\n",
       "  11006,\n",
       "  1773,\n",
       "  12140,\n",
       "  4135,\n",
       "  7799,\n",
       "  11503,\n",
       "  7082,\n",
       "  2056,\n",
       "  14703,\n",
       "  7816,\n",
       "  6228,\n",
       "  14991,\n",
       "  12914,\n",
       "  5354],\n",
       " [14948, 15476, 2938, 116, 4920, 15728, 12921, 10757],\n",
       " [71,\n",
       "  312,\n",
       "  7574,\n",
       "  4035,\n",
       "  8793,\n",
       "  6847,\n",
       "  10255,\n",
       "  865,\n",
       "  6702,\n",
       "  10405,\n",
       "  9630,\n",
       "  13565,\n",
       "  2678,\n",
       "  9096,\n",
       "  8221,\n",
       "  9630],\n",
       " [3264, 4614, 3012, 11565, 12426],\n",
       " [71, 71, 12067, 1921],\n",
       " [8371,\n",
       "  13717,\n",
       "  14922,\n",
       "  8352,\n",
       "  3086,\n",
       "  12886,\n",
       "  3510,\n",
       "  11092,\n",
       "  2123,\n",
       "  8052,\n",
       "  2590,\n",
       "  13662,\n",
       "  5039,\n",
       "  15416,\n",
       "  10026,\n",
       "  12675,\n",
       "  5012,\n",
       "  168,\n",
       "  12353,\n",
       "  9176,\n",
       "  5671],\n",
       " [10706, 3529],\n",
       " [5476, 3957, 14888, 10090, 10801, 7004, 683],\n",
       " [6326, 1021, 11472, 15064],\n",
       " [10706, 13944],\n",
       " [7437, 4273, 8685, 7162, 8940],\n",
       " [1591, 2602, 6944],\n",
       " [191,\n",
       "  3825,\n",
       "  202,\n",
       "  11779,\n",
       "  2741,\n",
       "  1366,\n",
       "  10296,\n",
       "  11127,\n",
       "  12035,\n",
       "  1183,\n",
       "  8792,\n",
       "  13352,\n",
       "  11295,\n",
       "  4354,\n",
       "  8552,\n",
       "  10335,\n",
       "  4107,\n",
       "  5627,\n",
       "  1720,\n",
       "  4598,\n",
       "  6927,\n",
       "  8685,\n",
       "  4924,\n",
       "  13245,\n",
       "  3662,\n",
       "  3773,\n",
       "  4376,\n",
       "  2390,\n",
       "  7640,\n",
       "  2092,\n",
       "  9734,\n",
       "  6994,\n",
       "  1356],\n",
       " [4157, 15122, 694, 10822, 3529],\n",
       " [10140, 4043, 14998, 4422, 3663, 1686, 4052, 7453],\n",
       " [10706, 12700, 15637],\n",
       " [15762, 15637, 5501],\n",
       " [5738,\n",
       "  4829,\n",
       "  11516,\n",
       "  1214,\n",
       "  12587,\n",
       "  21,\n",
       "  14091,\n",
       "  13213,\n",
       "  14948,\n",
       "  1697,\n",
       "  3493,\n",
       "  12587,\n",
       "  2880,\n",
       "  15439,\n",
       "  13498,\n",
       "  9732,\n",
       "  15381,\n",
       "  1172],\n",
       " [2880, 15637, 9558, 10110, 8333, 12949, 8723, 7085, 6455],\n",
       " [10165, 7774, 9909, 15691, 2123, 10832, 1964, 9938, 9781, 9453],\n",
       " [6494,\n",
       "  7081,\n",
       "  6887,\n",
       "  12513,\n",
       "  15508,\n",
       "  10910,\n",
       "  7277,\n",
       "  10737,\n",
       "  13823,\n",
       "  8642,\n",
       "  4909,\n",
       "  5123,\n",
       "  2525,\n",
       "  13023,\n",
       "  755,\n",
       "  2525,\n",
       "  10627,\n",
       "  3383,\n",
       "  13860,\n",
       "  2093,\n",
       "  14630],\n",
       " [9278, 682, 9563, 6512, 13585, 773],\n",
       " [11521, 14948, 6332, 15462, 4354, 14948, 9453, 7959],\n",
       " [1427, 12323],\n",
       " [10281,\n",
       "  5009,\n",
       "  8462,\n",
       "  12130,\n",
       "  2235,\n",
       "  11719,\n",
       "  2525,\n",
       "  11565,\n",
       "  6435,\n",
       "  4205,\n",
       "  15794,\n",
       "  11140,\n",
       "  12728,\n",
       "  1254,\n",
       "  10286,\n",
       "  6805,\n",
       "  1246,\n",
       "  1908,\n",
       "  758,\n",
       "  14666,\n",
       "  2264,\n",
       "  9324,\n",
       "  7514,\n",
       "  1662,\n",
       "  2525,\n",
       "  337,\n",
       "  3107,\n",
       "  7014,\n",
       "  3462,\n",
       "  12879,\n",
       "  13205,\n",
       "  13363,\n",
       "  12431,\n",
       "  11486],\n",
       " [71, 2013, 15564, 1858],\n",
       " [3990, 281, 12075, 12084, 4050, 14253, 5860, 14444, 8430],\n",
       " [1496,\n",
       "  3353,\n",
       "  5233,\n",
       "  2938,\n",
       "  594,\n",
       "  9732,\n",
       "  3063,\n",
       "  594,\n",
       "  11796,\n",
       "  14948,\n",
       "  13024,\n",
       "  4325,\n",
       "  875,\n",
       "  2642,\n",
       "  8140,\n",
       "  2458,\n",
       "  9,\n",
       "  12551,\n",
       "  10346,\n",
       "  5883,\n",
       "  13768,\n",
       "  11542,\n",
       "  6512,\n",
       "  4796,\n",
       "  1743,\n",
       "  10159,\n",
       "  12240,\n",
       "  9732,\n",
       "  288],\n",
       " [186, 14948, 1021, 14948, 8373],\n",
       " [11955, 15627, 8950, 15635, 12725, 6120, 1930],\n",
       " [6528, 1078, 13565, 15637],\n",
       " [9852, 12725, 254],\n",
       " [7026, 7842, 9706, 2889, 7004, 10166],\n",
       " [8532, 14290, 683],\n",
       " [5703, 6467, 880, 14299, 11306],\n",
       " [14009,\n",
       "  10550,\n",
       "  12587,\n",
       "  3232,\n",
       "  6880,\n",
       "  7451,\n",
       "  343,\n",
       "  3773,\n",
       "  3663,\n",
       "  683,\n",
       "  15371,\n",
       "  10706,\n",
       "  13947,\n",
       "  10119],\n",
       " [9763, 11768, 5925, 12549, 4263, 7004],\n",
       " [2904, 6001, 2245, 7032],\n",
       " [11528, 11351, 8085],\n",
       " [12194, 8922, 2172, 14767, 3005],\n",
       " [5213, 8130, 3498],\n",
       " [1951, 4342, 14065, 1799, 12512, 8979],\n",
       " [15788, 3529],\n",
       " [9396, 11959, 13067, 6909, 10171],\n",
       " [10446, 14253, 9706, 1261, 13183],\n",
       " [3780, 15637, 13548, 6234, 4017, 4476],\n",
       " [10706, 11514, 1103],\n",
       " [8652, 3398, 11758, 9204, 8407],\n",
       " [8759,\n",
       "  5424,\n",
       "  15602,\n",
       "  1124,\n",
       "  7326,\n",
       "  3732,\n",
       "  10927,\n",
       "  1698,\n",
       "  2006,\n",
       "  12914,\n",
       "  1351,\n",
       "  8367,\n",
       "  6330,\n",
       "  2099,\n",
       "  1085,\n",
       "  14955,\n",
       "  3852,\n",
       "  7774,\n",
       "  14609,\n",
       "  9994,\n",
       "  11910,\n",
       "  10028,\n",
       "  13159,\n",
       "  11396,\n",
       "  1930,\n",
       "  5175,\n",
       "  10873,\n",
       "  34,\n",
       "  1351,\n",
       "  3338,\n",
       "  5388,\n",
       "  12886],\n",
       " [5349, 13171, 6901, 10969, 8941, 11510],\n",
       " [3529, 10706, 10657],\n",
       " [14630, 7257],\n",
       " [9423,\n",
       "  2622,\n",
       "  12180,\n",
       "  95,\n",
       "  323,\n",
       "  6896,\n",
       "  13133,\n",
       "  7456,\n",
       "  3941,\n",
       "  12000,\n",
       "  130,\n",
       "  1585,\n",
       "  13574,\n",
       "  323,\n",
       "  10110,\n",
       "  10493,\n",
       "  11092,\n",
       "  3944,\n",
       "  13157,\n",
       "  2885,\n",
       "  7452,\n",
       "  1431,\n",
       "  11258,\n",
       "  12363,\n",
       "  3962,\n",
       "  11287,\n",
       "  8600,\n",
       "  9314,\n",
       "  95,\n",
       "  10110,\n",
       "  3822,\n",
       "  5560,\n",
       "  8685,\n",
       "  6896,\n",
       "  4167,\n",
       "  95,\n",
       "  46,\n",
       "  9096,\n",
       "  12722,\n",
       "  12288,\n",
       "  9519],\n",
       " [6023, 950, 4030, 5509, 3529],\n",
       " [4608,\n",
       "  9197,\n",
       "  13024,\n",
       "  13807,\n",
       "  2013,\n",
       "  2622,\n",
       "  7326,\n",
       "  9163,\n",
       "  9197,\n",
       "  13024,\n",
       "  2992,\n",
       "  12247,\n",
       "  10737,\n",
       "  14198,\n",
       "  15371],\n",
       " [8445, 10706, 1103],\n",
       " [6909, 13158, 5476],\n",
       " [11006, 1546, 3490, 13128, 1611],\n",
       " [1686, 8980, 11994, 11542, 285, 13192, 13352, 12949],\n",
       " [14857, 7742, 3405, 10446, 7672, 4066],\n",
       " [12323, 6634, 11137, 14948, 2157, 2045, 15616, 218, 4541, 14338],\n",
       " [12914, 10706],\n",
       " [1385, 1385, 12416, 5827, 4274, 1170, 7756],\n",
       " [89, 13159, 7004, 1915],\n",
       " [4457, 15637, 9706, 11409, 1686, 9706, 2938, 11409, 8334],\n",
       " [3362, 9159, 8373, 3150, 13576, 15479, 2401],\n",
       " [9131, 7224, 1351, 6404, 12505, 263, 10701, 827, 12130, 14106, 5552, 9419],\n",
       " [3260, 13913, 13396, 2105],\n",
       " [13944, 9622, 1204, 5343, 14290, 2708, 6463, 683, 1103],\n",
       " [15728,\n",
       "  9929,\n",
       "  7004,\n",
       "  3844,\n",
       "  14948,\n",
       "  11058,\n",
       "  6763,\n",
       "  4711,\n",
       "  4421,\n",
       "  14359,\n",
       "  8355,\n",
       "  5472,\n",
       "  12209],\n",
       " [7283, 202, 10355, 13880, 9171, 4930, 6752, 713, 598],\n",
       " [9437, 14800, 8471, 12375, 9497],\n",
       " [2245, 11273, 4592, 15082],\n",
       " [14529, 4846, 1103, 9882, 7004],\n",
       " [2253, 14089, 13983, 2253, 2595, 15509, 11054, 758, 10417, 1225, 4272],\n",
       " [71, 2013, 6282, 12194, 4454, 13355, 3774],\n",
       " [6289, 11642, 11948, 7004, 683],\n",
       " [11858, 9706, 8425, 5343],\n",
       " [1983, 14609, 10726, 71, 9084, 2253, 13714, 10528, 7024, 8371, 12725, 7231],\n",
       " [13280, 9548],\n",
       " [15762, 8373, 8391],\n",
       " [1341, 9281, 15064, 12117, 683],\n",
       " [4888],\n",
       " [10706, 2963, 4263],\n",
       " [6122, 2938, 6512, 15637, 3828, 10833, 2115, 7406, 1418],\n",
       " [3846, 14584, 5925, 8711, 14374],\n",
       " [547,\n",
       "  14338,\n",
       "  7283,\n",
       "  11459,\n",
       "  560,\n",
       "  8509,\n",
       "  285,\n",
       "  12147,\n",
       "  12880,\n",
       "  4283,\n",
       "  9775,\n",
       "  14575,\n",
       "  13757,\n",
       "  15353,\n",
       "  11988,\n",
       "  12829],\n",
       " [734, 2741, 4778, 532],\n",
       " [12159, 3807, 10781, 10446, 11565, 2123, 1003],\n",
       " [5425, 11591],\n",
       " [13050, 1021, 4224, 3909, 15064],\n",
       " [3817, 5582, 14009, 10550, 5966, 5312, 7073, 4277, 12319],\n",
       " [15637, 13807, 2344],\n",
       " [13202, 12005, 7770],\n",
       " [13564, 1407, 15637],\n",
       " [1562, 14338, 7283, 9930, 3529],\n",
       " [13159, 10921],\n",
       " [2904, 6001, 9165, 9401],\n",
       " [10706, 14860, 12005, 9929, 8373],\n",
       " [3252, 4846, 11904, 6037, 7480],\n",
       " [1783, 9247, 5647, 9084, 1663],\n",
       " [15788, 12112, 7004, 7493],\n",
       " [9852, 10997],\n",
       " [13562, 8953, 14126, 3886, 12151, 6606, 4342],\n",
       " [284,\n",
       "  15637,\n",
       "  2536,\n",
       "  11787,\n",
       "  9811,\n",
       "  4572,\n",
       "  8370,\n",
       "  3456,\n",
       "  13001,\n",
       "  13807,\n",
       "  2013,\n",
       "  5741,\n",
       "  10811,\n",
       "  11209,\n",
       "  4572,\n",
       "  8370,\n",
       "  15637],\n",
       " [1443,\n",
       "  5689,\n",
       "  10530,\n",
       "  5689,\n",
       "  14948,\n",
       "  9017,\n",
       "  9755,\n",
       "  5689,\n",
       "  566,\n",
       "  2077,\n",
       "  13807,\n",
       "  3353,\n",
       "  2157,\n",
       "  12931,\n",
       "  11994,\n",
       "  12161,\n",
       "  1720,\n",
       "  3189,\n",
       "  89,\n",
       "  14948,\n",
       "  11547,\n",
       "  5986,\n",
       "  10448,\n",
       "  8705,\n",
       "  9326],\n",
       " [10706, 1103],\n",
       " [15082, 9165, 8819, 7224, 5768, 7761, 12602, 12455],\n",
       " [13902, 2882, 15637],\n",
       " [13633, 6714, 7193, 13715, 3963, 14792, 5050, 1317, 7891, 12410],\n",
       " [6921, 8373, 14941, 8753, 2345, 3683, 285],\n",
       " [5689, 3560, 13548, 7320],\n",
       " [6595, 9186],\n",
       " [15082, 10281, 11717, 11114],\n",
       " [10446, 13531, 14666, 14334, 1351],\n",
       " [14571, 7283],\n",
       " [6514,\n",
       "  7292,\n",
       "  1964,\n",
       "  13293,\n",
       "  344,\n",
       "  1204,\n",
       "  12014,\n",
       "  5508,\n",
       "  931,\n",
       "  1301,\n",
       "  7055,\n",
       "  12281,\n",
       "  850,\n",
       "  9505,\n",
       "  5031,\n",
       "  12029,\n",
       "  11638,\n",
       "  14948,\n",
       "  5253,\n",
       "  14948,\n",
       "  683],\n",
       " [8559, 13067],\n",
       " [13303, 6239, 6022, 14141, 50, 14727],\n",
       " [6831, 4338, 697],\n",
       " [7560, 4637, 5818, 3190, 4205, 2593, 2160, 4878],\n",
       " [10706, 15637, 2548],\n",
       " [10490, 3025, 10706],\n",
       " [89],\n",
       " [15462, 3005, 6901, 4457, 4457, 4593, 3529],\n",
       " [7410, 15064, 7004],\n",
       " [13807, 13389, 12005, 12813, 10296, 14948, 2938, 8468, 6429],\n",
       " [1686,\n",
       "  1799,\n",
       "  3270,\n",
       "  6823,\n",
       "  15462,\n",
       "  1414,\n",
       "  6287,\n",
       "  8436,\n",
       "  1720,\n",
       "  13203,\n",
       "  7928,\n",
       "  7965,\n",
       "  1103,\n",
       "  5950,\n",
       "  7004,\n",
       "  683],\n",
       " [6943, 6745],\n",
       " [12132, 7241, 3062, 12423, 2288, 14536, 10832, 8649, 9159, 634, 2502],\n",
       " [9763, 1103, 13159, 7004],\n",
       " [12771, 7004, 11833, 14948],\n",
       " [10388, 14106, 14299],\n",
       " [9763, 13159, 15525],\n",
       " [6921, 11902, 5261],\n",
       " [3038, 5207, 10706, 11085, 1845],\n",
       " [10706, 4568, 6380],\n",
       " [634, 2760, 8373, 8572, 1964],\n",
       " [13548,\n",
       "  7454,\n",
       "  799,\n",
       "  3795,\n",
       "  8728,\n",
       "  7423,\n",
       "  1916,\n",
       "  9523,\n",
       "  3446,\n",
       "  683,\n",
       "  6927,\n",
       "  9824,\n",
       "  9292,\n",
       "  11833,\n",
       "  2285,\n",
       "  10512,\n",
       "  14515],\n",
       " [14201,\n",
       "  13720,\n",
       "  937,\n",
       "  3173,\n",
       "  13806,\n",
       "  14201,\n",
       "  13771,\n",
       "  5176,\n",
       "  10751,\n",
       "  8382,\n",
       "  14018,\n",
       "  10699,\n",
       "  4728,\n",
       "  8221,\n",
       "  15112,\n",
       "  3208,\n",
       "  10699,\n",
       "  2157,\n",
       "  7433,\n",
       "  3585],\n",
       " [13923, 9837, 8225, 15450],\n",
       " [7120, 6512],\n",
       " [9852, 15082, 12547, 5207, 14503],\n",
       " [15502, 10706, 3529],\n",
       " [634, 11161, 10477, 5383, 8217, 8747, 5064, 10143],\n",
       " [4992,\n",
       "  9273,\n",
       "  11723,\n",
       "  10187,\n",
       "  15342,\n",
       "  14011,\n",
       "  10915,\n",
       "  2030,\n",
       "  14589,\n",
       "  14570,\n",
       "  10596,\n",
       "  9131,\n",
       "  13447,\n",
       "  9131,\n",
       "  4868,\n",
       "  14666,\n",
       "  1935,\n",
       "  14707,\n",
       "  8152,\n",
       "  9935,\n",
       "  5609,\n",
       "  7438,\n",
       "  10012,\n",
       "  1446,\n",
       "  1980,\n",
       "  5355,\n",
       "  8711,\n",
       "  12261,\n",
       "  6448,\n",
       "  4992,\n",
       "  9273,\n",
       "  13297,\n",
       "  13709,\n",
       "  5790,\n",
       "  2869,\n",
       "  10048,\n",
       "  6734,\n",
       "  6036,\n",
       "  4168,\n",
       "  15038,\n",
       "  451,\n",
       "  10264,\n",
       "  867,\n",
       "  5339,\n",
       "  10826,\n",
       "  15467,\n",
       "  7155],\n",
       " [12827, 11194, 15183],\n",
       " [7108,\n",
       "  12906,\n",
       "  3929,\n",
       "  7784,\n",
       "  7784,\n",
       "  12580,\n",
       "  972,\n",
       "  1191,\n",
       "  3121,\n",
       "  2393,\n",
       "  2393,\n",
       "  11400,\n",
       "  10823],\n",
       " [12956, 3448, 15697, 14857, 5425, 14290, 683, 1103],\n",
       " [1105,\n",
       "  14948,\n",
       "  1523,\n",
       "  15226,\n",
       "  10388,\n",
       "  4909,\n",
       "  2741,\n",
       "  15309,\n",
       "  1247,\n",
       "  11037,\n",
       "  857,\n",
       "  4482,\n",
       "  9811,\n",
       "  11833,\n",
       "  2071,\n",
       "  15226,\n",
       "  6876,\n",
       "  11833,\n",
       "  6956],\n",
       " [11085, 7410, 8953],\n",
       " [3519, 2560, 9706, 11747, 2421, 13576, 14948, 8970, 8594],\n",
       " [9796, 14006, 5920],\n",
       " [15480, 15122, 2175, 9918, 14405, 8792],\n",
       " [14948, 10706, 504],\n",
       " [5705,\n",
       "  9660,\n",
       "  3909,\n",
       "  8624,\n",
       "  14431,\n",
       "  10692,\n",
       "  1276,\n",
       "  4426,\n",
       "  1992,\n",
       "  14101,\n",
       "  238,\n",
       "  8063,\n",
       "  8084,\n",
       "  1446,\n",
       "  3264,\n",
       "  14588,\n",
       "  3264,\n",
       "  11608,\n",
       "  13146,\n",
       "  9194,\n",
       "  532,\n",
       "  12318,\n",
       "  5005,\n",
       "  1701,\n",
       "  9543,\n",
       "  12318,\n",
       "  13600,\n",
       "  506],\n",
       " [10446, 9781, 2016, 12418, 12879, 1041, 1922],\n",
       " [15379, 10706, 12994],\n",
       " [8998, 9706],\n",
       " [8618,\n",
       "  6927,\n",
       "  11542,\n",
       "  13548,\n",
       "  13352,\n",
       "  15462,\n",
       "  12234,\n",
       "  5404,\n",
       "  1720,\n",
       "  14663,\n",
       "  3189,\n",
       "  9929,\n",
       "  11306,\n",
       "  11747,\n",
       "  2843],\n",
       " [12005, 3414],\n",
       " [9517, 2332, 5962, 116, 4350, 229, 1439, 4114, 10166],\n",
       " [861],\n",
       " [10706, 15637, 14912, 4521, 12847, 6053, 9337, 4237],\n",
       " [15371, 4980, 9932],\n",
       " [12700, 3104, 5925],\n",
       " [302, 14633, 15637, 8203, 10822, 2356, 634, 10555],\n",
       " [13564,\n",
       "  9694,\n",
       "  488,\n",
       "  11030,\n",
       "  6829,\n",
       "  8371,\n",
       "  10187,\n",
       "  15342,\n",
       "  6612,\n",
       "  14786,\n",
       "  15275,\n",
       "  7695,\n",
       "  9838,\n",
       "  3139,\n",
       "  6404,\n",
       "  2253,\n",
       "  10187,\n",
       "  15342,\n",
       "  12327,\n",
       "  12512,\n",
       "  8122,\n",
       "  9838,\n",
       "  10146,\n",
       "  15306,\n",
       "  3917,\n",
       "  3774,\n",
       "  9118,\n",
       "  3774,\n",
       "  14862,\n",
       "  8510,\n",
       "  2868,\n",
       "  7980,\n",
       "  14635,\n",
       "  11580,\n",
       "  4048,\n",
       "  1785,\n",
       "  3541,\n",
       "  15082,\n",
       "  5152,\n",
       "  2795,\n",
       "  3774,\n",
       "  9159,\n",
       "  10991,\n",
       "  12455,\n",
       "  2868,\n",
       "  524,\n",
       "  488,\n",
       "  3774,\n",
       "  6829,\n",
       "  8510,\n",
       "  5465,\n",
       "  14102,\n",
       "  524,\n",
       "  13188,\n",
       "  10972,\n",
       "  15425],\n",
       " [10706, 3529, 9033, 8953, 15064],\n",
       " [13050, 1021, 4045, 273, 6909, 15542, 14948, 4045, 9706, 3327],\n",
       " [3852,\n",
       "  15570,\n",
       "  3605,\n",
       "  10954,\n",
       "  11881,\n",
       "  8191,\n",
       "  12824,\n",
       "  9186,\n",
       "  9852,\n",
       "  14670,\n",
       "  9998,\n",
       "  9852,\n",
       "  9186,\n",
       "  9852,\n",
       "  4094,\n",
       "  10070,\n",
       "  2767],\n",
       " [14948, 10268],\n",
       " [6805, 2354, 10286],\n",
       " [9493, 8373, 14948],\n",
       " [7609, 256],\n",
       " [12994,\n",
       "  4845,\n",
       "  8373,\n",
       "  10672,\n",
       "  6037,\n",
       "  5695,\n",
       "  7906,\n",
       "  1755,\n",
       "  6009,\n",
       "  9929,\n",
       "  11072,\n",
       "  1680,\n",
       "  6389,\n",
       "  6009,\n",
       "  9929],\n",
       " [2976, 7004, 10382, 2324, 15064],\n",
       " [3852,\n",
       "  7774,\n",
       "  623,\n",
       "  8646,\n",
       "  9260,\n",
       "  10781,\n",
       "  15397,\n",
       "  6036,\n",
       "  2346,\n",
       "  13355,\n",
       "  1476,\n",
       "  12334,\n",
       "  3774],\n",
       " [3485, 5108, 6265],\n",
       " [1266, 62, 1848, 11141],\n",
       " [14529, 2207, 7182],\n",
       " [9852, 532, 10105],\n",
       " [1755, 15064, 11697, 8023, 5578, 2767],\n",
       " [3529, 13144, 3645, 13159],\n",
       " [694, 5097, 14551, 1562, 7410, 11994, 8217, 7780, 9298],\n",
       " [5709, 5412, 4086, 4086, 3935, 3326, 1953, 727],\n",
       " [5786,\n",
       "  471,\n",
       "  5251,\n",
       "  7368,\n",
       "  8373,\n",
       "  2622,\n",
       "  6896,\n",
       "  8105,\n",
       "  9665,\n",
       "  12587,\n",
       "  12479,\n",
       "  540,\n",
       "  10803,\n",
       "  12941,\n",
       "  11071,\n",
       "  12587,\n",
       "  1569,\n",
       "  8411,\n",
       "  13017,\n",
       "  540,\n",
       "  10010,\n",
       "  1024,\n",
       "  13920,\n",
       "  11,\n",
       "  4199],\n",
       " [1194, 10264, 5448, 5696, 7551],\n",
       " [5630, 14205, 6201, 3551, 11082, 12675, 8085, 4205, 2525, 6970, 4928],\n",
       " [9852, 7377, 2245],\n",
       " [2658, 3529],\n",
       " [3773,\n",
       "  4325,\n",
       "  4839,\n",
       "  8411,\n",
       "  14290,\n",
       "  5999,\n",
       "  4474,\n",
       "  6392,\n",
       "  12587,\n",
       "  6234,\n",
       "  11422,\n",
       "  683,\n",
       "  12062,\n",
       "  6895,\n",
       "  5498,\n",
       "  875,\n",
       "  12114,\n",
       "  4474,\n",
       "  13701],\n",
       " [11085, 8953],\n",
       " [10706, 9622, 10706, 8786],\n",
       " [72, 634, 14948],\n",
       " [2882, 10409, 3571],\n",
       " [3162, 1622],\n",
       " [10165, 7774, 9909, 15691, 2123, 10832, 1964, 9938, 9781, 9453],\n",
       " [7609,\n",
       "  5258,\n",
       "  7439,\n",
       "  10446,\n",
       "  71,\n",
       "  12670,\n",
       "  7417,\n",
       "  6578,\n",
       "  8969,\n",
       "  811,\n",
       "  12178,\n",
       "  10580,\n",
       "  1041],\n",
       " [15637, 10706],\n",
       " [71, 2013, 7023, 7745],\n",
       " [11085, 8953],\n",
       " [3529, 10706, 3663, 3529, 15558, 12306, 3534, 8532, 1556, 15462, 15702],\n",
       " [1799, 12512, 6823],\n",
       " [5689, 8503, 2548, 2995, 6333, 713, 10706, 12100, 14871, 5140, 3663],\n",
       " [7425, 12343, 3948],\n",
       " [4389, 2174, 2123],\n",
       " [13067, 7429, 14420, 471, 13069, 10166, 8045, 1131, 4199],\n",
       " [6122, 7928, 1828, 232, 7004],\n",
       " [4759, 1182, 11542, 302, 4572, 10335, 15637],\n",
       " [3773,\n",
       "  9814,\n",
       "  14948,\n",
       "  10917,\n",
       "  1710,\n",
       "  3842,\n",
       "  714,\n",
       "  3773,\n",
       "  14948,\n",
       "  12549,\n",
       "  4263,\n",
       "  9292,\n",
       "  8824,\n",
       "  14948,\n",
       "  12549,\n",
       "  6009,\n",
       "  3299,\n",
       "  2482,\n",
       "  5254,\n",
       "  5840,\n",
       "  3500,\n",
       "  9814,\n",
       "  3773,\n",
       "  10706,\n",
       "  4263,\n",
       "  9292,\n",
       "  7769,\n",
       "  14787,\n",
       "  875,\n",
       "  1311,\n",
       "  13959,\n",
       "  1262,\n",
       "  15050,\n",
       "  7429,\n",
       "  5671,\n",
       "  8338,\n",
       "  4909,\n",
       "  3104,\n",
       "  5925,\n",
       "  12005,\n",
       "  9929,\n",
       "  3529,\n",
       "  6927,\n",
       "  11587,\n",
       "  2715,\n",
       "  6975,\n",
       "  9811,\n",
       "  6927,\n",
       "  5254,\n",
       "  10790,\n",
       "  1916,\n",
       "  7712,\n",
       "  4704,\n",
       "  1496,\n",
       "  6854,\n",
       "  14820,\n",
       "  13947,\n",
       "  6122,\n",
       "  875,\n",
       "  517,\n",
       "  1686],\n",
       " [2722, 8745, 14827],\n",
       " [15462, 9886, 7454, 875, 3929, 9845, 1111, 14859, 9706, 10296],\n",
       " [6921, 14911, 14948, 11097, 6467, 9824],\n",
       " [10165, 7774, 9909, 15691, 2123, 10832, 1964, 9938, 9781, 9453],\n",
       " [15788, 9706, 6909, 15542],\n",
       " [7900, 3529, 3645, 13159],\n",
       " [3579, 14065, 14284, 6410, 6823],\n",
       " [3529,\n",
       "  10657,\n",
       "  3785,\n",
       "  14024,\n",
       "  598,\n",
       "  1375,\n",
       "  14009,\n",
       "  10550,\n",
       "  1387,\n",
       "  9793,\n",
       "  10311,\n",
       "  12660,\n",
       "  6931,\n",
       "  10737,\n",
       "  2054,\n",
       "  3529],\n",
       " [12725, 8856, 11955],\n",
       " [7429, 3529, 12374, 15216, 683],\n",
       " [14955, 3825, 8271, 13050, 11322, 1021],\n",
       " [3983,\n",
       "  1696,\n",
       "  1528,\n",
       "  15077,\n",
       "  13404,\n",
       "  13269,\n",
       "  9604,\n",
       "  4158,\n",
       "  10796,\n",
       "  6083,\n",
       "  2747,\n",
       "  4072,\n",
       "  10002,\n",
       "  4022,\n",
       "  13770,\n",
       "  3264,\n",
       "  10173,\n",
       "  12826,\n",
       "  11752,\n",
       "  9930,\n",
       "  301],\n",
       " [10446,\n",
       "  644,\n",
       "  9365,\n",
       "  845,\n",
       "  10397,\n",
       "  10263,\n",
       "  10657,\n",
       "  3605,\n",
       "  13594,\n",
       "  10446,\n",
       "  15356,\n",
       "  1448,\n",
       "  11634,\n",
       "  8444,\n",
       "  6565,\n",
       "  13957,\n",
       "  14089,\n",
       "  15691,\n",
       "  3774,\n",
       "  10446,\n",
       "  11457,\n",
       "  8736,\n",
       "  5637,\n",
       "  5815,\n",
       "  11485,\n",
       "  8942,\n",
       "  9959,\n",
       "  2011,\n",
       "  524,\n",
       "  14244,\n",
       "  13957,\n",
       "  15691,\n",
       "  3774,\n",
       "  10446,\n",
       "  11457],\n",
       " [3485, 3529],\n",
       " [12762, 1103],\n",
       " [5950, 8699],\n",
       " [7928, 7965],\n",
       " [3519, 14948, 4037, 6921, 14911],\n",
       " [7265, 3285, 2553, 14591, 6994, 5079, 3044],\n",
       " [8373,\n",
       "  6090,\n",
       "  3575,\n",
       "  8373,\n",
       "  13966,\n",
       "  8260,\n",
       "  1916,\n",
       "  13574,\n",
       "  1916,\n",
       "  15192,\n",
       "  5245,\n",
       "  14453,\n",
       "  7004,\n",
       "  683,\n",
       "  15196,\n",
       "  5482,\n",
       "  15257,\n",
       "  15196,\n",
       "  12548,\n",
       "  11168,\n",
       "  2880,\n",
       "  13159,\n",
       "  8685,\n",
       "  302,\n",
       "  8373,\n",
       "  9304],\n",
       " [15570, 3196, 12000],\n",
       " [2543, 10175, 11306, 11220, 2543, 10175],\n",
       " [12068, 4345, 12548, 5503, 8791],\n",
       " [7829, 8649, 2055, 13420, 11632, 1103],\n",
       " [7410, 8953, 1960, 15028, 5343, 14948, 875, 11747, 14126, 2131],\n",
       " [7610,\n",
       "  1216,\n",
       "  8082,\n",
       "  9619,\n",
       "  4042,\n",
       "  11542,\n",
       "  11882,\n",
       "  12489,\n",
       "  9619,\n",
       "  11882,\n",
       "  12489,\n",
       "  6948,\n",
       "  15539,\n",
       "  11931,\n",
       "  6126,\n",
       "  12092,\n",
       "  10935,\n",
       "  1586,\n",
       "  10812,\n",
       "  3929,\n",
       "  6148,\n",
       "  15496,\n",
       "  8991,\n",
       "  1720,\n",
       "  11168,\n",
       "  4243,\n",
       "  14215,\n",
       "  1022,\n",
       "  1511,\n",
       "  2980,\n",
       "  8856,\n",
       "  12280,\n",
       "  3929,\n",
       "  1022,\n",
       "  11168,\n",
       "  4050,\n",
       "  8991,\n",
       "  1720,\n",
       "  11586,\n",
       "  14065,\n",
       "  2163,\n",
       "  7108,\n",
       "  7746,\n",
       "  8841,\n",
       "  5962,\n",
       "  2605,\n",
       "  9779,\n",
       "  1720,\n",
       "  1972,\n",
       "  7610,\n",
       "  7108,\n",
       "  8705,\n",
       "  13794,\n",
       "  1191,\n",
       "  1734,\n",
       "  875,\n",
       "  7262,\n",
       "  14065,\n",
       "  15533,\n",
       "  1916,\n",
       "  9993,\n",
       "  9775,\n",
       "  7004,\n",
       "  683],\n",
       " [12678, 13069, 12202],\n",
       " [15637,\n",
       "  15265,\n",
       "  8914,\n",
       "  15767,\n",
       "  11076,\n",
       "  10833,\n",
       "  10525,\n",
       "  7610,\n",
       "  13888,\n",
       "  15767,\n",
       "  9600,\n",
       "  4086],\n",
       " [1103, 2866, 12896, 14913, 13067],\n",
       " [1103,\n",
       "  2450,\n",
       "  8147,\n",
       "  9811,\n",
       "  1591,\n",
       "  13574,\n",
       "  11127,\n",
       "  14437,\n",
       "  1916,\n",
       "  9811,\n",
       "  1591,\n",
       "  13950,\n",
       "  5008,\n",
       "  5671,\n",
       "  546,\n",
       "  694,\n",
       "  13804],\n",
       " [1493,\n",
       "  6413,\n",
       "  12824,\n",
       "  1478,\n",
       "  2245,\n",
       "  2381,\n",
       "  561,\n",
       "  5388,\n",
       "  4807,\n",
       "  1478,\n",
       "  10825,\n",
       "  8369,\n",
       "  2274,\n",
       "  5477,\n",
       "  4523,\n",
       "  15353,\n",
       "  14203,\n",
       "  3837],\n",
       " [10706,\n",
       "  1103,\n",
       "  5523,\n",
       "  4541,\n",
       "  14866,\n",
       "  8791,\n",
       "  13807,\n",
       "  603,\n",
       "  875,\n",
       "  12188,\n",
       "  742,\n",
       "  7401,\n",
       "  9461],\n",
       " [12578, 12578, 1105, 3529, 1088, 14160, 10706, 7108],\n",
       " [7239, 10485, 6799, 11592, 3999, 496, 11541],\n",
       " [2904, 6001, 7153],\n",
       " [106, 13701, 1964, 10111, 2013],\n",
       " [15196, 12872, 5070, 7498, 3625, 560],\n",
       " [10706, 922, 2841],\n",
       " [11860, 1170, 3885, 6718],\n",
       " [10706, 10706, 10706, 9706],\n",
       " [1949, 2898, 4534, 1337, 4789, 1730],\n",
       " [10706, 3529, 9642, 12005, 9706],\n",
       " [10706, 3529],\n",
       " [11085, 8373, 11085, 2013],\n",
       " [8045, 3332, 13807, 8373, 14948],\n",
       " [7377,\n",
       "  9273,\n",
       "  14939,\n",
       "  11699,\n",
       "  2775,\n",
       "  7726,\n",
       "  3066,\n",
       "  9852,\n",
       "  15691,\n",
       "  2362,\n",
       "  232,\n",
       "  2362,\n",
       "  7875],\n",
       " [14065, 12931, 14244, 1103],\n",
       " [14366, 221, 1219, 10446],\n",
       " [6896, 2024, 11177],\n",
       " [5553, 14495, 7619],\n",
       " [12857, 8395, 10525],\n",
       " [10107, 360, 3485],\n",
       " [6752, 13973, 10525, 15532, 1103, 15350, 1964],\n",
       " [9126, 6670, 7004, 2219, 236, 6907, 603],\n",
       " [366, 195, 10419, 3825],\n",
       " [14009, 10550, 8581, 15776, 5665, 4566, 3529],\n",
       " [14940, 437, 2362, 15381, 9608],\n",
       " [11948, 3529, 12435, 8831, 3663, 3529],\n",
       " [5039, 71, 3657, 2043, 6856, 4697, 11827, 3774, 3774, 7877],\n",
       " [14009, 10550, 10699],\n",
       " [8532, 14290, 683, 11511],\n",
       " [14009, 10550, 15381],\n",
       " [15728, 12931, 9242, 5245],\n",
       " [9149, 15122, 14529],\n",
       " [6908, 14065, 3481],\n",
       " [10429, 14196, 14617, 2309],\n",
       " [12396, 12038, 10794],\n",
       " [1103, 2788, 4042, 4593, 5482, 1586, 5986],\n",
       " [13322, 6691, 12762],\n",
       " [14024, 3638, 15637, 1353, 11141, 12436],\n",
       " [416, 2653, 553],\n",
       " [2866, 8379, 2013],\n",
       " [10706, 9706, 1103],\n",
       " [3721, 56, 4670, 4541, 8228],\n",
       " [10257, 14857],\n",
       " [3760, 12351, 5729, 2666, 12089, 12089],\n",
       " [5705, 9660, 8831, 3555, 12514, 10266],\n",
       " [11306, 9929, 7283, 186],\n",
       " [12005, 9763, 5925],\n",
       " [10419, 3825, 8271, 14771],\n",
       " [10706, 10286, 15788, 11836, 11673, 5207, 15371, 15683],\n",
       " [8953, 13902, 5250],\n",
       " [8373, 7454, 344, 875, 13888, 6208],\n",
       " [522, 8817, 7480, 11201, 11813],\n",
       " [6909, 13158, 682, 14948, 14545, 8252],\n",
       " [5425],\n",
       " [1951, 9706, 1216],\n",
       " [13420, 15371, 12005, 8145],\n",
       " [1499, 9604, 9706],\n",
       " [5355],\n",
       " [11955, 7412, 3839, 13355, 9139, 8460, 853],\n",
       " [1951, 7891],\n",
       " [71,\n",
       "  34,\n",
       "  13592,\n",
       "  4959,\n",
       "  11405,\n",
       "  2705,\n",
       "  7649,\n",
       "  6084,\n",
       "  2201,\n",
       "  4049,\n",
       "  4959,\n",
       "  10105,\n",
       "  9649,\n",
       "  524,\n",
       "  1930,\n",
       "  9134,\n",
       "  8483,\n",
       "  3852,\n",
       "  10692,\n",
       "  11499,\n",
       "  7344],\n",
       " [15742, 14830, 15371],\n",
       " [9732,\n",
       "  12905,\n",
       "  3929,\n",
       "  3493,\n",
       "  3353,\n",
       "  8711,\n",
       "  7365,\n",
       "  875,\n",
       "  15753,\n",
       "  8809,\n",
       "  1492,\n",
       "  14065,\n",
       "  3645,\n",
       "  2899],\n",
       " [8719, 12122, 6867, 8642, 1250, 10006],\n",
       " [10967, 6896, 14948, 3200],\n",
       " [15765, 3290, 10916, 1021],\n",
       " [9165, 10058, 9143, 5225, 5554, 4134, 385, 1387, 10335],\n",
       " [708, 7982, 34, 12835, 506, 2898, 14589, 2317, 10238, 8533, 1875, 12364],\n",
       " [11523, 1103],\n",
       " [10706, 9706],\n",
       " [7924,\n",
       "  3703,\n",
       "  5689,\n",
       "  1353,\n",
       "  6037,\n",
       "  12812,\n",
       "  10754,\n",
       "  11883,\n",
       "  3731,\n",
       "  2164,\n",
       "  11152,\n",
       "  3929,\n",
       "  1353,\n",
       "  6948,\n",
       "  14386],\n",
       " [694, 10706, 15637],\n",
       " [8831, 5250, 13814],\n",
       " [10706, 5300, 9706],\n",
       " [11545, 11573, 704, 8373, 1546, 14146],\n",
       " [10706, 15637],\n",
       " [3104, 14683, 11741],\n",
       " [3935, 8867, 1569, 1569, 4218, 14332, 8373, 8650, 6642, 5421],\n",
       " [4888, 12827],\n",
       " [6829,\n",
       "  9852,\n",
       "  10480,\n",
       "  14875,\n",
       "  9277,\n",
       "  10050,\n",
       "  10586,\n",
       "  14875,\n",
       "  10550,\n",
       "  3603,\n",
       "  9418,\n",
       "  13994,\n",
       "  1124],\n",
       " [10245,\n",
       "  3703,\n",
       "  13750,\n",
       "  11335,\n",
       "  4356,\n",
       "  12130,\n",
       "  11097,\n",
       "  3152,\n",
       "  13341,\n",
       "  6939,\n",
       "  15687,\n",
       "  9557,\n",
       "  7039,\n",
       "  15124],\n",
       " [4541, 12791, 1103],\n",
       " [3935, 2990, 5503, 6818, 694, 13548, 6699, 9292, 5011],\n",
       " [5493, 2235, 11334, 361, 12548, 4569, 15040],\n",
       " [10270, 7396, 15637],\n",
       " [13785, 2656, 1267, 330],\n",
       " [9852, 3825, 7805, 9700, 14950, 1930, 644],\n",
       " [5100, 10050, 7470],\n",
       " [694,\n",
       "  2362,\n",
       "  6988,\n",
       "  15371,\n",
       "  2362,\n",
       "  15381,\n",
       "  15117,\n",
       "  15226,\n",
       "  8479,\n",
       "  13576,\n",
       "  15371,\n",
       "  13144,\n",
       "  14126,\n",
       "  327],\n",
       " [3990, 2436, 14835, 2622, 6722, 285],\n",
       " [10706, 14948],\n",
       " [9706, 11542, 14091, 13023, 13355, 8695],\n",
       " [9759, 10497, 12692, 5343, 6809, 627, 12479, 3774, 13385, 10919],\n",
       " [8319, 10398, 1232, 2622, 12258, 14771, 4002],\n",
       " [2904, 6001, 3699, 9357, 15186, 13649, 5880, 12760],\n",
       " [7004, 770, 7928, 15064],\n",
       " [12435, 12435, 12435],\n",
       " [13717, 14100, 4320, 3454, 3529],\n",
       " [14367, 5064, 7556, 15064],\n",
       " [7137, 3880, 8431, 10996, 6974, 15082],\n",
       " [2216, 10257, 14857],\n",
       " [13144, 12005, 3414],\n",
       " [2375, 11337, 2672],\n",
       " [6921, 6662, 2353],\n",
       " [2722, 8745, 14827, 9642],\n",
       " [13144, 7004, 10706, 15637, 14065, 14065, 3663, 765],\n",
       " [5288, 5288, 3098, 14902, 15314, 2889, 3716],\n",
       " [11523, 8291, 7467, 6310, 15462, 11631, 12599, 11351, 13454],\n",
       " [401, 11938, 2081, 6284, 10863, 10176],\n",
       " [2942, 2765, 15716, 15538, 3900, 12681],\n",
       " [2560, 13920, 9706, 14835],\n",
       " [15788, 196],\n",
       " [9972,\n",
       "  1353,\n",
       "  12595,\n",
       "  739,\n",
       "  10266,\n",
       "  1353,\n",
       "  5671,\n",
       "  4204,\n",
       "  11258,\n",
       "  10296,\n",
       "  8981,\n",
       "  10833,\n",
       "  3443,\n",
       "  5422,\n",
       "  11141,\n",
       "  3699,\n",
       "  6096,\n",
       "  10062,\n",
       "  7320],\n",
       " [340,\n",
       "  9929,\n",
       "  7283,\n",
       "  1964,\n",
       "  340,\n",
       "  13624,\n",
       "  8373,\n",
       "  8230,\n",
       "  11913,\n",
       "  7941,\n",
       "  340,\n",
       "  14551,\n",
       "  340,\n",
       "  13894,\n",
       "  340,\n",
       "  3842,\n",
       "  4697,\n",
       "  340,\n",
       "  14453,\n",
       "  15738,\n",
       "  8373,\n",
       "  3453,\n",
       "  4930,\n",
       "  4894,\n",
       "  11913,\n",
       "  5866,\n",
       "  14453,\n",
       "  14453,\n",
       "  14453,\n",
       "  14453,\n",
       "  14453],\n",
       " [15728, 1686, 8373, 5671, 126, 825, 6512],\n",
       " [7900, 8803, 3476, 9128, 2622, 14290, 2715, 7554],\n",
       " [1889, 71, 12209, 1608, 1949],\n",
       " [10706, 9706],\n",
       " [13807, 12784, 10472, 14637, 10587],\n",
       " [11862, 6641, 8045, 4140, 13067, 12587, 10296, 5509, 8831, 9325],\n",
       " [5689,\n",
       "  2936,\n",
       "  8711,\n",
       "  6018,\n",
       "  1960,\n",
       "  7719,\n",
       "  13947,\n",
       "  216,\n",
       "  3929,\n",
       "  10229,\n",
       "  14414,\n",
       "  10333,\n",
       "  9929,\n",
       "  6333,\n",
       "  8052,\n",
       "  3517,\n",
       "  2286,\n",
       "  6095,\n",
       "  3123,\n",
       "  3766,\n",
       "  341],\n",
       " [10706, 15371],\n",
       " [8045, 10912, 14035],\n",
       " [10706, 5575, 8243],\n",
       " [10706, 5300, 7396],\n",
       " [10687,\n",
       "  5709,\n",
       "  5805,\n",
       "  14351,\n",
       "  2869,\n",
       "  5875,\n",
       "  13373,\n",
       "  3268,\n",
       "  6004,\n",
       "  1376,\n",
       "  5950,\n",
       "  10597,\n",
       "  13328,\n",
       "  6089,\n",
       "  15594,\n",
       "  7880],\n",
       " [72, 10706, 10291, 8612, 186, 15107],\n",
       " [7891, 3178],\n",
       " [8608, 12181, 9700, 5639, 3953, 11867, 983, 7672],\n",
       " [5709, 634, 15350, 634],\n",
       " [15611,\n",
       "  15794,\n",
       "  11223,\n",
       "  5230,\n",
       "  3773,\n",
       "  9821,\n",
       "  9144,\n",
       "  7048,\n",
       "  8584,\n",
       "  4332,\n",
       "  8831,\n",
       "  11335,\n",
       "  2622,\n",
       "  14859,\n",
       "  13144,\n",
       "  12435],\n",
       " [15479, 6337, 13061, 3677, 4457, 15153, 2178, 14299, 4457, 13526, 13015],\n",
       " [2760, 12762, 8496, 3541],\n",
       " [9852, 9186, 10727, 9186, 15637],\n",
       " [1103, 15479, 8998, 14035, 7002, 4601],\n",
       " [7429, 3529],\n",
       " [5253, 14948, 2889, 7004, 10166],\n",
       " [6809, 8807, 7704],\n",
       " [15468, 14683, 8373, 14683],\n",
       " [1288, 3085, 2548],\n",
       " [10387, 4448, 11642, 5855, 2927, 10266, 1022, 3990, 13067, 13771, 6660],\n",
       " [15788, 13823, 2584, 12548, 8236, 9519, 13698, 15738, 9700],\n",
       " [10513, 3563],\n",
       " [11900, 185, 8017, 5457, 8013, 5127, 185, 13284, 9695, 8013],\n",
       " [12817, 8953, 2157, 13562, 8953, 2938, 4525, 8953, 6272],\n",
       " [4759, 2453, 875, 14984, 12296],\n",
       " [10706, 9706, 2938, 14065],\n",
       " [5692, 7925, 6291, 4436, 13953, 1279, 15635, 9925, 14789, 5082, 5082, 6270],\n",
       " [1996,\n",
       "  14359,\n",
       "  6272,\n",
       "  9326,\n",
       "  14800,\n",
       "  6716,\n",
       "  1595,\n",
       "  9496,\n",
       "  7502,\n",
       "  11642,\n",
       "  14791,\n",
       "  1221,\n",
       "  7007,\n",
       "  10266,\n",
       "  15615],\n",
       " [10706, 6662],\n",
       " [3264, 7320, 10704, 13284],\n",
       " [2904,\n",
       "  6001,\n",
       "  14642,\n",
       "  1720,\n",
       "  13817,\n",
       "  13129,\n",
       "  11740,\n",
       "  15187,\n",
       "  2778,\n",
       "  10620,\n",
       "  5149,\n",
       "  5268,\n",
       "  7454,\n",
       "  11542,\n",
       "  10919,\n",
       "  7236,\n",
       "  9719,\n",
       "  5140,\n",
       "  1569,\n",
       "  1719,\n",
       "  14252,\n",
       "  1720,\n",
       "  8069,\n",
       "  10782,\n",
       "  13121,\n",
       "  6255,\n",
       "  9350,\n",
       "  3916,\n",
       "  6752,\n",
       "  9756,\n",
       "  5384,\n",
       "  8069,\n",
       "  4947,\n",
       "  1620,\n",
       "  14945,\n",
       "  14252,\n",
       "  7746],\n",
       " [8425, 14800, 2935, 12062, 4807, 3842, 8373, 4807, 7420, 12594],\n",
       " [14393, 3258, 3258, 6927],\n",
       " [15489, 15081],\n",
       " [14683, 3009, 7663],\n",
       " [5912, 305, 6957, 2253, 1351, 7171, 12199, 15426, 1930],\n",
       " [8953,\n",
       "  3662,\n",
       "  11741,\n",
       "  2600,\n",
       "  6948,\n",
       "  13807,\n",
       "  8953,\n",
       "  15064,\n",
       "  12085,\n",
       "  14126,\n",
       "  2476,\n",
       "  4386,\n",
       "  3638,\n",
       "  3529],\n",
       " [2904, 6001, 3264, 11703],\n",
       " [10706, 3529, 2843],\n",
       " [8011, 12743, 6707],\n",
       " [2571, 875, 1999, 10326, 8095],\n",
       " [11747, 14948, 11902, 430, 4878],\n",
       " [10706, 12841, 10496],\n",
       " [13498, 1022, 13585, 3063, 1720, 1579, 8745, 14835],\n",
       " [15465, 14947, 15095],\n",
       " [14584, 9886, 10266],\n",
       " [1103, 14986, 2622, 1384, 5113, 1262, 221],\n",
       " [9929, 7283, 10706, 3529],\n",
       " [15462, 3663, 11542, 14367, 8511, 2995, 7088, 5150, 21],\n",
       " [10086, 15050, 6501, 11027, 597, 13832, 13950],\n",
       " [3703, 2050, 8876, 9422, 6719, 1053, 6390, 11513, 10692, 12675],\n",
       " [6380, 875, 15064, 11419, 2889, 15738, 7004],\n",
       " [8291, 10451, 13030],\n",
       " [15245, 6036],\n",
       " [2640, 13788, 797],\n",
       " [7779, 12867, 14146, 15538, 186],\n",
       " [10706, 14948, 15637],\n",
       " [10706, 11085, 10107, 14551, 15371],\n",
       " [10706, 9706],\n",
       " [10165, 7774, 9909, 15691, 2123, 10832, 1964, 9938, 9781, 9453],\n",
       " [8511, 483, 4519, 14219, 8571, 12197, 8740, 11428, 10832, 10977, 14344],\n",
       " [12879, 8856, 14278, 7861, 8349, 6002, 11480, 1861, 8313, 9340, 12692],\n",
       " [12989, 6984, 14338],\n",
       " [15637,\n",
       "  1952,\n",
       "  281,\n",
       "  694,\n",
       "  14009,\n",
       "  10550,\n",
       "  9018,\n",
       "  3793,\n",
       "  1885,\n",
       "  1166,\n",
       "  1016,\n",
       "  7984,\n",
       "  14974,\n",
       "  1016,\n",
       "  12023,\n",
       "  11979,\n",
       "  2868,\n",
       "  5369,\n",
       "  14003,\n",
       "  12092,\n",
       "  3124],\n",
       " [15728, 4107, 14866, 10624],\n",
       " [7467, 9272, 6745],\n",
       " [15371, 11271, 13554],\n",
       " [7146, 4543, 14948],\n",
       " [10699, 11966, 11668, 1631, 4123, 3411],\n",
       " [12479,\n",
       "  13879,\n",
       "  13548,\n",
       "  5766,\n",
       "  857,\n",
       "  13946,\n",
       "  11865,\n",
       "  15501,\n",
       "  10706,\n",
       "  8831,\n",
       "  14722,\n",
       "  13144,\n",
       "  15450],\n",
       " [708, 15122, 6691, 14252, 713, 3697, 2546, 7610],\n",
       " [12994, 4845, 8373, 1353, 13848, 4654, 10833, 7320],\n",
       " [744, 7516, 12762],\n",
       " [15637, 12618, 13947, 37],\n",
       " [6916,\n",
       "  10544,\n",
       "  202,\n",
       "  11514,\n",
       "  4475,\n",
       "  2617,\n",
       "  6743,\n",
       "  6895,\n",
       "  7299,\n",
       "  14242,\n",
       "  6895,\n",
       "  15732,\n",
       "  8373,\n",
       "  9706,\n",
       "  8538],\n",
       " [13144, 7004, 9706],\n",
       " [7429, 14948, 12005, 14948, 5628],\n",
       " [6152, 8856, 8793, 11909],\n",
       " [8045, 4263, 14948],\n",
       " [14666, 10048, 10173, 2253, 15475, 12266, 6158],\n",
       " [13480, 14244, 3485],\n",
       " [194,\n",
       "  12994,\n",
       "  1585,\n",
       "  10050,\n",
       "  1585,\n",
       "  11308,\n",
       "  14042,\n",
       "  12180,\n",
       "  6317,\n",
       "  3506,\n",
       "  1487,\n",
       "  1761,\n",
       "  2362,\n",
       "  14102,\n",
       "  1067,\n",
       "  5842,\n",
       "  11858,\n",
       "  6592,\n",
       "  15637,\n",
       "  121,\n",
       "  8591],\n",
       " [4222, 5253, 14948, 7825],\n",
       " [4094, 5578, 2767, 14575, 2099, 10692],\n",
       " [6895, 11836, 6944, 2031],\n",
       " [10165, 7774, 9909, 15691, 2123, 10832, 1964, 9938, 9781, 9453],\n",
       " [8373, 12062],\n",
       " [6051, 10187, 15342, 14011, 7849],\n",
       " [6090, 10291, 1964],\n",
       " [2978, 2157, 11933, 4131, 9684, 71, 6309],\n",
       " [8584,\n",
       "  10262,\n",
       "  8215,\n",
       "  8215,\n",
       "  10954,\n",
       "  8480,\n",
       "  12879,\n",
       "  9329,\n",
       "  7308,\n",
       "  6975,\n",
       "  13424,\n",
       "  1588,\n",
       "  12914,\n",
       "  14938,\n",
       "  8856,\n",
       "  12602,\n",
       "  6910],\n",
       " [8535, 15122, 8569, 8535, 8569, 13973],\n",
       " [9706, 11747, 14681, 4304, 4304],\n",
       " [1103,\n",
       "  2450,\n",
       "  1792,\n",
       "  14800,\n",
       "  4404,\n",
       "  3990,\n",
       "  7454,\n",
       "  14642,\n",
       "  11201,\n",
       "  850,\n",
       "  10782,\n",
       "  3791,\n",
       "  3929,\n",
       "  1960],\n",
       " [10706, 9706],\n",
       " [15574,\n",
       "  15462,\n",
       "  2436,\n",
       "  5411,\n",
       "  6876,\n",
       "  13709,\n",
       "  2928,\n",
       "  11510,\n",
       "  2556,\n",
       "  14777,\n",
       "  7560,\n",
       "  4359,\n",
       "  1262,\n",
       "  10976,\n",
       "  12272,\n",
       "  875,\n",
       "  5962,\n",
       "  45,\n",
       "  4970,\n",
       "  5509],\n",
       " [15728, 3852, 7774, 15064],\n",
       " [10706, 3529],\n",
       " [1103, 3935, 11100, 9706, 440, 14126, 683],\n",
       " [11299, 14814],\n",
       " [10110, 2081, 1859, 6739],\n",
       " [7089, 7089, 14785, 10382, 14253, 3147, 7233],\n",
       " [4052, 7454, 12151, 6914, 694, 1185, 14242, 14439, 7417, 7640, 285],\n",
       " [9396, 8998],\n",
       " [13050, 11322, 1021, 8611, 14905, 7425, 12007, 7382, 6673, 9869],\n",
       " [12700, 5412, 15350, 10706, 14835, 2362, 8689, 875, 3355, 14024],\n",
       " [634, 4059, 15371, 10706],\n",
       " [1686, 3658, 12512, 15463],\n",
       " [15351, 71, 9706, 7236, 12921, 13877, 8389],\n",
       " [10706, 5575, 8243],\n",
       " [6818,\n",
       "  10145,\n",
       "  10139,\n",
       "  278,\n",
       "  5403,\n",
       "  8712,\n",
       "  9706,\n",
       "  6345,\n",
       "  8663,\n",
       "  2332,\n",
       "  7264,\n",
       "  9793,\n",
       "  12514,\n",
       "  14315,\n",
       "  1686],\n",
       " [3852, 7774, 7471],\n",
       " [9594, 15515, 285, 14805, 6501, 15652, 3448, 14940, 11699],\n",
       " [10490, 3025, 2216],\n",
       " [9141, 49, 13355, 3774],\n",
       " [14877, 14877, 1112],\n",
       " [13144, 9146, 14229, 6504, 9706, 3844, 11656, 1065, 14229, 367],\n",
       " [10706, 773, 10387, 4448, 7031, 11994, 3645, 683, 4386, 15712, 10706, 7695],\n",
       " [9141,\n",
       "  4049,\n",
       "  2773,\n",
       "  5017,\n",
       "  12879,\n",
       "  12069,\n",
       "  12914,\n",
       "  10715,\n",
       "  12949,\n",
       "  1725,\n",
       "  12069,\n",
       "  12914,\n",
       "  15025],\n",
       " [13495, 6333, 2938, 7090],\n",
       " [10706, 10158, 3663, 10412, 4151],\n",
       " [6818, 13701, 8373],\n",
       " [12509, 9929, 12323],\n",
       " [15371, 10706, 10505, 4733, 14922, 2375, 1692, 13332],\n",
       " [9852, 9970, 3963],\n",
       " [15371, 10706, 9706],\n",
       " [15281, 1476, 366, 2816, 6213, 2525, 6419, 2328, 13297],\n",
       " [11847, 7928, 7965, 1103, 5207],\n",
       " [10706, 10525],\n",
       " [7004, 2357, 6831, 13970],\n",
       " [9033, 11587, 11741, 15417, 14962],\n",
       " [11424, 11514, 7538, 4990],\n",
       " [8243, 13210, 6949, 14841, 10706],\n",
       " [6315, 875, 3773, 7454, 10326, 5284, 10706, 1103],\n",
       " [2696, 2325, 5509],\n",
       " [2527, 6927, 10656, 10308],\n",
       " [708,\n",
       "  13896,\n",
       "  2978,\n",
       "  6528,\n",
       "  10355,\n",
       "  12032,\n",
       "  10618,\n",
       "  15219,\n",
       "  6035,\n",
       "  3274,\n",
       "  2663,\n",
       "  3774,\n",
       "  5674,\n",
       "  1832,\n",
       "  13188,\n",
       "  7556,\n",
       "  933,\n",
       "  8070,\n",
       "  7592,\n",
       "  14608,\n",
       "  962],\n",
       " [10706, 8528, 500, 14009, 8336, 510, 953],\n",
       " [9641, 7454, 8045, 8252],\n",
       " [13348, 9706, 10706, 4906],\n",
       " [10706, 3529, 15353, 9811, 15353],\n",
       " [10345, 4786, 12922, 1103, 1964, 1594, 1103, 2843, 11303],\n",
       " [1493, 10861, 1480, 12675, 8988, 12725, 3613],\n",
       " [1086, 10833, 105, 2050, 7004, 13175, 10706, 3923],\n",
       " [3935,\n",
       "  7456,\n",
       "  11966,\n",
       "  10216,\n",
       "  8883,\n",
       "  14454,\n",
       "  5132,\n",
       "  875,\n",
       "  12306,\n",
       "  14009,\n",
       "  10550,\n",
       "  10737,\n",
       "  14520,\n",
       "  9278,\n",
       "  9775,\n",
       "  507,\n",
       "  2304,\n",
       "  12949,\n",
       "  11872,\n",
       "  2797,\n",
       "  11127,\n",
       "  13265,\n",
       "  6049,\n",
       "  14009,\n",
       "  10550,\n",
       "  12548,\n",
       "  6741,\n",
       "  9799,\n",
       "  13273,\n",
       "  5671,\n",
       "  1366],\n",
       " ...]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_repr=[one_hot(words,vocab_size)for words in Train_Data.Msg_without_Stopwords] \n",
    "onehot_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14089  1935  6247 ...     0     0     0]\n",
      " [ 1279  1218  1408 ...     0     0     0]\n",
      " [10706  5709  9706 ...     0     0     0]\n",
      " ...\n",
      " [15408  7330 10050 ...     0     0     0]\n",
      " [13350  1406  1777 ...     0     0     0]\n",
      " [ 4888 12827     0 ...     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "embedded_docs=pad_sequences(onehot_repr,padding='post',maxlen=195)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6212, 195), (6212, 5))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_docs.shape, y_train1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "691"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_repr1=[one_hot(words,vocab_size)for words in Dev_Data.Msg_without_Stopwords] \n",
    "len(onehot_repr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "691"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_docs_dev=pad_sequences(onehot_repr1,padding='post',maxlen=195)\n",
    "len(embedded_docs_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_final=np.array(embedded_docs)\n",
    "y_final=np.array(y_train1)\n",
    "\n",
    "x_dev_final=np.array(embedded_docs_dev)\n",
    "y_dev_final=np.array(y_dev1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "691"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_dev_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6212, 195), (6212, 5), (691, 195), (691, 5))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.shape, y_final.shape, x_dev_final.shape, y_dev_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot convert a symbolic Tensor (bidirectional/forward_lstm/strided_slice:0) to a numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-4f14f5bfd84f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaxPool1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m ])\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, layers, name)\u001b[0m\n\u001b[0;32m    112\u001b[0m       \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    194\u001b[0m       \u001b[1;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\wrappers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# Applies the same workaround as in `RNN.__call__`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    840\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[0;32m    841\u001b[0m                   \u001b[1;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 842\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    843\u001b[0m                     \u001b[1;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m                     \u001b[1;31m# circular dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\wrappers.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask, initial_state, constants)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m       y = self.forward_layer(forward_inputs,\n\u001b[1;32m--> 642\u001b[1;33m                              initial_state=forward_state, **kwargs)\n\u001b[0m\u001b[0;32m    643\u001b[0m       y_rev = self.backward_layer(backward_inputs,\n\u001b[0;32m    644\u001b[0m                                   initial_state=backward_state, **kwargs)\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 623\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    840\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[0;32m    841\u001b[0m                   \u001b[1;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 842\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    843\u001b[0m                     \u001b[1;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m                     \u001b[1;31m# circular dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m   2547\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_recurrent_dropout_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2548\u001b[0m     return super(LSTM, self).call(\n\u001b[1;32m-> 2549\u001b[1;33m         inputs, mask=mask, training=training, initial_state=initial_state)\n\u001b[0m\u001b[0;32m   2550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2551\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state, constants)\u001b[0m\n\u001b[0;32m    680\u001b[0m            constants=None):\n\u001b[0;32m    681\u001b[0m     inputs, initial_state, constants = self._process_inputs(\n\u001b[1;32m--> 682\u001b[1;33m         inputs, initial_state, constants)\n\u001b[0m\u001b[0;32m    683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(self, inputs, initial_state, constants)\u001b[0m\n\u001b[0;32m    796\u001b[0m       \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 798\u001b[1;33m       \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_initial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mget_initial_state_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m       init_state = get_initial_state_fn(\n\u001b[1;32m--> 606\u001b[1;33m           inputs=None, batch_size=batch_size, dtype=dtype)\n\u001b[0m\u001b[0;32m    607\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m       init_state = _generate_zero_filled_state(batch_size, self.cell.state_size,\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[1;34m(self, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   2312\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_initial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2313\u001b[0m     return list(_generate_zero_filled_state_for_cell(\n\u001b[1;32m-> 2314\u001b[1;33m         self, inputs, batch_size, dtype))\n\u001b[0m\u001b[0;32m   2315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_generate_zero_filled_state_for_cell\u001b[1;34m(cell, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   2750\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2751\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2752\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_generate_zero_filled_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2753\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_generate_zero_filled_state\u001b[1;34m(batch_size_tensor, state_size, dtype)\u001b[0m\n\u001b[0;32m   2766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2767\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2768\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_zeros\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2769\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2770\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_zeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 535\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 535\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mcreate_zeros\u001b[1;34m(unnested_state_size)\u001b[0m\n\u001b[0;32m   2763\u001b[0m     \u001b[0mflat_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munnested_state_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2764\u001b[0m     \u001b[0minit_state_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_size_tensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mflat_dims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2765\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_state_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2767\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mzeros\u001b[1;34m(shape, dtype, name)\u001b[0m\n\u001b[0;32m   2347\u001b[0m         \u001b[1;31m# Create a constant if it won't be very big. Otherwise create a fill op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2348\u001b[0m         \u001b[1;31m# to prevent serialized GraphDefs from becoming too large.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2349\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzero\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2350\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2351\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_constant_if_small\u001b[1;34m(value, shape, dtype, name)\u001b[0m\n\u001b[0;32m   2304\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2305\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2306\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2307\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2308\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   3050\u001b[0m     \"\"\"\n\u001b[0;32m   3051\u001b[0m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[1;32m-> 3052\u001b[1;33m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[0;32m   3053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    734\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m     raise NotImplementedError(\"Cannot convert a symbolic Tensor ({}) to a numpy\"\n\u001b[1;32m--> 736\u001b[1;33m                               \" array.\".format(self.name))\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Cannot convert a symbolic Tensor (bidirectional/forward_lstm/strided_slice:0) to a numpy array."
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.layers import Dropout, Dense, Embedding, LSTM, Bidirectional\n",
    "model_CNN1 = keras.Sequential([\n",
    "    keras.layers.Embedding(vocab_size, 50, input_length=max_length),\n",
    "   # keras.layers.GlobalAveragePooling1D(),\n",
    "    # convolutional filters=128,  kernel size=3: it means length_long_sentence size of 65 we are luking for 3 words at a time\n",
    "    keras.layers.Conv1D(756, 7, activation='relu'),\n",
    "    keras.layers.Conv1D(756, 7, activation='relu'),\n",
    "    keras.layers.MaxPool1D(),\n",
    "    keras.layers.Conv1D(256, 3, activation='relu'),\n",
    "    keras.layers.Conv1D(256, 3, activation='relu'),\n",
    "    keras.layers.MaxPool1D(),\n",
    "    keras.layers.Bidirectional(LSTM(400)),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model_CNN1.compile(loss='sparse_categorical_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "model_CNN1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CNN1.fit(X_final,y_final,epochs=10,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 195, 40)           1609200   \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 200)               112800    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 1005      \n",
      "=================================================================\n",
      "Total params: 1,723,005\n",
      "Trainable params: 1,723,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vector_features=40\n",
    "model1=Sequential()\n",
    "model1.add(Embedding(vocab_size,embedding_vector_features,input_length=195))\n",
    "model1.add(Bidirectional(LSTM(100)))\n",
    "model1.add(Dropout(0.3))\n",
    "model1.add(Dense(5,activation='sigmoid'))\n",
    "model1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15888 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000277F4F64EE8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000277F4F64EE8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "15888/15888 [==============================] - 2813s 177ms/sample - loss: 0.4279 - accuracy: 0.8112\n",
      "Epoch 2/10\n",
      "15888/15888 [==============================] - 1174s 74ms/sample - loss: 0.2807 - accuracy: 0.8847\n",
      "Epoch 3/10\n",
      "15888/15888 [==============================] - 1182s 74ms/sample - loss: 0.1715 - accuracy: 0.9341\n",
      "Epoch 4/10\n",
      "15888/15888 [==============================] - 2292s 144ms/sample - loss: 0.1099 - accuracy: 0.9619\n",
      "Epoch 5/10\n",
      "15888/15888 [==============================] - 1207s 76ms/sample - loss: 0.0656 - accuracy: 0.9788\n",
      "Epoch 6/10\n",
      "15888/15888 [==============================] - 1194s 75ms/sample - loss: 0.0479 - accuracy: 0.9850\n",
      "Epoch 7/10\n",
      "15888/15888 [==============================] - 1190s 75ms/sample - loss: 0.0377 - accuracy: 0.9888\n",
      "Epoch 8/10\n",
      "15888/15888 [==============================] - 812s 51ms/sample - loss: 0.0311 - accuracy: 0.9900\n",
      "Epoch 9/10\n",
      "15888/15888 [==============================] - 803s 51ms/sample - loss: 0.0261 - accuracy: 0.9917\n",
      "Epoch 10/10\n",
      "15888/15888 [==============================] - 807s 51ms/sample - loss: 0.0231 - accuracy: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x277f4faef08>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_final,y_final,epochs=10,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.557204\n",
      "Loss: 55.181224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.37      0.35       102\n",
      "           1       0.64      0.43      0.51       237\n",
      "           2       0.69      0.74      0.71       706\n",
      "           3       0.71      0.68      0.69       141\n",
      "           4       0.65      0.67      0.66       580\n",
      "\n",
      "    accuracy                           0.65      1766\n",
      "   macro avg       0.60      0.58      0.59      1766\n",
      "weighted avg       0.65      0.65      0.65      1766\n",
      "\n",
      "Cohen Score:  0.495450229923202\n"
     ]
    }
   ],
   "source": [
    "emoji(y_dev_final, x_dev_final, model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15888, 195), (15888, 5), (1766, 5), (1766, 195))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_padded_sentences.shape, y_train1.shape, y_dev1.shape, Dev_padded_sentences.shape"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP8geQdUqy6mvn4zRsyX2jU",
   "collapsed_sections": [],
   "name": "Malayalam 3 Offensive ML.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
