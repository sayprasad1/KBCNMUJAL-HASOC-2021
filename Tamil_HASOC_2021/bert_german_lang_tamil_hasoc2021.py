# -*- coding: utf-8 -*-
"""BERT GERMAN LANG TAMIL hasoc2021.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HLVy1_DHOqn93Uf0qUI420VmxjxZ63q3

BERT Text Classification in a different language:
https://towardsdatascience.com/bert-text-classification-in-a-different-language-6af54930f9cb
"""

from google.colab import files
uploaded = files.upload()

# install simpletransformers
!pip install simpletransformers

# check installed version
!pip freeze | grep simpletransformers

import pandas as pd
from simpletransformers.classification import ClassificationModel

Mal_train=pd.read_csv("tamil_sentiment_full_train.tsv" , sep='\t')
Mal_Dev=pd.read_csv("tamil_sentiment_full_dev.tsv" , sep='\t')
#Mal_test=pd.read_csv("tamil_sentiment_full_test_withoutlabels.tsv" , sep='\t')

Mal_train.head()

Mal_Dev.head()

Mal_train=Mal_train.replace(to_replace =["Positive "], value ="Positive")

#Mal_test.head()

Mal_train['category'].value_counts()

Mal_Dev['category'].value_counts()

msg=Mal_train['text']

msgDev=Mal_Dev['text']

#msgTest=Mal_test['text']

import regex
import re
import numpy as np

#Remove Emojis

def emoji(msg): 
    
    msg_emoj=msg.str.replace(r'[(\U0001F600-\U0001F92F|\U0001F300-\U0001F5FF|\U0001F680-\U0001F6FF|\U0001F190-\U0001F1FF|\U00002702-\U000027B0|\U0001F926-\U0001FA9F|\u200d|\u2640-\u2642|\u2600-\u2B55|\u23cf|\u23e9|\u231a|\ufe0f)]+','')
    
    msg_digit=msg_emoj.str.replace(r'[0-9]', ' ')

    msg_Spac = msg_digit.str.replace(r'_',' ')

    msg_Spac = msg_Spac.str.replace(r'.','')

    msg_Spac = msg_Spac.str.replace(r'!','')

    msg_Spac = msg_Spac.str.replace(r'#','')

    msg_Spac = msg_Spac.str.replace(r'%','')

    msg_Spac = msg_Spac.str.replace(r'&','')

    msg_Spac = msg_Spac.str.replace(r'â€™','')

    msg_Spac = msg_Spac.str.replace(r'(','')

    msg_Spac = msg_Spac.str.replace(r')','')

    msg_Spac = msg_Spac.str.replace(r'-','')

    msg_Spac = msg_Spac.str.replace(r'/','')

    msg_Spac = msg_Spac.str.replace(r':','')

    msg_Spac = msg_Spac.str.replace(r';','')

    msg_Spac = msg_Spac.str.replace(r'<','')

    msg_Spac = msg_Spac.str.replace(r'=','')

    msg_Spac = msg_Spac.str.replace(r'>','')

    msg_Spac = msg_Spac.str.replace(r'?','')

    msg_Spac = msg_Spac.str.replace(r'@','')

    msg_Spac = msg_Spac.str.replace(r'[','')

    msg_Spac = msg_Spac.str.replace(r']','')

    msg_Spac = msg_Spac.str.replace(r'^','')

    msg_Spac = msg_Spac.str.replace(r'{','')

    msg_Spac = msg_Spac.str.replace(r'}','')

    msg_Spac = msg_Spac.str.replace(r'|','')

    msg_Spac = msg_Spac.str.replace(r'~','')

    msg_Spac = msg_Spac.str.replace(r'+','')

    msg_Spac = msg_Spac.str.replace(r'\s+', ' ')


    return msg_Spac

msg_Train=emoji(msg)

msg_Dev=emoji(msgDev)

#msg_Test=emoji(msgTest)

Train_Df=pd.DataFrame(msg_Train)
Train_Df.columns=['Msg_with_Stopwords']

Dev_Df=pd.DataFrame(msg_Dev)
Dev_Df.columns=['Msg_with_Stopwords']

Train_Df.shape, Dev_Df.shape

# Removing Null Values

Train_Df['Msg_with_Stopwords']=Train_Df['Msg_with_Stopwords'].fillna("")

Dev_Df['Msg_with_Stopwords']=Dev_Df['Msg_with_Stopwords'].fillna("")

#Test_Df['Msg_with_Stopwords']=Test_Df['Msg_with_Stopwords'].fillna("")

Mal_train.shape, Mal_Dev.shape,Train_Df.shape, Dev_Df.shape

import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

stop_words = set(stopwords.words('english'))

Train_Df['Msg_without_Stopwords']=Train_Df['Msg_with_Stopwords'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))

Dev_Df['Msg_without_Stopwords']=Dev_Df['Msg_with_Stopwords'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))

Train_Df['Msg_with_Stopwords_Len'] = [len(x.split()) for x in Train_Df['Msg_with_Stopwords'].tolist()]
Train_Df['Msg_without_Stopwords_Len'] = [len(x.split()) for x in Train_Df['Msg_without_Stopwords'].tolist()]

Dev_Df['Msg_with_Stopwords_Len'] = [len(x.split()) for x in Dev_Df['Msg_with_Stopwords'].tolist()]
Dev_Df['Msg_without_Stopwords_Len'] = [len(x.split()) for x in Dev_Df['Msg_without_Stopwords'].tolist()]

Train_Data=pd.concat([Mal_train, Train_Df], axis=1)

Dev_Data=pd.concat([Mal_Dev, Dev_Df], axis=1)

Train_Data.shape, Dev_Data.shape

Train_Data

Train_Data=Train_Data.drop(['Msg_with_Stopwords','Msg_without_Stopwords_Len', 'Msg_with_Stopwords_Len', 'text'], axis=1)

Dev_Data=Dev_Data.drop(['Msg_with_Stopwords','Msg_without_Stopwords_Len', 'Msg_with_Stopwords_Len', 'text'], axis=1)

Train_Data.shape, Dev_Data.shape

Train_Data.head()

from sklearn import preprocessing
le = preprocessing.LabelEncoder()

Train_Data['Nlabel']=le.fit_transform(Train_Data['category']) 
Dev_Data['Nlabel']=le.fit_transform(Dev_Data['category'])



Train_Data=Train_Data.drop(['category'], axis=1)

Dev_Data=Dev_Data.drop(['category'], axis=1)

Train_Data.head()

Dev_Data.head()



#Train_Data=Train_Data.drop(['text1','Mixed_feelings', 'Negative', 'Positive', 'not-malayalam', 'unknown_state'], axis=1)
#Train_Data

#from sklearn.model_selection import train_test_split

#train_df, test_df = train_test_split(Train_Data, test_size=0.20)

#print('train shape: ',train_df.shape)
#print('test shape: ',test_df.shape)

from sklearn.utils import class_weight

#class_weights = class_weight.compute_class_weight('balanced',
 #                                                np.unique(Train_Data.Nlabel),
  #                                               Train_Data.Nlabel)
#class_weights

# define hyperparameter
model_args ={"reprocess_input_data": True,
             "fp16":False,
             "num_train_epochs": 4,
             "overwrite_output_dir" : True}

# Create a ClassificationModel
model = ClassificationModel(
    "bert", "bert-base-cased",
    num_labels=5,
   # pos_weight=[3.43153348, 1.50954869, 0.49487619, 2.74641314, 0.60193218],
    args=model_args
)

model.train_model(Train_Data)

from sklearn.metrics import f1_score, accuracy_score


def f1_multiclass(labels, preds):
    return f1_score(labels, preds, average='micro')
    
result, model_outputs, wrong_predictions = model.eval_model(Dev_Data, f1=f1_multiclass, acc=accuracy_score)

result

Dev_Data['Msg_without_Stopwords']

prediction=model.predict(Dev_Data['Msg_without_Stopwords'].values.tolist())

prediction

prediction=prediction[0]
prediction

import numpy as np
from sklearn.metrics import classification_report
from sklearn.metrics import cohen_kappa_score
from sklearn.metrics import precision_score, recall_score, f1_score

X_dev1=Dev_Data['Msg_without_Stopwords']
y_dev1=Dev_Data['Nlabel']

print(classification_report(y_dev1, prediction))

precision = precision_score(y_dev1, prediction, average='weighted')
print('Precision: %f' % precision)
recall = recall_score(y_dev1, prediction, average='weighted')
print('Recall: %f' % recall)
f1 = f1_score(y_dev1, prediction, average='weighted')
print('F1 score: %f' % f1)

Test_Data.head(2), Test_Data.shape

Test_Data['Msg_without_Stopwords'].values.tolist()

prediction=model.predict(Test_Data['Msg_without_Stopwords'].values.tolist())

prediction



prediction[0]

"""bert-base-cased
**bold text**{'acc': 0.616102978293791,
 'eval_loss': 1.2433846585617792,
 'f1': 0.616102978293791,
 'mcc': 0.34974590327974353}

precision    recall  f1-score   support

           0       0.28      0.21      0.24       438
           1       0.42      0.36      0.39       480
           2       0.72      0.82      0.77      2257
           3       0.56      0.52      0.54       176
           4       0.47      0.37      0.41       611

    accuracy                           0.62      3962
   macro avg       0.49      0.46      0.47      3962
weighted avg       0.59      0.62      0.60      3962

bert-base-multilingual-cased : {'acc': 0.6297324583543665,
 'eval_loss': 1.017766387397123,
 'f1': 0.6297324583543665,
 'mcc': 0.32806759314389233}

(1 Epoch)
 precision    recall  f1-score   support

           0       0.48      0.14      0.21       438
           1       0.45      0.34      0.39       480
           2       0.66      0.91      0.77      2257
           3       0.70      0.44      0.54       176
           4       0.52      0.23      0.32       611

    accuracy                           0.63      3962
   macro avg       0.56      0.41      0.45      3962
weighted avg       0.60      0.63      0.58      3962


Epochs 4
{'acc': 0.6259464916708734,
 'eval_loss': 1.1304713642945694,
 'f1': 0.6259464916708734,
 'mcc': 0.37302886520875017}

 precision    recall  f1-score   support

           0       0.28      0.21      0.24       438
           1       0.43      0.40      0.41       480
           2       0.74      0.82      0.78      2257
           3       0.63      0.57      0.60       176
           4       0.47      0.40      0.43       611

    accuracy                           0.63      3962
   macro avg       0.51      0.48      0.49      3962
weighted avg       0.60      0.63      0.61      3962

"bert", "bert-base-uncased",
**bold text**{'acc': 0.5933429811866859,
 'eval_loss': 1.2411620157888565,
 'f1': 0.5933429811866859,
 'mcc': 0.39435841651758213}
"""

tp - True positives 257
tn - True negatives 297
fp - False positives 99
fn - False negatives 147

Precision = TruePositives / (TruePositives + FalsePositives)
Precision = 45 / (45 + 5)

Recall = TruePositives / (TruePositives + FalseNegatives)
Recall = 95 / (95 + 5)
Recall = 0.95

F-Measure = (2 * Precision * Recall) / (Precision + Recall)
F-Measure = (2 * 0.633 * 0.95) / (0.633 + 0.95)
F-Measure = (2 * 0.601) / 1.583
F-Measure = 1.202 / 1.583
F-Measure = 0.759







