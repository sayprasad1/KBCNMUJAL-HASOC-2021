{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SkzwLeYdvUgm"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Malayalam\n",
    "Mal_train=pd.read_csv(\"tamil_sentiment_full_train.tsv\", sep='\\t')\n",
    "\n",
    "\n",
    "Mal_Dev=pd.read_csv(\"tamil_sentiment_full_dev.tsv\", sep='\\t')\n",
    "\n",
    "\n",
    "Mal_test=pd.read_csv(\"tamil_sentiment_full_test_withoutlabels.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vani bhojam fans hit like solli 500 like Vangi...</td>\n",
       "      <td>unknown_state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love you ajith very I like</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ennaya trailer Ku mudi Ellam nikkudhu... Vera ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vijay Annaa  Ur Maassssss Therrrrriiiiii</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>நம்ப நடே நாசாமா தான் போச்சி</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35651</th>\n",
       "      <td>ஒருவர் செய்த தவறுக்காக எல்லாரையும் பழி போடுவது...</td>\n",
       "      <td>Mixed_feelings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35652</th>\n",
       "      <td>Repeated Mode to Watching Theri Trailer &amp; Ther...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35653</th>\n",
       "      <td>yeevanikuachu  pula kutti erudhal oodi poyidu....</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35654</th>\n",
       "      <td>She is looking like laughing budha</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35655</th>\n",
       "      <td>NORTH OR SOUTH KGF IS THE BEST!!</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35656 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text        category\n",
       "0      Vani bhojam fans hit like solli 500 like Vangi...   unknown_state\n",
       "1                           I love you ajith very I like        Positive\n",
       "2      ennaya trailer Ku mudi Ellam nikkudhu... Vera ...        Positive\n",
       "3               Vijay Annaa  Ur Maassssss Therrrrriiiiii        Positive\n",
       "4                            நம்ப நடே நாசாமா தான் போச்சி        Negative\n",
       "...                                                  ...             ...\n",
       "35651  ஒருவர் செய்த தவறுக்காக எல்லாரையும் பழி போடுவது...  Mixed_feelings\n",
       "35652  Repeated Mode to Watching Theri Trailer & Ther...        Positive\n",
       "35653  yeevanikuachu  pula kutti erudhal oodi poyidu....        Negative\n",
       "35654                 She is looking like laughing budha        Positive\n",
       "35655                   NORTH OR SOUTH KGF IS THE BEST!!        Positive\n",
       "\n",
       "[35656 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mal_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                text       category\n",
       " 0  Vani bhojam fans hit like solli 500 like Vangi...  unknown_state\n",
       " 1                       I love you ajith very I like       Positive\n",
       " 2  ennaya trailer Ku mudi Ellam nikkudhu... Vera ...       Positive\n",
       " 3           Vijay Annaa  Ur Maassssss Therrrrriiiiii       Positive\n",
       " 4                        நம்ப நடே நாசாமா தான் போச்சி       Negative,\n",
       "                                                 text       category\n",
       " 0  @0:40 songsuperb..kamallllla..  I'm waiting fo...  unknown_state\n",
       " 1  கணத்ததோர் அகமுடையார் சார்பாக  படம் வெற்றி அடைய...       Positive\n",
       " 2  Thalavia neenga veera level boss and neega tha...       Positive\n",
       " 3              Oru padam patha fell.vera level music       Positive\n",
       " 4  Hairstyle than mattama iruku. Adhu mattum math...  unknown_state)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mal_train[0:5], Mal_Dev[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ml2en import ml2en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converter = ml2en()\n",
    "\n",
    "#desti_lang={\n",
    " #    'malayalam' : 'ml'\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for key,value in desti_lang.items():\n",
    "#     #print(transt.translate(Mal_train['text']))\n",
    "  #      Mal_train['text1']=Mal_train['text'].apply(lambda x: converter.transliterate(x))\n",
    "    #    Mal_Dev['text1']=Mal_Dev['text'].apply(lambda x: converter.transliterate(x))\n",
    "  #      Mal_test['text1']=Mal_test['text'].apply(lambda x: converter.transliterate(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Today trailer paaka yaarellam wait panreenga</td>\n",
       "      <td>unknown_state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>mayiru maadiri iruku thevidiya pasagala Rajini...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Saguni padam madhiri theriudhu,soori irukkurad...</td>\n",
       "      <td>Mixed_feelings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Ada paavingala mangatha theme. Aaa. Slow. Moti...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Kangana look like same I just love this first ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>wowwwwwwwwww thalaya aaaaaa masssssssss dialog...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>3 supar dupar star akshaya rajnikant and any j...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Coffee solunga marana masss thala</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>598K left for 15M views</td>\n",
       "      <td>unknown_state</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text        category\n",
       "61       Today trailer paaka yaarellam wait panreenga   unknown_state\n",
       "62  mayiru maadiri iruku thevidiya pasagala Rajini...        Negative\n",
       "63  Saguni padam madhiri theriudhu,soori irukkurad...  Mixed_feelings\n",
       "64  Ada paavingala mangatha theme. Aaa. Slow. Moti...        Negative\n",
       "65  Kangana look like same I just love this first ...        Positive\n",
       "66  wowwwwwwwwww thalaya aaaaaa masssssssss dialog...        Positive\n",
       "67  3 supar dupar star akshaya rajnikant and any j...        Positive\n",
       "68                  Coffee solunga marana masss thala        Positive\n",
       "69                            598K left for 15M views   unknown_state"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mal_train[61:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@0:40 songsuperb..kamallllla..  I'm waiting fo...</td>\n",
       "      <td>unknown_state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>கணத்ததோர் அகமுடையார் சார்பாக  படம் வெற்றி அடைய...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thalavia neenga veera level boss and neega tha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oru padam patha fell.vera level music</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hairstyle than mattama iruku. Adhu mattum math...</td>\n",
       "      <td>unknown_state</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       category\n",
       "0  @0:40 songsuperb..kamallllla..  I'm waiting fo...  unknown_state\n",
       "1  கணத்ததோர் அகமுடையார் சார்பாக  படம் வெற்றி அடைய...       Positive\n",
       "2  Thalavia neenga veera level boss and neega tha...       Positive\n",
       "3              Oru padam patha fell.vera level music       Positive\n",
       "4  Hairstyle than mattama iruku. Adhu mattum math...  unknown_state"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mal_Dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tam_1</td>\n",
       "      <td>வீர செங்குந்தர் சார்பாக இந்த திரைப்படம் வெற்றி...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tam_2</td>\n",
       "      <td>Teruk ah irukku .... mokke movie .. waste of time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tam_3</td>\n",
       "      <td>manitha samuthaayam amaipil irunthu intha pada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tam_4</td>\n",
       "      <td>JJ mam we miss u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tam_5</td>\n",
       "      <td>Subtitle me traller dekhne wale like karo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text\n",
       "0  Tam_1  வீர செங்குந்தர் சார்பாக இந்த திரைப்படம் வெற்றி...\n",
       "1  Tam_2  Teruk ah irukku .... mokke movie .. waste of time\n",
       "2  Tam_3  manitha samuthaayam amaipil irunthu intha pada...\n",
       "3  Tam_4                                   JJ mam we miss u\n",
       "4  Tam_5          Subtitle me traller dekhne wale like karo"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mal_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35656, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mal_train=Mal_train.replace(to_replace =[\"Positive \"], value =\"Positive\") \n",
    "Mal_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2146,
     "status": "ok",
     "timestamp": 1609999165830,
     "user": {
      "displayName": "Prasad Joshi",
      "photoUrl": "",
      "userId": "09800632122724335955"
     },
     "user_tz": -330
    },
    "id": "cQqJeR_syJYi",
    "outputId": "058d8c57-49fb-4442-ef55-868a3ea3609f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive          20070\n",
       "unknown_state      5628\n",
       "Negative           4271\n",
       "Mixed_feelings     4020\n",
       "not-Tamil          1667\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "Mal_train['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2352,
     "status": "ok",
     "timestamp": 1609999166818,
     "user": {
      "displayName": "Prasad Joshi",
      "photoUrl": "",
      "userId": "09800632122724335955"
     },
     "user_tz": -330
    },
    "id": "bchq8x31680D",
    "outputId": "097f0311-3aca-4220-a26f-07bfc9697ef2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive          2257\n",
       "unknown_state      611\n",
       "Negative           480\n",
       "Mixed_feelings     438\n",
       "not-Tamil          176\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Development \n",
    "Mal_Dev['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZtfvQ60W5mKf"
   },
   "outputs": [],
   "source": [
    "msg=Mal_train['text']\n",
    "\n",
    "msgDev=Mal_Dev['text']\n",
    "\n",
    "msgTest=Mal_test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50    Bigil=like Kaithi= cmnt Idhu epdi irruku vj fn...\n",
       "51    Camne bole trending kt malaysia? Yg dri malays...\n",
       "52             Auto like alludhu vekkama illayada?? Thu\n",
       "53    Itha paartha kaapan maathiri illa adhavan 2 ma...\n",
       "54                         333k likes thala Ajith storm\n",
       "55    மோகன் அண்ணா மேன்மேலும் திரைப்படத்துறையில் வளர ...\n",
       "56    01.Namba kita kaadu iruntha eduthukuvango 02.r...\n",
       "57    சாதிய ஒழிக்கனுனு koovitu... சாதி வெறி புடிச்ச ...\n",
       "58    I think sema line Ravi pidisu irukaaru. Sema j...\n",
       "59    Like here like here nu solravanga enaku like p...\n",
       "60    அடுத்தவங்க இசையை பயன்படுத்துகிறவங்க எல்லாம்......\n",
       "61    My fevret Hero Akshay kumar  Supar Dupar hogi ...\n",
       "62    VANNIYAR kottai dharmapuri padaiyachi Vanniyar...\n",
       "63                    Pwoli  rakshit shetty kerala fans\n",
       "64    Simbu zindhabad from all kannada power  puneet...\n",
       "65    Avalavu nalla illai.. I'm not a superstar hate...\n",
       "66                          Str da ..goyala str fans da\n",
       "67           Padoo mass ah iruka podhu but tn la odadhu\n",
       "68    Fans show 1.o clock porom massss kaaatrom sury...\n",
       "69                    Waiting  to seeeeeeeeee Anna mass\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgDev[50:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "lm3rhwEOyBP3"
   },
   "outputs": [],
   "source": [
    "#Remove Emojis\n",
    "\n",
    "def emoji(msg): \n",
    "    \n",
    "    msg_emoj=msg.str.replace(r'[(\\U0001F600-\\U0001F92F|\\U0001F300-\\U0001F5FF|\\U0001F680-\\U0001F6FF|\\U0001F190-\\U0001F1FF|\\U00002702-\\U000027B0|\\U0001F926-\\U0001FA9F|\\u200d|\\u2640-\\u2642|\\u2600-\\u2B55|\\u23cf|\\u23e9|\\u231a|\\ufe0f)]+','')\n",
    "    \n",
    "    msg_digit=msg_emoj.str.replace(r'[0-9]', ' ')\n",
    "\n",
    "    msg_Spac = msg_digit.str.replace(r'_',' ')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'.','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'!','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'#','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'%','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'&','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'’','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'(','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r')','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'-','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'/','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r':','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r';','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'<','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'=','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'>','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'?','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'@','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'[','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r']','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'^','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'{','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'}','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'|','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'~','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'+','')\n",
    "\n",
    "    msg_Spac = msg_Spac.str.replace(r'\\s+', ' ')\n",
    "\n",
    "\n",
    "    return msg_Spac\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3ApjI62l9vRw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \"\"\"\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  import sys\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:47: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:51: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:53: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:55: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:61: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    }
   ],
   "source": [
    "msg_Train=emoji(msg)\n",
    "\n",
    "msg_Dev=emoji(msgDev)\n",
    "\n",
    "msg_Test=emoji(msgTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24322,
     "status": "ok",
     "timestamp": 1609999200406,
     "user": {
      "displayName": "Prasad Joshi",
      "photoUrl": "",
      "userId": "09800632122724335955"
     },
     "user_tz": -330
    },
    "id": "sGXx0i5S_11T",
    "outputId": "58bdc1d4-f8b5-440a-d52f-5dcc777b2b56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78    Cmnt section pona like here like here nu uyira...\n",
       " 79                        tranding kyu ni aa rahi h yrr\n",
       " 80                  Mrana Mass iliya suppr star DHANUSH\n",
       " 81    vera level pakka blockbuster for sure all d be...\n",
       " 82    வன்னியர் சாதி சார்பாக படம் வெற்றி பெற வாழ்த்து...\n",
       " 83             Yuvan bgm vera level i love u yuvan anna\n",
       " 84    Rishi Richard Fans Club சார்பாக படம் வெற்றியடை...\n",
       " 85    ஜெயம் ரவி அண்ணா வாழ்த்துக்கள் நீங்க இதே மாதிரி...\n",
       " 86    படம் வெற்றிகரமாக அமைய வாழ்த்துக்கள் செளராஷ்டிர...\n",
       " 87                      what is this rubbish Ayoooo ayo\n",
       " 88            தரமா டீஸர் அதேபோல் படமும் தரமாக இருக்கும்\n",
       " 89    Maximum intha mathiri msg kudukara reality Fil...\n",
       " Name: text, dtype: object,\n",
       " 50    Bigillike Kaithi cmnt Idhu epdi irruku vj fns ...\n",
       " 51    Camne bole trending kt malaysia Yg dri malaysi...\n",
       " 52               Auto like alludhu vekkama illayada Thu\n",
       " 53    Itha paartha kaapan maathiri illa adhavan maat...\n",
       " 54                            k likes thala Ajith storm\n",
       " 55    மோகன் அண்ணா மேன்மேலும் திரைப்படத்துறையில் வளர ...\n",
       " 56     Namba kita kaadu iruntha eduthukuvango ruuva ...\n",
       " 57    சாதிய ஒழிக்கனுனு koovitu சாதி வெறி புடிச்ச தேவ...\n",
       " 58    I think sema line Ravi pidisu irukaaru Sema jo...\n",
       " 59    Like here like here nu solravanga enaku like p...\n",
       " 60    அடுத்தவங்க இசையை பயன்படுத்துகிறவங்க எல்லாம் ஆண...\n",
       " 61    My fevret Hero Akshay kumar Supar Dupar hogi M...\n",
       " 62    VANNIYAR kottai dharmapuri padaiyachi Vanniyar...\n",
       " 63                     Pwoli rakshit shetty kerala fans\n",
       " 64    Simbu zindhabad from all kannada power puneeth...\n",
       " 65    Avalavu nalla illai I'm not a superstar hater ...\n",
       " 66                            Str da goyala str fans da\n",
       " 67           Padoo mass ah iruka podhu but tn la odadhu\n",
       " 68    Fans show o clock porom massss kaaatrom surya ...\n",
       " 69                     Waiting to seeeeeeeeee Anna mass\n",
       " Name: text, dtype: object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_Train[78:90], msg_Dev[50:70], #msg_Test[21:22]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "SUaNKv6xFlNj"
   },
   "outputs": [],
   "source": [
    "Train_Df=pd.DataFrame(msg_Train)\n",
    "Train_Df.columns=['Msg_with_Stopwords']\n",
    "\n",
    "Dev_Df=pd.DataFrame(msg_Dev)\n",
    "Dev_Df.columns=['Msg_with_Stopwords']\n",
    "\n",
    "Test_Df=pd.DataFrame(msg_Test)\n",
    "Test_Df.columns=['Msg_with_Stopwords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25306,
     "status": "ok",
     "timestamp": 1609999202380,
     "user": {
      "displayName": "Prasad Joshi",
      "photoUrl": "",
      "userId": "09800632122724335955"
     },
     "user_tz": -330
    },
    "id": "PdAGnkd4GYQh",
    "outputId": "467cd839-4f5a-41b4-99af-4a6245a87e91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35656, 1), (3962, 1), (4402, 1))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Df.shape, Dev_Df.shape, Test_Df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "cfybAk87L1Rf"
   },
   "outputs": [],
   "source": [
    "# Removing Null Values\n",
    "\n",
    "Train_Df['Msg_with_Stopwords']=Train_Df['Msg_with_Stopwords'].fillna(\"\")\n",
    "\n",
    "Dev_Df['Msg_with_Stopwords']=Dev_Df['Msg_with_Stopwords'].fillna(\"\")\n",
    "\n",
    "Test_Df['Msg_with_Stopwords']=Test_Df['Msg_with_Stopwords'].fillna(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35656, 2), (3962, 2), (35656, 1), (3962, 1), (4402, 1))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mal_train.shape, Mal_Dev.shape,Train_Df.shape, Dev_Df.shape, Test_Df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24536,
     "status": "ok",
     "timestamp": 1609999202387,
     "user": {
      "displayName": "Prasad Joshi",
      "photoUrl": "",
      "userId": "09800632122724335955"
     },
     "user_tz": -330
    },
    "id": "IsNaEIX1QWXp",
    "outputId": "68a6f472-f848-49fd-f9ea-1a997d2c0f8c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Joshi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ovLeV1EDQYeq"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "qlDvZ2m6QwTt"
   },
   "outputs": [],
   "source": [
    "Train_Df['Msg_without_Stopwords']=Train_Df['Msg_with_Stopwords'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "Dev_Df['Msg_without_Stopwords']=Dev_Df['Msg_with_Stopwords'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "Test_Df['Msg_without_Stopwords']=Test_Df['Msg_with_Stopwords'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "2UgF7xDSRAI_"
   },
   "outputs": [],
   "source": [
    "Train_Df['Msg_with_Stopwords_Len'] = [len(x.split()) for x in Train_Df['Msg_with_Stopwords'].tolist()]\n",
    "Train_Df['Msg_without_Stopwords_Len'] = [len(x.split()) for x in Train_Df['Msg_without_Stopwords'].tolist()]\n",
    "\n",
    "Dev_Df['Msg_with_Stopwords_Len'] = [len(x.split()) for x in Dev_Df['Msg_with_Stopwords'].tolist()]\n",
    "Dev_Df['Msg_without_Stopwords_Len'] = [len(x.split()) for x in Dev_Df['Msg_without_Stopwords'].tolist()]\n",
    "\n",
    "Test_Df['Msg_with_Stopwords_Len'] = [len(x.split()) for x in Test_Df['Msg_with_Stopwords'].tolist()]\n",
    "Test_Df['Msg_without_Stopwords_Len'] = [len(x.split()) for x in Test_Df['Msg_without_Stopwords'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "TdI70ZELRKHB"
   },
   "outputs": [],
   "source": [
    "Train_Data=pd.concat([Mal_train, Train_Df], axis=1)\n",
    "\n",
    "Dev_Data=pd.concat([Mal_Dev, Dev_Df], axis=1)\n",
    "\n",
    "Test_Data=pd.concat([Mal_test, Test_Df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3236,
     "status": "ok",
     "timestamp": 1609999217534,
     "user": {
      "displayName": "Prasad Joshi",
      "photoUrl": "",
      "userId": "09800632122724335955"
     },
     "user_tz": -330
    },
    "id": "yQ0eeiJUITpX",
    "outputId": "1811020a-d139-4a9e-c992-eaed5bf5119f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35656, 6), (3962, 6), (4402, 6))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Data.shape, Dev_Data.shape, Test_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "eb5iWB0DRXE7"
   },
   "outputs": [],
   "source": [
    "Train_Data=Train_Data.drop(['Msg_with_Stopwords','Msg_without_Stopwords_Len', 'Msg_with_Stopwords_Len', 'text'], axis=1)\n",
    "\n",
    "Dev_Data=Dev_Data.drop(['Msg_with_Stopwords','Msg_without_Stopwords_Len', 'Msg_with_Stopwords_Len', 'text'], axis=1)\n",
    "\n",
    "Test_Data=Test_Data.drop(['Msg_with_Stopwords','Msg_without_Stopwords_Len', 'Msg_with_Stopwords_Len', 'text'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3167,
     "status": "ok",
     "timestamp": 1609999220300,
     "user": {
      "displayName": "Prasad Joshi",
      "photoUrl": "",
      "userId": "09800632122724335955"
     },
     "user_tz": -330
    },
    "id": "4fVP3iTOKQvw",
    "outputId": "14c881d6-0970-4f19-ab31-a37fbbf3dcd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35656, 2), (3962, 2), (4402, 2))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset Train & Dev are : (1) Message_Without_Stopwords and (2) labels\n",
    "# Only Test is : (1) Message_Without_Stopwords\n",
    "Train_Data.shape, Dev_Data.shape, Test_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>Msg_without_Stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Cmnt section pona like like nu uyira vanguvanu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>not-Tamil</td>\n",
       "      <td>tranding kyu ni aa rahi h yrr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Mrana Mass iliya suppr star DHANUSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Positive</td>\n",
       "      <td>vera level pakka blockbuster sure best anna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Positive</td>\n",
       "      <td>வன்னியர் சாதி சார்பாக படம் வெற்றி பெற வாழ்த்து...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Yuvan bgm vera level love u yuvan anna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Rishi Richard Fans Club சார்பாக படம் வெற்றியடை...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Positive</td>\n",
       "      <td>ஜெயம் ரவி அண்ணா வாழ்த்துக்கள் நீங்க இதே மாதிரி...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Positive</td>\n",
       "      <td>படம் வெற்றிகரமாக அமைய வாழ்த்துக்கள் செளராஷ்டிர...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Negative</td>\n",
       "      <td>rubbish Ayoooo ayo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Positive</td>\n",
       "      <td>தரமா டீஸர் அதேபோல் படமும் தரமாக இருக்கும்</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Maximum intha mathiri msg kudukara reality Fil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     category                              Msg_without_Stopwords\n",
       "78   Positive  Cmnt section pona like like nu uyira vanguvanu...\n",
       "79  not-Tamil                      tranding kyu ni aa rahi h yrr\n",
       "80   Positive                Mrana Mass iliya suppr star DHANUSH\n",
       "81   Positive        vera level pakka blockbuster sure best anna\n",
       "82   Positive  வன்னியர் சாதி சார்பாக படம் வெற்றி பெற வாழ்த்து...\n",
       "83   Positive             Yuvan bgm vera level love u yuvan anna\n",
       "84   Positive  Rishi Richard Fans Club சார்பாக படம் வெற்றியடை...\n",
       "85   Positive  ஜெயம் ரவி அண்ணா வாழ்த்துக்கள் நீங்க இதே மாதிரி...\n",
       "86   Positive  படம் வெற்றிகரமாக அமைய வாழ்த்துக்கள் செளராஷ்டிர...\n",
       "87   Negative                                 rubbish Ayoooo ayo\n",
       "88   Positive          தரமா டீஸர் அதேபோல் படமும் தரமாக இருக்கும்\n",
       "89   Positive  Maximum intha mathiri msg kudukara reality Fil..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Data[78:90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>Msg_without_Stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unknown_state</td>\n",
       "      <td>songsuperbkamallllla I'm waiting dis song</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>கணத்ததோர் அகமுடையார் சார்பாக படம் வெற்றி அடைய ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Thalavia neenga veera level boss neega thaan m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Oru padam patha fellvera level music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unknown_state</td>\n",
       "      <td>Hairstyle mattama iruku Adhu mattum mathirukal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>Positive</td>\n",
       "      <td>நாடக காதல் மிகப்பெரிய தவறு இதை தான் இந்த படம் ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>not-Tamil</td>\n",
       "      <td>So long see suriya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3959</th>\n",
       "      <td>Mixed_feelings</td>\n",
       "      <td>Super sK ettan adipoli makkalle dec waiting sK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3960</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Minimum viewa vara veppoma thala fans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3961</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Vera Vera level da version</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            category                              Msg_without_Stopwords\n",
       "0      unknown_state          songsuperbkamallllla I'm waiting dis song\n",
       "1           Positive  கணத்ததோர் அகமுடையார் சார்பாக படம் வெற்றி அடைய ...\n",
       "2           Positive  Thalavia neenga veera level boss neega thaan m...\n",
       "3           Positive               Oru padam patha fellvera level music\n",
       "4      unknown_state  Hairstyle mattama iruku Adhu mattum mathirukal...\n",
       "...              ...                                                ...\n",
       "3957        Positive  நாடக காதல் மிகப்பெரிய தவறு இதை தான் இந்த படம் ...\n",
       "3958       not-Tamil                                 So long see suriya\n",
       "3959  Mixed_feelings  Super sK ettan adipoli makkalle dec waiting sK...\n",
       "3960        Positive              Minimum viewa vara veppoma thala fans\n",
       "3961        Positive                         Vera Vera level da version\n",
       "\n",
       "[3962 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dev_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Msg_without_Stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tam_1</td>\n",
       "      <td>வீர செங்குந்தர் சார்பாக இந்த திரைப்படம் வெற்றி...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tam_2</td>\n",
       "      <td>Teruk ah irukku mokke movie waste time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tam_3</td>\n",
       "      <td>manitha samuthaayam amaipil irunthu intha pada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tam_4</td>\n",
       "      <td>JJ mam miss u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tam_5</td>\n",
       "      <td>Subtitle traller dekhne wale like karo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4397</th>\n",
       "      <td>Tam_4398</td>\n",
       "      <td>Ithukum dislike potta kammanattti koovaingalam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>Tam_4399</td>\n",
       "      <td>Suyama Sinthikiravan super Hero Seama dialogue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>Tam_4400</td>\n",
       "      <td>Super thalaiva Nee mass dha eppavume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>Tam_4401</td>\n",
       "      <td>பெண்ணை அடிமையாக்க நினைக்கும் இந்த படம் தோல்வித...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>Tam_4402</td>\n",
       "      <td>Semma thalaiva alu athikama akirukum enimale e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4402 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                              Msg_without_Stopwords\n",
       "0        Tam_1  வீர செங்குந்தர் சார்பாக இந்த திரைப்படம் வெற்றி...\n",
       "1        Tam_2             Teruk ah irukku mokke movie waste time\n",
       "2        Tam_3  manitha samuthaayam amaipil irunthu intha pada...\n",
       "3        Tam_4                                      JJ mam miss u\n",
       "4        Tam_5             Subtitle traller dekhne wale like karo\n",
       "...        ...                                                ...\n",
       "4397  Tam_4398  Ithukum dislike potta kammanattti koovaingalam...\n",
       "4398  Tam_4399     Suyama Sinthikiravan super Hero Seama dialogue\n",
       "4399  Tam_4400               Super thalaiva Nee mass dha eppavume\n",
       "4400  Tam_4401  பெண்ணை அடிமையாக்க நினைக்கும் இந்த படம் தோல்வித...\n",
       "4401  Tam_4402  Semma thalaiva alu athikama akirukum enimale e...\n",
       "\n",
       "[4402 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=Train_Data.Msg_without_Stopwords\n",
    "x_dev=Dev_Data.Msg_without_Stopwords\n",
    "x_test=Test_Data.Msg_without_Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "Train_Data['Nlabel']=le.fit_transform(Train_Data['category']) \n",
    "Dev_Data['Nlabel']=le.fit_transform(Dev_Data['category']) \n",
    "\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "y_train=Train_Data['Nlabel']\n",
    "y_dev=Dev_Data['Nlabel']\n",
    "\n",
    "y_train1 = to_categorical(y_train)\n",
    "y_dev1 = to_categorical(y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "num_labels = 5\n",
    "vocab_size = 10000\n",
    "batch_size = 100\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = tokenizer.texts_to_matrix(x_train)\n",
    "\n",
    "X_dev1 = tokenizer.texts_to_matrix(x_dev)\n",
    "\n",
    "X_test1=tokenizer.texts_to_matrix(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35656, 10000), (3962, 10000), (35656, 5), (3962, 5))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.shape, X_dev1.shape, y_train1.shape, y_dev1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train1), type(y_train1), type(X_dev1), type(y_dev1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.utils import class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.77393035, 1.66967923, 0.35531639, 4.27786443, 1.26709311])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Mode / ANN F1 score = 0.69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               5120512   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 2565      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 5,385,733\n",
      "Trainable params: 5,385,733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#let us build a basic model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, input_shape=(vocab_size,)),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(512),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(num_labels),\n",
    "    keras.layers.Activation('softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35656 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000002687AF34168> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000002687AF34168> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "35656/35656 - 20s - loss: 1.0468 - accuracy: 0.6055\n",
      "Epoch 2/10\n",
      "35656/35656 - 17s - loss: 0.7647 - accuracy: 0.7152\n",
      "Epoch 3/10\n",
      "35656/35656 - 17s - loss: 0.4921 - accuracy: 0.8257\n",
      "Epoch 4/10\n",
      "35656/35656 - 17s - loss: 0.2696 - accuracy: 0.9083\n",
      "Epoch 5/10\n",
      "35656/35656 - 17s - loss: 0.1610 - accuracy: 0.9486\n",
      "Epoch 6/10\n",
      "35656/35656 - 17s - loss: 0.1056 - accuracy: 0.9677\n",
      "Epoch 7/10\n",
      "35656/35656 - 17s - loss: 0.0799 - accuracy: 0.9748\n",
      "Epoch 8/10\n",
      "35656/35656 - 17s - loss: 0.0648 - accuracy: 0.9799\n",
      "Epoch 9/10\n",
      "35656/35656 - 17s - loss: 0.0567 - accuracy: 0.9826\n",
      "Epoch 10/10\n",
      "35656/35656 - 17s - loss: 0.0505 - accuracy: 0.9837\n"
     ]
    }
   ],
   "source": [
    "num_epochs =10\n",
    "batch_size = 128\n",
    "history = model.fit(X_train1, y_train1, batch_size=batch_size, epochs=num_epochs,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_dev1,y_dev1,X_test1):\n",
    "    loss, accuracy = model.evaluate(X_dev1,y_dev1,verbose=0)\n",
    "    print('Accuracy: %f' % (accuracy*100))\n",
    "    print('Loss: %f' % (loss*100))\n",
    "    y_pred=model.predict_classes(X_dev1)\n",
    "\n",
    "    # predict \n",
    "    predictions = model.predict(X_dev1, batch_size = 32)\n",
    "    pred = np.argmax(predictions, axis=1)\n",
    "    # label\n",
    "    y_dev1 = np.argmax(y_dev1, axis=1)\n",
    "    \n",
    "    print(classification_report(y_dev1, pred))\n",
    "    \n",
    "    cohen_score = cohen_kappa_score(y_dev1, pred)\n",
    "    print(\"Cohen Score: \",cohen_score)\n",
    "    ##### PREDICTING test values ######\n",
    "    y_pred=model.predict_classes(X_test1)\n",
    "    df = pd.DataFrame(y_pred, columns = ['result'])\n",
    "    \n",
    "    precision = precision_score(y_dev1, pred, average='weighted')\n",
    "    print('Precision: %f' % precision)\n",
    "\n",
    "    recall = recall_score(y_dev1, pred, average='weighted')\n",
    "    print('Recall: %f' % recall)\n",
    "\n",
    "    f1 = f1_score(y_dev1, pred, average='weighted')\n",
    "    print('F1 score: %f' % f1)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.682483\n",
      "Loss: 273.856671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.17      0.19       438\n",
      "           1       0.39      0.36      0.38       480\n",
      "           2       0.72      0.78      0.75      2257\n",
      "           3       0.55      0.51      0.53       176\n",
      "           4       0.41      0.36      0.38       611\n",
      "\n",
      "    accuracy                           0.59      3962\n",
      "   macro avg       0.46      0.44      0.45      3962\n",
      "weighted avg       0.57      0.59      0.58      3962\n",
      "\n",
      "Cohen Score:  0.3112951396875011\n",
      "Precision: 0.567179\n",
      "Recall: 0.586825\n",
      "F1 score: 0.575650\n"
     ]
    }
   ],
   "source": [
    "df=predict(X_dev1,y_dev1,X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4397</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4402 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result\n",
       "0          2\n",
       "1          1\n",
       "2          2\n",
       "3          2\n",
       "4          1\n",
       "...      ...\n",
       "4397       0\n",
       "4398       2\n",
       "4399       2\n",
       "4400       0\n",
       "4401       2\n",
       "\n",
       "[4402 rows x 1 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>வீர செங்குந்தர் சார்பாக இந்த திரைப்படம் வெற்றி...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Teruk ah irukku mokke movie waste time</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>manitha samuthaayam amaipil irunthu intha pada...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JJ mam miss u</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subtitle traller dekhne wale like karo</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4397</th>\n",
       "      <td>Ithukum dislike potta kammanattti koovaingalam...</td>\n",
       "      <td>Mixed_feelings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>Suyama Sinthikiravan super Hero Seama dialogue</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>Super thalaiva Nee mass dha eppavume</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>பெண்ணை அடிமையாக்க நினைக்கும் இந்த படம் தோல்வித...</td>\n",
       "      <td>Mixed_feelings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>Semma thalaiva alu athikama akirukum enimale e...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4402 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text           label\n",
       "0     வீர செங்குந்தர் சார்பாக இந்த திரைப்படம் வெற்றி...        Positive\n",
       "1                Teruk ah irukku mokke movie waste time        Negative\n",
       "2     manitha samuthaayam amaipil irunthu intha pada...        Positive\n",
       "3                                         JJ mam miss u        Positive\n",
       "4                Subtitle traller dekhne wale like karo        Negative\n",
       "...                                                 ...             ...\n",
       "4397  Ithukum dislike potta kammanattti koovaingalam...  Mixed_feelings\n",
       "4398     Suyama Sinthikiravan super Hero Seama dialogue        Positive\n",
       "4399               Super thalaiva Nee mass dha eppavume        Positive\n",
       "4400  பெண்ணை அடிமையாக்க நினைக்கும் இந்த படம் தோல்வித...  Mixed_feelings\n",
       "4401  Semma thalaiva alu athikama akirukum enimale e...        Positive\n",
       "\n",
       "[4402 rows x 2 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINAL=pd.concat([Test_Data.Msg_without_Stopwords, df], axis=1)\n",
    "FINAL=FINAL.rename(columns={\"Msg_without_Stopwords\": \"text\", \"result\": \"label\"})\n",
    "\n",
    "FINAL['label'] = FINAL['label'].map({0 : 'Mixed_feelings', 1 : 'Negative', 2: 'Positive', 3 :'not-Tamil', 4 : 'unknown_state'})\n",
    "FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL.to_csv(\"ANN_Tamil_HASOC21.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import confusion_matrix, classification_report\n",
    "#from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "\n",
    "#def emoji(y_Dev, X_Dev1, model): \n",
    "  # y_Dev1 = to_categorical(y_Dev)\n",
    " #   loss, accuracy = model.evaluate(X_Dev1,y_Dev, verbose=0)\n",
    "  #  print('Accuracy: %f' % (accuracy*100))\n",
    "   # print('Loss: %f' % (loss*100))\n",
    "    #\n",
    "    #y_pred=model.predict_classes(X_Dev1)\n",
    "\n",
    "    \n",
    "    # predict \n",
    "    #predictions = model.predict(X_Dev1, batch_size = 32)\n",
    "    #pred = np.argmax(predictions, axis=1)\n",
    "    # label\n",
    "    #y_Dev1 = np.argmax(y_Dev, axis=1)\n",
    "    \n",
    "   # print(classification_report(y_Dev1, pred))\n",
    "    \n",
    "    #cohen_score = cohen_kappa_score(y_Dev1, pred)\n",
    "    #print(\"Cohen Score: \",cohen_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.647792\n",
      "Loss: 921.951864\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.36      0.40       102\n",
      "           1       0.60      0.52      0.56       237\n",
      "           2       0.71      0.80      0.75       706\n",
      "           3       0.76      0.52      0.62       141\n",
      "           4       0.65      0.65      0.65       580\n",
      "\n",
      "    accuracy                           0.67      1766\n",
      "   macro avg       0.63      0.57      0.60      1766\n",
      "weighted avg       0.66      0.67      0.66      1766\n",
      "\n",
      "Cohen Score:  0.5158853789727409\n"
     ]
    }
   ],
   "source": [
    "#emoji(y_dev1, X_dev1, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:638: FutureWarning: Pass sampling_strategy=minority as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "e:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1 2 3 4] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54059, 10000) (54059, 5)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE('minority')\n",
    "\n",
    "\n",
    "X_sm, y_sm = smote.fit_sample(X_train1, y_train1)\n",
    "print(X_sm.shape, y_sm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54059 samples\n",
      "Epoch 1/10\n",
      "54059/54059 - 63s - loss: 0.0397 - accuracy: 0.9885\n",
      "Epoch 2/10\n",
      "54059/54059 - 25s - loss: 0.0357 - accuracy: 0.9892\n",
      "Epoch 3/10\n",
      "54059/54059 - 26s - loss: 0.0351 - accuracy: 0.9896\n",
      "Epoch 4/10\n",
      "54059/54059 - 26s - loss: 0.0338 - accuracy: 0.9895\n",
      "Epoch 5/10\n",
      "54059/54059 - 25s - loss: 0.0323 - accuracy: 0.9902\n",
      "Epoch 6/10\n",
      "54059/54059 - 25s - loss: 0.0313 - accuracy: 0.9902\n",
      "Epoch 7/10\n",
      "54059/54059 - 25s - loss: 0.0278 - accuracy: 0.9912\n",
      "Epoch 8/10\n",
      "54059/54059 - 25s - loss: 0.0286 - accuracy: 0.9911\n",
      "Epoch 9/10\n",
      "54059/54059 - 26s - loss: 0.0308 - accuracy: 0.9903\n",
      "Epoch 10/10\n",
      "54059/54059 - 25s - loss: 0.0283 - accuracy: 0.9909\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_sm, y_sm, batch_size=batch_size, epochs=num_epochs,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1 2 3 4] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6043, 10000) (6043, 5)\n"
     ]
    }
   ],
   "source": [
    "X_Dev_sm, y_Dev_sm = smote.fit_sample(X_dev1, y_dev1)\n",
    "print(X_Dev_sm.shape, y_Dev_sm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.050471\n",
      "Loss: 280.484506\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.18      0.20       438\n",
      "           1       0.40      0.34      0.37       480\n",
      "           2       0.62      0.78      0.69      2257\n",
      "           3       0.96      0.75      0.84      2257\n",
      "           4       0.35      0.39      0.37       611\n",
      "\n",
      "    accuracy                           0.65      6043\n",
      "   macro avg       0.51      0.49      0.49      6043\n",
      "weighted avg       0.67      0.65      0.65      6043\n",
      "\n",
      "Cohen Score:  0.4969482017087453\n"
     ]
    }
   ],
   "source": [
    "df_smote=predict(X_Dev_sm,y_Dev_sm,X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4398</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4399</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4401</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4402 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result\n",
       "0          2\n",
       "1          1\n",
       "2          2\n",
       "3          2\n",
       "4          0\n",
       "...      ...\n",
       "4397       1\n",
       "4398       2\n",
       "4399       2\n",
       "4400       0\n",
       "4401       2\n",
       "\n",
       "[4402 rows x 1 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_smote' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-170-208a0b32a061>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mFINAL\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTest_Data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMsg_without_Stopwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_smote\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mFINAL\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFINAL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"Msg_without_Stopwords\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"text\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"result\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"label\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mFINAL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFINAL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;34m'Mixed_feelings'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;34m'Negative'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Positive'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;34m'not-Tamil'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;34m'unknown_state'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mFINAL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_smote' is not defined"
     ]
    }
   ],
   "source": [
    "FINAL=pd.concat([Test_Data.Msg_without_Stopwords, df_smote], axis=1)\n",
    "FINAL=FINAL.rename(columns={\"Msg_without_Stopwords\": \"text\", \"result\": \"label\"})\n",
    "\n",
    "FINAL['label'] = FINAL['label'].map({0 : 'Mixed_feelings', 1 : 'Negative', 2: 'Positive', 3 :'not-Tamil', 4 : 'unknown_state'})\n",
    "FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL.to_csv(\"ANN_Malayalam_HASOC21.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  https://shrikar.com/deep-learning-with-keras-and-python-for-multiclass-classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN F1 score = 0.70\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer= Tokenizer()\n",
    "\n",
    "# Train, Dev, Test\n",
    "word_tokenizer.fit_on_texts(Train_Data.Msg_without_Stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = max([len(s.split()) for s in Train_Data.Msg_without_Stopwords])\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69675"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define vocabulary size\n",
    "\n",
    "vocab_size = len(word_tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeded Sentences of Train\n",
    "Train_Sent = word_tokenizer.texts_to_sequences(Train_Data.Msg_without_Stopwords)\n",
    "\n",
    "# Embeded Sentences of Dev\n",
    "Dev_Sent = word_tokenizer.texts_to_sequences(Dev_Data.Msg_without_Stopwords)\n",
    "\n",
    "# Embeded Sentences of Test\n",
    "Test_Sent = word_tokenizer.texts_to_sequences(Test_Data.Msg_without_Stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train\n",
    "Train_padded_sentences = pad_sequences(Train_Sent, max_length, padding='post')\n",
    "\n",
    "# Dev\n",
    "Dev_padded_sentences = pad_sequences(Dev_Sent, max_length, padding='post')\n",
    "\n",
    "# Test\n",
    "Test_padded_sentences = pad_sequences(Test_Sent, max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1244, 20445, 12, 29, 1, 477, 1, 20446, 2032],\n",
       " array([ 1244, 20445,    12,    29,     1,   477,     1, 20446,  2032,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Sent[0],Train_padded_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 124, 100)          6967500   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 122, 64)           19264     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 6,987,089\n",
      "Trainable params: 6,987,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_CNN = keras.Sequential([\n",
    "    keras.layers.Embedding(vocab_size, 100, input_length=max_length),\n",
    "   # keras.layers.GlobalAveragePooling1D(),\n",
    "    # convolutional filters=128,  kernel size=3: it means length_long_sentence size of 65 we are luking for 3 words at a time\n",
    "    keras.layers.Conv1D(64, 3, activation='relu'),\n",
    "    keras.layers.GlobalMaxPooling1D(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "model_CNN.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_CNN.summary()\n",
    "\n",
    "\n",
    "\n",
    "#model = Sequential()\n",
    "#model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
    "#model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(10, activation='relu'))\n",
    "#model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "Train_Data['Nlabel']=le.fit_transform(Train_Data['category']) \n",
    "Dev_Data['Nlabel']=le.fit_transform(Dev_Data['category']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train=Train_Data['Nlabel']\n",
    "y_dev=Dev_Data['Nlabel']\n",
    "\n",
    "y_train1 = to_categorical(y_train)\n",
    "y_dev1 = to_categorical(y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35656, 124), (35656, 5), (3962, 124), (3962, 5), (4402, 124))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_padded_sentences.shape, y_train1.shape, Dev_padded_sentences.shape, y_dev1.shape, Test_padded_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train1), type(Train_padded_sentences), type(Dev_padded_sentences), type(y_dev1), type(Test_padded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35656, 124), (35656, 5))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_padded_sentences=np.array(Train_padded_sentences)\n",
    "y_train1=np.array(y_train1)\n",
    "\n",
    "Train_padded_sentences.shape, y_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35656 samples\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000269502FBF78> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000269502FBF78> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "35656/35656 - 46s - loss: 1.1830 - accuracy: 0.5661\n",
      "Epoch 2/5\n",
      "35656/35656 - 43s - loss: 0.9058 - accuracy: 0.6714\n",
      "Epoch 3/5\n",
      "35656/35656 - 43s - loss: 0.6398 - accuracy: 0.7849\n",
      "Epoch 4/5\n",
      "35656/35656 - 43s - loss: 0.4142 - accuracy: 0.8699\n",
      "Epoch 5/5\n",
      "35656/35656 - 42s - loss: 0.2852 - accuracy: 0.9116\n"
     ]
    }
   ],
   "source": [
    "num_epochs =5\n",
    "batch_size = 128\n",
    "history = model_CNN.fit(Train_padded_sentences, y_train1, batch_size=batch_size, epochs=num_epochs, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dev_padded_sentences=np.array(Dev_padded_sentences)\n",
    "y_dev1=np.array(y_dev1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_CNN(X_dev1,y_dev1,X_test1):\n",
    "    loss, accuracy = model_CNN.evaluate(X_dev1,y_dev1,verbose=0)\n",
    "    print('Accuracy: %f' % (accuracy*100))\n",
    "    print('Loss: %f' % (loss*100))\n",
    "    y_pred=model_CNN.predict_classes(X_dev1)\n",
    "\n",
    "    # predict \n",
    "    predictions = model_CNN.predict(X_dev1, batch_size = 32)\n",
    "    pred = np.argmax(predictions, axis=1)\n",
    "    # label\n",
    "    y_dev1 = np.argmax(y_dev1, axis=1)\n",
    "    \n",
    "    print(classification_report(y_dev1, pred))\n",
    "    \n",
    "    cohen_score = cohen_kappa_score(y_dev1, pred)\n",
    "    print(\"Cohen Score: \",cohen_score)\n",
    "    ##### PREDICTING test values ######\n",
    "    y_pred=model_CNN.predict_classes(X_test1)\n",
    "    df = pd.DataFrame(y_pred, columns = ['result'])\n",
    "    \n",
    "    precision = precision_score(y_dev1, pred, average='weighted')\n",
    "    print('Precision: %f' % precision)\n",
    "\n",
    "    recall = recall_score(y_dev1, pred, average='weighted')\n",
    "    print('Recall: %f' % recall)\n",
    "\n",
    "    f1 = f1_score(y_dev1, pred, average='weighted')\n",
    "    print('F1 score: %f' % f1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.616357\n",
      "Loss: 138.901585\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.13      0.16       438\n",
      "           1       0.44      0.32      0.37       480\n",
      "           2       0.70      0.82      0.75      2257\n",
      "           3       0.67      0.53      0.59       176\n",
      "           4       0.38      0.35      0.37       611\n",
      "\n",
      "    accuracy                           0.60      3962\n",
      "   macro avg       0.48      0.43      0.45      3962\n",
      "weighted avg       0.56      0.60      0.57      3962\n",
      "\n",
      "Cohen Score:  0.30159385598259814\n",
      "Precision: 0.562826\n",
      "Recall: 0.596164\n",
      "F1 score: 0.574063\n"
     ]
    }
   ],
   "source": [
    "df_CNN=predict_CNN(Dev_padded_sentences,y_dev1,Test_padded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>வீர செங்குந்தர் சார்பாக இந்த திரைப்படம் வெற்றி...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Teruk ah irukku mokke movie waste time</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>manitha samuthaayam amaipil irunthu intha pada...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JJ mam miss u</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subtitle traller dekhne wale like karo</td>\n",
       "      <td>not-Tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4397</th>\n",
       "      <td>Ithukum dislike potta kammanattti koovaingalam...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>Suyama Sinthikiravan super Hero Seama dialogue</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>Super thalaiva Nee mass dha eppavume</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>பெண்ணை அடிமையாக்க நினைக்கும் இந்த படம் தோல்வித...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>Semma thalaiva alu athikama akirukum enimale e...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4402 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text      label\n",
       "0     வீர செங்குந்தர் சார்பாக இந்த திரைப்படம் வெற்றி...   Positive\n",
       "1                Teruk ah irukku mokke movie waste time   Negative\n",
       "2     manitha samuthaayam amaipil irunthu intha pada...   Positive\n",
       "3                                         JJ mam miss u   Positive\n",
       "4                Subtitle traller dekhne wale like karo  not-Tamil\n",
       "...                                                 ...        ...\n",
       "4397  Ithukum dislike potta kammanattti koovaingalam...   Negative\n",
       "4398     Suyama Sinthikiravan super Hero Seama dialogue   Positive\n",
       "4399               Super thalaiva Nee mass dha eppavume   Positive\n",
       "4400  பெண்ணை அடிமையாக்க நினைக்கும் இந்த படம் தோல்வித...   Positive\n",
       "4401  Semma thalaiva alu athikama akirukum enimale e...   Positive\n",
       "\n",
       "[4402 rows x 2 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINAL_CNN=pd.concat([Test_Data.Msg_without_Stopwords, df_CNN], axis=1)\n",
    "FINAL_CNN=FINAL_CNN.rename(columns={\"Msg_without_Stopwords\": \"text\", \"result\": \"label\"})\n",
    "\n",
    "FINAL_CNN['label'] = FINAL_CNN['label'].map({0 : 'Mixed_feelings', 1 : 'Negative', 2: 'Positive', 3 :'not-Tamil', 4 : 'unknown_state'})\n",
    "FINAL_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_CNN.to_csv(\"CNN_Tamil_HASOC21.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emoji(y_dev1, Dev_padded_sentences, model_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings_dictionary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-20a5cc928fcc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# step 2 & step 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0membedding_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membeddings_dictionary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0membedding_vector\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# Words not found in embedding index will be all-zeros.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'embeddings_dictionary' is not defined"
     ]
    }
   ],
   "source": [
    "# step 1\n",
    "embedding_matrix = np.zeros((vocab_size, 300)) #create an array of zeros with word_num rows and embedding_dim columns\n",
    "\n",
    "# step 2 & step 3\n",
    "for word, index in word_tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[index] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_node=32\n",
    "nclasses=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dropout, Dense, Embedding, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 195, 300)          12069000  \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 195, 64)           85248     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 195, 64)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 12,197,005\n",
      "Trainable params: 12,197,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_BiLSTM=keras.Sequential([\n",
    "     # add Embeddign layer\n",
    "keras.layers.Embedding(vocab_size,300, input_length=max_length, trainable=True),\n",
    "    # add birectional \n",
    "keras.layers.Bidirectional(LSTM(lstm_node, return_sequences=True, recurrent_dropout=0.2)),\n",
    "    # add dropout layer after  each lstm\n",
    "keras.layers.Dropout(0.2),\n",
    "        # add birectional \n",
    "keras.layers.Bidirectional(LSTM(lstm_node, recurrent_dropout=0.2)),\n",
    "     # add dropout layer after  each lstm\n",
    "keras.layers.Dropout(0.2),\n",
    "    # Add the fully connected layer with 256 nurons and relu activation\n",
    "keras.layers.Dense(256,activation='relu'),\n",
    "    # Add the output layer with softmax activation since we have 2 classes\n",
    "keras.layers.Dense(nclasses, activation='softmax')\n",
    "])\n",
    "\n",
    "model_BiLSTM.compile(loss='sparse_categorical_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "model_BiLSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  398,   399,     9, ...,     0,     0,     0],\n",
       "        [  179,  3473,  3474, ...,     0,     0,     0],\n",
       "        [  194,   253,   813, ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [ 1871,   696,   787, ...,     0,     0,     0],\n",
       "        [11438,   453,  1582, ...,     0,     0,     0],\n",
       "        [  543,  2190,    25, ...,     0,     0,     0]]), (15888, 195))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_padded_sentences, Train_padded_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.]]), (15888, 5))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train1, y_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15888, 195), (15888, 5))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_padded_sentences.shape, y_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15888, 195), (15888,), numpy.ndarray, pandas.core.series.Series)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_padded_sentences.shape, Train_Data['Nlabel'].shape, type(Train_padded_sentences), type(Train_Data['Nlabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y=Train_Data['Nlabel'].to_numpy()\n",
    "type(train_y), type(y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15888 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-170-093d397dd1f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_BiLSTM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrain_padded_sentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "history = model_BiLSTM.fit(Train_padded_sentences, y_train1, batch_size=batch_size, epochs=num_epochs, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot : Bilstem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[914, 16033, 62443, 62344, 26008, 54005, 26008, 34466, 33183],\n",
       " [44374, 975, 62756, 44374, 26008],\n",
       " [12370, 53381, 42754, 19707, 15398, 63009, 65414, 52411, 53381],\n",
       " [61898, 45132, 18421, 30069, 8253],\n",
       " [33355, 65733, 48318, 11639, 27137],\n",
       " [48512, 65414, 52411, 30723, 5128, 34316],\n",
       " [32926, 46168, 47771, 26008, 19595, 26008, 67979],\n",
       " [57500, 52426, 57500, 12692, 23742, 61898, 69254, 65657, 69254],\n",
       " [6200, 19816, 1614, 28068, 15062, 27994, 28555],\n",
       " [948, 53105, 16396, 46422, 21770],\n",
       " [61898, 32334, 32334, 28132, 45285],\n",
       " [4954, 10159, 25508, 669, 26008, 20784],\n",
       " [16388, 44264, 29335, 49184, 67076],\n",
       " [10897, 10566, 49030, 60691, 8621, 19008, 33898, 13487, 8621],\n",
       " [5696,\n",
       "  10897,\n",
       "  5696,\n",
       "  10897,\n",
       "  63943,\n",
       "  15562,\n",
       "  27508,\n",
       "  9436,\n",
       "  13208,\n",
       "  37829,\n",
       "  35268,\n",
       "  39210,\n",
       "  44727,\n",
       "  62554,\n",
       "  67883,\n",
       "  10955,\n",
       "  32627,\n",
       "  46380,\n",
       "  52415,\n",
       "  50348,\n",
       "  19386,\n",
       "  26226,\n",
       "  36653,\n",
       "  37829,\n",
       "  22011,\n",
       "  35405,\n",
       "  47929,\n",
       "  40951,\n",
       "  33310,\n",
       "  50348,\n",
       "  39054,\n",
       "  26226,\n",
       "  26715,\n",
       "  43857,\n",
       "  14565],\n",
       " [30462, 8667, 25067, 53120, 2136, 64201, 36241],\n",
       " [6731, 45579, 20446, 17547],\n",
       " [57188, 60315, 11150, 30835, 26226, 9263, 21286],\n",
       " [8233, 62443, 21901, 27837, 59757, 33296, 65414, 5315, 20525],\n",
       " [43551, 65414, 52411, 6363, 2290, 32926, 29798],\n",
       " [63993, 53712, 32209, 410, 41211, 55413],\n",
       " [67363, 52764, 52764, 52426, 52426, 5389],\n",
       " [29716,\n",
       "  46453,\n",
       "  8919,\n",
       "  32756,\n",
       "  44617,\n",
       "  9436,\n",
       "  12995,\n",
       "  53723,\n",
       "  21920,\n",
       "  57496,\n",
       "  18773,\n",
       "  34170,\n",
       "  68463,\n",
       "  44504,\n",
       "  41841,\n",
       "  32321,\n",
       "  36970,\n",
       "  45897,\n",
       "  43835,\n",
       "  38589,\n",
       "  22674,\n",
       "  66650],\n",
       " [4250, 49214, 1726, 46285, 51444, 3930, 26008],\n",
       " [69549, 31868, 28265, 58382, 6731, 5389],\n",
       " [17089, 59861, 1883, 8003],\n",
       " [22523, 44616, 6731, 44620, 16659, 35478],\n",
       " [35376, 52973, 41311, 65582],\n",
       " [41211, 30928, 10756, 15069, 1724, 4652, 32821, 7137, 41572],\n",
       " [52071,\n",
       "  6331,\n",
       "  52395,\n",
       "  65475,\n",
       "  45820,\n",
       "  55636,\n",
       "  4957,\n",
       "  47929,\n",
       "  10367,\n",
       "  4957,\n",
       "  47929,\n",
       "  9666,\n",
       "  4957,\n",
       "  47929,\n",
       "  4497,\n",
       "  52071,\n",
       "  6331,\n",
       "  52395,\n",
       "  65475,\n",
       "  1997,\n",
       "  4957,\n",
       "  47929,\n",
       "  53267,\n",
       "  17815,\n",
       "  40336,\n",
       "  7141,\n",
       "  6133,\n",
       "  61765,\n",
       "  37048,\n",
       "  11207,\n",
       "  48782,\n",
       "  2068,\n",
       "  27820,\n",
       "  34287,\n",
       "  24657,\n",
       "  43524,\n",
       "  54910,\n",
       "  23638,\n",
       "  14137,\n",
       "  61506,\n",
       "  12462],\n",
       " [6200, 35101, 13009, 35101, 28555],\n",
       " [65414, 52411, 5389, 11313],\n",
       " [61098, 32904, 28727, 23620, 29229],\n",
       " [22167, 27019, 2236, 42810, 54854, 26226, 9324, 562, 5538],\n",
       " [18295, 6731, 50478, 62344, 63145],\n",
       " [44070,\n",
       "  44692,\n",
       "  889,\n",
       "  13181,\n",
       "  67891,\n",
       "  19697,\n",
       "  10159,\n",
       "  15081,\n",
       "  5003,\n",
       "  58539,\n",
       "  853,\n",
       "  44070,\n",
       "  68352,\n",
       "  26289,\n",
       "  67030,\n",
       "  28690],\n",
       " [25436,\n",
       "  1431,\n",
       "  42320,\n",
       "  27655,\n",
       "  60780,\n",
       "  4957,\n",
       "  47929,\n",
       "  11150,\n",
       "  55202,\n",
       "  8858,\n",
       "  58398,\n",
       "  50995,\n",
       "  16501],\n",
       " [37553,\n",
       "  32909,\n",
       "  17278,\n",
       "  10882,\n",
       "  35886,\n",
       "  21416,\n",
       "  23641,\n",
       "  45250,\n",
       "  10163,\n",
       "  21553,\n",
       "  60237,\n",
       "  41937,\n",
       "  38506,\n",
       "  41186,\n",
       "  52561,\n",
       "  60130,\n",
       "  34319,\n",
       "  60854,\n",
       "  64236,\n",
       "  25660,\n",
       "  56869,\n",
       "  68562,\n",
       "  16944,\n",
       "  32633,\n",
       "  38774,\n",
       "  7300,\n",
       "  32401,\n",
       "  62131,\n",
       "  12462],\n",
       " [9516, 36148, 4545],\n",
       " [4873, 25508, 26081, 67570, 3440, 65414, 52411, 25508],\n",
       " [24850,\n",
       "  55823,\n",
       "  9166,\n",
       "  40216,\n",
       "  3001,\n",
       "  7190,\n",
       "  32511,\n",
       "  13172,\n",
       "  9166,\n",
       "  42454,\n",
       "  51968,\n",
       "  22104,\n",
       "  2251,\n",
       "  14123,\n",
       "  39544,\n",
       "  14123,\n",
       "  17075],\n",
       " [17517,\n",
       "  11450,\n",
       "  56215,\n",
       "  21379,\n",
       "  14434,\n",
       "  35204,\n",
       "  53381,\n",
       "  56215,\n",
       "  19947,\n",
       "  34327,\n",
       "  17517,\n",
       "  11450,\n",
       "  56215,\n",
       "  11093,\n",
       "  63108,\n",
       "  26872],\n",
       " [66228, 34517, 19307, 50465, 4212, 55859, 42926],\n",
       " [55731, 35200, 25201, 69583, 6494, 53712, 5544, 24446, 68108, 12747, 26736],\n",
       " [54062, 54062, 18059, 40822, 43898, 10457, 1185, 61898, 62443, 12549],\n",
       " [67735,\n",
       "  10386,\n",
       "  35287,\n",
       "  13222,\n",
       "  52562,\n",
       "  12445,\n",
       "  41211,\n",
       "  20920,\n",
       "  21149,\n",
       "  43856,\n",
       "  4988,\n",
       "  21286,\n",
       "  12935,\n",
       "  26822,\n",
       "  48492,\n",
       "  31656,\n",
       "  27684],\n",
       " [40311, 1541, 64516, 47910, 6535],\n",
       " [40841, 40841, 40841, 40841, 40841, 40841, 48206, 14290],\n",
       " [66393, 35841, 33526, 37813, 41178, 65414, 52411, 6363],\n",
       " [64384, 54405, 16044, 52652, 6213, 55608, 21175, 8219, 30473],\n",
       " [38967, 19670, 19212, 26226, 2701, 9324, 5527],\n",
       " [10393,\n",
       "  51180,\n",
       "  24782,\n",
       "  3281,\n",
       "  65093,\n",
       "  15519,\n",
       "  3712,\n",
       "  35297,\n",
       "  17447,\n",
       "  21371,\n",
       "  41457,\n",
       "  3712,\n",
       "  14330],\n",
       " [32904, 49459, 65414, 52411, 5389, 14199],\n",
       " [39662,\n",
       "  7708,\n",
       "  66556,\n",
       "  49670,\n",
       "  4954,\n",
       "  61898,\n",
       "  46168,\n",
       "  54062,\n",
       "  53047,\n",
       "  30923,\n",
       "  39662,\n",
       "  13356,\n",
       "  64851,\n",
       "  10031,\n",
       "  30723,\n",
       "  31821,\n",
       "  68154,\n",
       "  54102,\n",
       "  10159,\n",
       "  21901,\n",
       "  42754,\n",
       "  43193,\n",
       "  63368,\n",
       "  4954,\n",
       "  49670,\n",
       "  7401,\n",
       "  54062,\n",
       "  20694,\n",
       "  32861,\n",
       "  56215,\n",
       "  39248,\n",
       "  25621],\n",
       " [30285, 34336, 55639],\n",
       " [67764, 6200, 14748, 53820],\n",
       " [630, 54854, 9324, 36984, 31943, 27252, 205],\n",
       " [36242, 51849, 22600, 30723],\n",
       " [42754, 32366, 46601, 34935, 10368],\n",
       " [65414, 52411, 55531, 46168, 12633, 32904],\n",
       " [10046, 66090, 26008, 59441, 20706],\n",
       " [21652, 53381, 23149, 32366, 1333, 6453],\n",
       " [34843, 4680, 48492, 30258, 54579, 43474, 25295, 40291, 52575],\n",
       " [45054, 41211, 25371, 15524, 203, 16289, 42727, 2865, 1687, 56060],\n",
       " [48463, 3314, 33387, 54941, 39644, 25896, 52980, 4954, 68065],\n",
       " [41092, 18157, 26008, 44374, 975, 64001, 18157],\n",
       " [55239, 3249, 62488, 37975, 49863, 5389, 6731, 53386],\n",
       " [6476, 2786, 40531, 40147, 9675, 21029, 948, 60007],\n",
       " [22414, 49959, 24264, 20224, 6731],\n",
       " [66639, 43434, 16744, 16344],\n",
       " [37592, 12203, 36010, 29350, 16828, 17774],\n",
       " [66878, 29712, 23578, 30723, 14898, 31145],\n",
       " [20356, 46168, 21045, 5389, 31145, 25270, 51738, 34042],\n",
       " [17853, 3079, 42451, 63948, 46667, 29712, 57926],\n",
       " [16952, 42754, 24264, 5389, 34409, 1490],\n",
       " [6148, 50527, 54062, 37592, 62644, 6200, 38381],\n",
       " [21932,\n",
       "  52561,\n",
       "  7236,\n",
       "  20787,\n",
       "  33755,\n",
       "  1350,\n",
       "  38823,\n",
       "  35657,\n",
       "  3287,\n",
       "  11639,\n",
       "  65671,\n",
       "  63244,\n",
       "  40380,\n",
       "  66329,\n",
       "  19722,\n",
       "  53534],\n",
       " [47910, 60126, 66639, 13962, 47556, 44478, 59676, 26943, 15890],\n",
       " [43941, 60429, 11625, 26008, 26008, 34935, 48280, 60331],\n",
       " [61385, 33957, 49670, 11586, 28110, 16086, 11282],\n",
       " [33370, 45579, 45530, 23389, 40531, 55531],\n",
       " [65414, 52411, 11093, 24903, 48391, 59256, 46168],\n",
       " [19008, 10897, 54854, 26226, 9324, 36984, 5538],\n",
       " [64334, 32904, 65414, 52411, 975, 51444, 64334, 46168],\n",
       " [50126, 37568, 62443, 12549, 54854, 26226, 13693, 31943],\n",
       " [10549,\n",
       "  37518,\n",
       "  38967,\n",
       "  5538,\n",
       "  2591,\n",
       "  63032,\n",
       "  38432,\n",
       "  67602,\n",
       "  40319,\n",
       "  61453,\n",
       "  32344,\n",
       "  12721,\n",
       "  38967,\n",
       "  44320,\n",
       "  60476,\n",
       "  22980,\n",
       "  38967],\n",
       " [26226, 37373, 19649, 5538, 33788, 39549, 54854],\n",
       " [58986, 55957, 14283],\n",
       " [25197, 54209, 27807, 67626, 15845, 37829],\n",
       " [1952,\n",
       "  10159,\n",
       "  67570,\n",
       "  43054,\n",
       "  1117,\n",
       "  27444,\n",
       "  36288,\n",
       "  34327,\n",
       "  62344,\n",
       "  14434,\n",
       "  9293,\n",
       "  58914,\n",
       "  65744,\n",
       "  33687,\n",
       "  36024,\n",
       "  10159,\n",
       "  28145,\n",
       "  60368,\n",
       "  8862,\n",
       "  61848,\n",
       "  44374,\n",
       "  975,\n",
       "  38629,\n",
       "  52663,\n",
       "  53712,\n",
       "  36288],\n",
       " [66639, 63145, 26284, 6731, 33558],\n",
       " [10159, 61936, 7410, 18053, 53047, 13677, 32438, 58246, 53381],\n",
       " [48432, 17643, 58450, 34346, 7754, 65682, 35470],\n",
       " [39662, 37592, 30723, 2677, 50364, 42100, 48492, 53381, 63861],\n",
       " [948, 948, 948, 948, 948, 61898, 46168, 26155],\n",
       " [36117,\n",
       "  40032,\n",
       "  16258,\n",
       "  45537,\n",
       "  14843,\n",
       "  6381,\n",
       "  60210,\n",
       "  65668,\n",
       "  14843,\n",
       "  6381,\n",
       "  60210,\n",
       "  58639,\n",
       "  34935,\n",
       "  54467,\n",
       "  30706,\n",
       "  64001,\n",
       "  21554,\n",
       "  27252,\n",
       "  63583,\n",
       "  14843,\n",
       "  60796,\n",
       "  15260,\n",
       "  1063,\n",
       "  34025,\n",
       "  6208,\n",
       "  24909,\n",
       "  16258,\n",
       "  4954,\n",
       "  26326,\n",
       "  3497,\n",
       "  25202,\n",
       "  26085,\n",
       "  36109,\n",
       "  5513,\n",
       "  14843,\n",
       "  44719,\n",
       "  51398,\n",
       "  46803,\n",
       "  46425,\n",
       "  27812,\n",
       "  4221,\n",
       "  10205,\n",
       "  6555,\n",
       "  48226,\n",
       "  20080,\n",
       "  36923,\n",
       "  21609,\n",
       "  49719,\n",
       "  19747,\n",
       "  28005,\n",
       "  40079,\n",
       "  43826,\n",
       "  48750,\n",
       "  21172,\n",
       "  67320,\n",
       "  19976],\n",
       " [53368, 30855, 20769, 41211, 5003, 10756, 45701],\n",
       " [15179, 27187, 27334, 27619, 34628, 17158, 17492, 11878],\n",
       " [20356, 46168, 59156, 58382, 44374, 975, 20356],\n",
       " [52071,\n",
       "  51786,\n",
       "  23801,\n",
       "  42221,\n",
       "  1564,\n",
       "  30786,\n",
       "  19230,\n",
       "  52551,\n",
       "  762,\n",
       "  26226,\n",
       "  38667,\n",
       "  13693,\n",
       "  5538],\n",
       " [40984,\n",
       "  36416,\n",
       "  62205,\n",
       "  34371,\n",
       "  14863,\n",
       "  34344,\n",
       "  42588,\n",
       "  25323,\n",
       "  30727,\n",
       "  66456,\n",
       "  69601,\n",
       "  6436,\n",
       "  55785,\n",
       "  26940,\n",
       "  34554,\n",
       "  20429],\n",
       " [50122, 6991, 20224, 54613, 13254, 23801, 4954, 54062, 43253],\n",
       " [24264, 45579, 13006, 40558, 25651, 48033, 65462, 47632],\n",
       " [65475,\n",
       "  26251,\n",
       "  43727,\n",
       "  18366,\n",
       "  9368,\n",
       "  43038,\n",
       "  9687,\n",
       "  33401,\n",
       "  43080,\n",
       "  28190,\n",
       "  17922,\n",
       "  4854,\n",
       "  7636,\n",
       "  9687,\n",
       "  49379,\n",
       "  19517,\n",
       "  44217,\n",
       "  20950,\n",
       "  52909,\n",
       "  58232,\n",
       "  41311,\n",
       "  36314,\n",
       "  48655],\n",
       " [59184, 67480, 1177, 54254, 54854, 61506, 5538],\n",
       " [2865,\n",
       "  34172,\n",
       "  5682,\n",
       "  20356,\n",
       "  46168,\n",
       "  41211,\n",
       "  53047,\n",
       "  60368,\n",
       "  65170,\n",
       "  33610,\n",
       "  56215,\n",
       "  21839,\n",
       "  14152],\n",
       " [25508, 42754, 28416, 61612, 26564, 62608, 51531, 12955, 18793],\n",
       " [44374, 63989, 32217, 12992, 12992, 12992, 12992],\n",
       " [42750, 34829, 32904, 65414, 52411, 11093, 20224],\n",
       " [975, 61898, 64135, 64664, 16446, 61898, 62443],\n",
       " [15437,\n",
       "  4044,\n",
       "  65711,\n",
       "  22330,\n",
       "  12826,\n",
       "  27051,\n",
       "  46211,\n",
       "  35144,\n",
       "  12983,\n",
       "  913,\n",
       "  16592,\n",
       "  16592,\n",
       "  42451,\n",
       "  48412,\n",
       "  3041,\n",
       "  26639,\n",
       "  29712,\n",
       "  43856,\n",
       "  9001,\n",
       "  4954,\n",
       "  50966,\n",
       "  58875,\n",
       "  8816,\n",
       "  42451,\n",
       "  66524,\n",
       "  11693,\n",
       "  28246,\n",
       "  28068,\n",
       "  2132,\n",
       "  17622,\n",
       "  26273,\n",
       "  27266,\n",
       "  60829,\n",
       "  60829,\n",
       "  11093,\n",
       "  554,\n",
       "  8033,\n",
       "  42451,\n",
       "  65567,\n",
       "  57932,\n",
       "  66422,\n",
       "  39746,\n",
       "  15349,\n",
       "  68991,\n",
       "  48452,\n",
       "  66765,\n",
       "  23643,\n",
       "  27081,\n",
       "  42754,\n",
       "  38590,\n",
       "  14858,\n",
       "  56475],\n",
       " [54630,\n",
       "  13776,\n",
       "  29772,\n",
       "  40456,\n",
       "  61345,\n",
       "  27051,\n",
       "  65820,\n",
       "  69551,\n",
       "  27318,\n",
       "  10756,\n",
       "  35629,\n",
       "  65296,\n",
       "  42866,\n",
       "  2851,\n",
       "  5220,\n",
       "  69551,\n",
       "  15808,\n",
       "  31185,\n",
       "  27051,\n",
       "  46691,\n",
       "  55639,\n",
       "  14470,\n",
       "  10756,\n",
       "  48456,\n",
       "  5220,\n",
       "  58950,\n",
       "  53730,\n",
       "  52639,\n",
       "  14151,\n",
       "  20944,\n",
       "  28246,\n",
       "  24919,\n",
       "  11408,\n",
       "  5119,\n",
       "  51674,\n",
       "  8211,\n",
       "  26387,\n",
       "  16257,\n",
       "  48859,\n",
       "  41384,\n",
       "  55639,\n",
       "  64516,\n",
       "  42430,\n",
       "  53494,\n",
       "  16535,\n",
       "  35633,\n",
       "  25202,\n",
       "  15699,\n",
       "  410,\n",
       "  49920,\n",
       "  52082,\n",
       "  52167,\n",
       "  45325,\n",
       "  35225,\n",
       "  50362,\n",
       "  42430,\n",
       "  42333,\n",
       "  10281],\n",
       " [21064,\n",
       "  59183,\n",
       "  42451,\n",
       "  52743,\n",
       "  59183,\n",
       "  28595,\n",
       "  46181,\n",
       "  23909,\n",
       "  28234,\n",
       "  6264,\n",
       "  33969,\n",
       "  10454,\n",
       "  33969],\n",
       " [44374, 224, 9675, 41606, 53381],\n",
       " [36117, 4954, 25532, 7970, 58864],\n",
       " [39662, 6200, 54341, 41211, 30723, 14748, 18799],\n",
       " [52426,\n",
       "  31205,\n",
       "  6200,\n",
       "  23104,\n",
       "  14748,\n",
       "  7396,\n",
       "  60619,\n",
       "  25532,\n",
       "  26564,\n",
       "  66411,\n",
       "  59010,\n",
       "  59588,\n",
       "  66874,\n",
       "  50517],\n",
       " [20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356,\n",
       "  20356],\n",
       " [55749, 62443, 16258, 54880, 62443, 26008],\n",
       " [42898,\n",
       "  33120,\n",
       "  25306,\n",
       "  24264,\n",
       "  45579,\n",
       "  21391,\n",
       "  51843,\n",
       "  24264,\n",
       "  975,\n",
       "  52426,\n",
       "  61492,\n",
       "  24264,\n",
       "  5389,\n",
       "  34912],\n",
       " [9130, 13006, 55749, 34935, 11517, 45530, 4410, 20920, 8806, 61451],\n",
       " [48714,\n",
       "  20787,\n",
       "  60184,\n",
       "  41311,\n",
       "  32696,\n",
       "  56212,\n",
       "  27866,\n",
       "  6232,\n",
       "  50706,\n",
       "  1650,\n",
       "  54372,\n",
       "  62826,\n",
       "  14511,\n",
       "  14822,\n",
       "  57579,\n",
       "  32696,\n",
       "  56212,\n",
       "  27866,\n",
       "  53973,\n",
       "  26657,\n",
       "  34685,\n",
       "  50706,\n",
       "  59068,\n",
       "  9436,\n",
       "  14406,\n",
       "  41311,\n",
       "  41043,\n",
       "  3994,\n",
       "  69625,\n",
       "  11639,\n",
       "  32696,\n",
       "  61161,\n",
       "  58200],\n",
       " [32904, 65414, 52411, 6731, 59660, 16409, 52244, 45932, 55781, 5389],\n",
       " [25201, 28525, 42248, 21486, 21486, 40750],\n",
       " [36117,\n",
       "  30723,\n",
       "  36109,\n",
       "  58652,\n",
       "  22495,\n",
       "  65414,\n",
       "  52411,\n",
       "  3316,\n",
       "  53712,\n",
       "  55531,\n",
       "  6535,\n",
       "  15054,\n",
       "  16406],\n",
       " [1227,\n",
       "  6731,\n",
       "  64612,\n",
       "  15963,\n",
       "  62464,\n",
       "  45579,\n",
       "  59719,\n",
       "  35047,\n",
       "  68055,\n",
       "  11093,\n",
       "  21045,\n",
       "  5389,\n",
       "  35675,\n",
       "  4850,\n",
       "  51948],\n",
       " [66228, 30411, 12945, 64090, 67017, 21864],\n",
       " [27266,\n",
       "  45079,\n",
       "  32189,\n",
       "  32401,\n",
       "  10696,\n",
       "  58636,\n",
       "  24473,\n",
       "  58478,\n",
       "  65733,\n",
       "  66032,\n",
       "  4269,\n",
       "  45579,\n",
       "  12912],\n",
       " [2865, 2865, 14581, 13738, 53712, 10159, 40100],\n",
       " [36117, 31222, 22717, 13994, 34419, 29502, 16661],\n",
       " [35995, 56475, 37515, 46877, 41211, 40563, 64220, 45665],\n",
       " [56116, 11597, 19008, 46813, 54854, 26226, 2701, 9324, 562, 5538],\n",
       " [28788,\n",
       "  54730,\n",
       "  19873,\n",
       "  68660,\n",
       "  17872,\n",
       "  50686,\n",
       "  41457,\n",
       "  55908,\n",
       "  1885,\n",
       "  13097,\n",
       "  3263,\n",
       "  14038,\n",
       "  67968,\n",
       "  24180],\n",
       " [37592, 58636, 49077, 13619, 61774, 5958, 48841, 33188],\n",
       " [55004,\n",
       "  22306,\n",
       "  60166,\n",
       "  14416,\n",
       "  44059,\n",
       "  53381,\n",
       "  44314,\n",
       "  33084,\n",
       "  58620,\n",
       "  55639,\n",
       "  18295,\n",
       "  32462,\n",
       "  17875,\n",
       "  60166,\n",
       "  26008],\n",
       " [48525, 54305, 1474, 20356, 46168, 17287, 46168, 68433, 46168],\n",
       " [66639, 43434, 66639, 63145],\n",
       " [5389, 61898, 44098, 42750],\n",
       " [61374, 1177, 54854, 26226, 2701, 9324, 36984, 5538],\n",
       " [40336,\n",
       "  7901,\n",
       "  45574,\n",
       "  39293,\n",
       "  38746,\n",
       "  68702,\n",
       "  6370,\n",
       "  2066,\n",
       "  18140,\n",
       "  66329,\n",
       "  49403,\n",
       "  1350,\n",
       "  32835,\n",
       "  51633,\n",
       "  16400,\n",
       "  45997,\n",
       "  40641,\n",
       "  67172,\n",
       "  22258,\n",
       "  838,\n",
       "  62398,\n",
       "  52216,\n",
       "  25163],\n",
       " [33120, 21550, 24939, 33884, 49863, 65657],\n",
       " [15311, 26008, 45434, 57693, 32124, 2192, 63256, 21839, 1871, 13540, 61384],\n",
       " [52441,\n",
       "  64269,\n",
       "  45486,\n",
       "  46305,\n",
       "  58049,\n",
       "  29778,\n",
       "  44748,\n",
       "  2774,\n",
       "  25181,\n",
       "  59357,\n",
       "  30854,\n",
       "  6317,\n",
       "  17359,\n",
       "  6133,\n",
       "  24268,\n",
       "  53604,\n",
       "  16538,\n",
       "  60798,\n",
       "  55122,\n",
       "  21737,\n",
       "  44566,\n",
       "  14192,\n",
       "  35765,\n",
       "  66650,\n",
       "  54452,\n",
       "  10897,\n",
       "  46345,\n",
       "  18773,\n",
       "  19381,\n",
       "  13406,\n",
       "  37829,\n",
       "  64431,\n",
       "  10163,\n",
       "  26180,\n",
       "  54823,\n",
       "  57663,\n",
       "  22674,\n",
       "  36128,\n",
       "  21341,\n",
       "  61397,\n",
       "  50365,\n",
       "  65420,\n",
       "  41565,\n",
       "  34643,\n",
       "  48410,\n",
       "  3328,\n",
       "  42298,\n",
       "  14779,\n",
       "  42680,\n",
       "  63025,\n",
       "  43801,\n",
       "  14087,\n",
       "  30208,\n",
       "  1323,\n",
       "  64023,\n",
       "  52854,\n",
       "  41457,\n",
       "  34305,\n",
       "  52071,\n",
       "  61309,\n",
       "  2701,\n",
       "  700,\n",
       "  37829,\n",
       "  1352,\n",
       "  3052,\n",
       "  25942,\n",
       "  52071,\n",
       "  56851,\n",
       "  44367,\n",
       "  8945,\n",
       "  27945,\n",
       "  64431,\n",
       "  63981,\n",
       "  59987,\n",
       "  2701,\n",
       "  46380,\n",
       "  31943],\n",
       " [28071,\n",
       "  16775,\n",
       "  60592,\n",
       "  19125,\n",
       "  3052,\n",
       "  27866,\n",
       "  62619,\n",
       "  52561,\n",
       "  58721,\n",
       "  63733,\n",
       "  64012,\n",
       "  59457,\n",
       "  10163,\n",
       "  39663,\n",
       "  43524,\n",
       "  47119,\n",
       "  41006,\n",
       "  35722,\n",
       "  57208,\n",
       "  64144,\n",
       "  60592,\n",
       "  17230,\n",
       "  54500,\n",
       "  60628,\n",
       "  9049,\n",
       "  19125,\n",
       "  28070,\n",
       "  9788,\n",
       "  63357,\n",
       "  69420,\n",
       "  47184,\n",
       "  55122,\n",
       "  34287,\n",
       "  61257,\n",
       "  55234,\n",
       "  34790],\n",
       " [18832, 40412, 59893, 6055, 29714],\n",
       " [54056, 28041, 4954, 65414, 52411, 13006, 61696, 22263, 52411, 52831],\n",
       " [3595, 61295, 65093, 34877, 23770, 20422, 64056],\n",
       " [6731, 6731, 6731, 65414, 66317, 8212, 20525],\n",
       " [64130, 45830, 1346, 55918, 11423, 7358],\n",
       " [15196, 51134, 62443, 62344, 26008],\n",
       " [62104,\n",
       "  28642,\n",
       "  11207,\n",
       "  6892,\n",
       "  62492,\n",
       "  49720,\n",
       "  25660,\n",
       "  47929,\n",
       "  19283,\n",
       "  33259,\n",
       "  63093,\n",
       "  31943,\n",
       "  16040,\n",
       "  24717,\n",
       "  46090],\n",
       " [4019, 51531, 29671, 38249, 45579, 14245, 41890, 61032, 51853, 5605, 35205],\n",
       " [13449, 32870, 67945, 11015, 29712, 44478],\n",
       " [31662, 38137, 24782, 56215, 28595, 17358, 20784, 51699, 17897, 58812],\n",
       " [13573,\n",
       "  41211,\n",
       "  39109,\n",
       "  68718,\n",
       "  55379,\n",
       "  26564,\n",
       "  61748,\n",
       "  42412,\n",
       "  6514,\n",
       "  36288,\n",
       "  56215,\n",
       "  16553,\n",
       "  30723],\n",
       " [59184, 35372, 5443, 54854, 26226, 2701, 9324, 36984, 5538, 59184, 35615],\n",
       " [24939,\n",
       "  39358,\n",
       "  57193,\n",
       "  4747,\n",
       "  48079,\n",
       "  30692,\n",
       "  27112,\n",
       "  31122,\n",
       "  32785,\n",
       "  15179,\n",
       "  55749,\n",
       "  30692,\n",
       "  43676,\n",
       "  26741,\n",
       "  33761,\n",
       "  36402,\n",
       "  57266,\n",
       "  43531,\n",
       "  45863,\n",
       "  53474,\n",
       "  34935,\n",
       "  67535],\n",
       " [55270, 16258, 62648, 52411, 11413, 55327, 29279, 45283, 44583, 23578],\n",
       " [56687,\n",
       "  65093,\n",
       "  48322,\n",
       "  48322,\n",
       "  19884,\n",
       "  47371,\n",
       "  58232,\n",
       "  47930,\n",
       "  38967,\n",
       "  26226,\n",
       "  2701,\n",
       "  13693,\n",
       "  31943,\n",
       "  48353,\n",
       "  269,\n",
       "  19008,\n",
       "  28685,\n",
       "  19936,\n",
       "  68562,\n",
       "  51670,\n",
       "  39126,\n",
       "  7434,\n",
       "  28685],\n",
       " [67844, 59894, 60570, 60962, 49164, 25977, 14876, 43098, 5549, 51804],\n",
       " [6625, 12208, 44374, 36148, 16169, 39102, 8997],\n",
       " [22994, 16446, 36223, 26856],\n",
       " [16344, 63145, 1723, 66639, 63145],\n",
       " [62756, 42754, 27877, 25806, 55270, 45579, 39358],\n",
       " [66498, 68480, 68480, 39102, 61898, 53712, 66498, 11875],\n",
       " [19008,\n",
       "  1177,\n",
       "  4237,\n",
       "  64676,\n",
       "  59184,\n",
       "  64676,\n",
       "  85,\n",
       "  63824,\n",
       "  18773,\n",
       "  4674,\n",
       "  61709,\n",
       "  52400,\n",
       "  12462,\n",
       "  43524,\n",
       "  38967],\n",
       " [24939, 51693, 55749, 52426, 21709, 30079, 20817, 52411],\n",
       " [38526, 1272, 26833, 1333, 21379, 18124, 13136, 51171],\n",
       " [43874, 13748, 63888, 22502, 14670, 64093],\n",
       " [10967, 65414, 56480, 24473, 45579],\n",
       " [64682, 12912, 65541, 54415, 51699],\n",
       " [66650, 8858, 30854, 57828, 55702, 47466, 16501],\n",
       " [60007, 53381, 37420, 2221, 10835, 15631],\n",
       " [46938, 50992, 53712, 51237],\n",
       " [42451, 41211, 20187, 4410, 42451, 55749, 4410, 6731],\n",
       " [6200, 56475, 26599, 12935, 12935, 41211, 16706, 6731],\n",
       " [5538, 43524, 38967, 14667, 46985, 58232],\n",
       " [22831, 16952, 25508],\n",
       " [8907, 41211, 26935, 10773, 3657, 14667, 41211, 11121, 50810],\n",
       " [48699, 13406, 59779, 5389, 12912, 53381],\n",
       " [32904, 10946],\n",
       " [23092, 5350, 15398, 67754, 56187, 40563, 28170],\n",
       " [21039, 65414, 52411, 67149, 19583],\n",
       " [34829, 26252, 42691, 53994, 6461, 56215, 31633],\n",
       " [29712, 64659, 42869, 45579, 42750, 40531, 55749],\n",
       " [62344, 34936, 55749, 53712, 38629, 35239, 44374, 26008, 35770, 44374, 58819],\n",
       " [20374,\n",
       "  12175,\n",
       "  48925,\n",
       "  34685,\n",
       "  11639,\n",
       "  7141,\n",
       "  46855,\n",
       "  52216,\n",
       "  49537,\n",
       "  34685,\n",
       "  39210,\n",
       "  11639,\n",
       "  47929,\n",
       "  38758,\n",
       "  48699,\n",
       "  58634],\n",
       " [6899,\n",
       "  17576,\n",
       "  15555,\n",
       "  68268,\n",
       "  33219,\n",
       "  39255,\n",
       "  46818,\n",
       "  2912,\n",
       "  40103,\n",
       "  23747,\n",
       "  3570,\n",
       "  4250,\n",
       "  58812,\n",
       "  30723],\n",
       " [52426, 52426, 52426, 45648, 55531, 45700],\n",
       " [65414, 52411, 55749, 45579],\n",
       " [28240,\n",
       "  23300,\n",
       "  13677,\n",
       "  7045,\n",
       "  60313,\n",
       "  69551,\n",
       "  33974,\n",
       "  6407,\n",
       "  56215,\n",
       "  66843,\n",
       "  65837,\n",
       "  44845,\n",
       "  41606,\n",
       "  52843,\n",
       "  37815,\n",
       "  7570,\n",
       "  27966,\n",
       "  56215,\n",
       "  42418],\n",
       " [29712, 30723, 63017, 64015, 13414, 4954, 32993],\n",
       " [44070, 39180, 68931, 23382, 62332, 39888, 65998, 14104],\n",
       " [52801, 39922, 52798, 39102, 33884, 55749, 62344, 26008],\n",
       " [29731, 39602, 17660, 55755, 63223, 12462, 64947, 1352, 27873, 63223],\n",
       " [15209, 38695, 65319, 20224, 52241, 69409],\n",
       " [22349, 37434, 40813, 66699, 54941, 20446],\n",
       " [20356,\n",
       "  44374,\n",
       "  65458,\n",
       "  14164,\n",
       "  26252,\n",
       "  41606,\n",
       "  55781,\n",
       "  44374,\n",
       "  5389,\n",
       "  53712,\n",
       "  42750,\n",
       "  33478],\n",
       " [17046, 42754, 29502, 48307, 52525, 28081],\n",
       " [22831, 52539, 4269, 19583, 45381, 60442, 57715, 59907, 26008],\n",
       " [43305, 60962, 8852, 46251],\n",
       " [47910, 8667, 41606, 44070, 61276, 49925, 25666],\n",
       " [11739,\n",
       "  50311,\n",
       "  29495,\n",
       "  11940,\n",
       "  66639,\n",
       "  63145,\n",
       "  55071,\n",
       "  66639,\n",
       "  26284,\n",
       "  66639,\n",
       "  66639,\n",
       "  66639,\n",
       "  66639,\n",
       "  66639,\n",
       "  16086,\n",
       "  66639,\n",
       "  16086],\n",
       " [39173,\n",
       "  20787,\n",
       "  38667,\n",
       "  19083,\n",
       "  22053,\n",
       "  64681,\n",
       "  25776,\n",
       "  61765,\n",
       "  51525,\n",
       "  42191,\n",
       "  52539,\n",
       "  21045,\n",
       "  45579,\n",
       "  53381,\n",
       "  16718,\n",
       "  69035],\n",
       " [16952, 15956, 48925, 62648, 52411, 64334, 10254],\n",
       " [54850, 56215, 27837, 19831, 27837, 520, 32540, 69076],\n",
       " [59920, 34959, 14837, 25216, 13006, 9860, 13356, 14837, 25216],\n",
       " [15889, 27545, 652, 54854, 26226, 2701, 9324, 36984, 5538, 34861],\n",
       " [65414,\n",
       "  52411,\n",
       "  8226,\n",
       "  62443,\n",
       "  65475,\n",
       "  47372,\n",
       "  54234,\n",
       "  54092,\n",
       "  40175,\n",
       "  50750,\n",
       "  52426,\n",
       "  62344,\n",
       "  45628,\n",
       "  35204,\n",
       "  41211,\n",
       "  34935],\n",
       " [12940,\n",
       "  5005,\n",
       "  42754,\n",
       "  52426,\n",
       "  42695,\n",
       "  20694,\n",
       "  10251,\n",
       "  67071,\n",
       "  55406,\n",
       "  31231,\n",
       "  55523,\n",
       "  58636,\n",
       "  69617,\n",
       "  57500],\n",
       " [28135, 41136, 61765, 7308, 53168, 2964],\n",
       " [29712, 65048, 30723, 50750, 10644, 55798],\n",
       " [10305,\n",
       "  40786,\n",
       "  9516,\n",
       "  55908,\n",
       "  43029,\n",
       "  38334,\n",
       "  37586,\n",
       "  40586,\n",
       "  2111,\n",
       "  836,\n",
       "  48463,\n",
       "  3812],\n",
       " [11429, 28494, 52729, 34287, 26226, 2701, 9324, 36984, 5538],\n",
       " [39662,\n",
       "  49279,\n",
       "  7015,\n",
       "  10897,\n",
       "  7015,\n",
       "  10897,\n",
       "  10955,\n",
       "  68925,\n",
       "  50785,\n",
       "  65093,\n",
       "  1450,\n",
       "  28308],\n",
       " [46452,\n",
       "  56215,\n",
       "  33451,\n",
       "  36669,\n",
       "  740,\n",
       "  52426,\n",
       "  60324,\n",
       "  67076,\n",
       "  29712,\n",
       "  51068,\n",
       "  19389,\n",
       "  3891,\n",
       "  56215,\n",
       "  57424,\n",
       "  54031,\n",
       "  65370],\n",
       " [22349, 61898, 5394, 48862, 53712, 41211, 60368, 52438, 42754, 37876, 63595],\n",
       " [975, 31145],\n",
       " [28280, 45951, 26008, 28750, 65458, 15956, 5200],\n",
       " [42869, 41211, 5003, 21856, 31807, 32924, 21442],\n",
       " [31145, 52891, 45579, 11436],\n",
       " [2453, 64327, 85, 61000, 31943],\n",
       " [31397, 37874, 50750, 22831, 4889],\n",
       " [42750, 32657, 63964, 5995, 20784, 21859],\n",
       " [20959, 26047, 14465, 19799, 52980, 29773, 17331, 47671, 11379],\n",
       " [66639, 50750, 50750, 14748, 14492, 25651, 49214],\n",
       " [15292,\n",
       "  29575,\n",
       "  6731,\n",
       "  45579,\n",
       "  56215,\n",
       "  37646,\n",
       "  30579,\n",
       "  3662,\n",
       "  30723,\n",
       "  35435,\n",
       "  4149,\n",
       "  38478,\n",
       "  66075,\n",
       "  17360,\n",
       "  21905,\n",
       "  53381],\n",
       " [66639, 28348, 38137, 30723, 7137, 50750],\n",
       " [31145, 67076, 32590, 1490, 42002],\n",
       " [35402, 50512, 56217, 32314, 2865, 19040, 41211, 50255, 42795, 52411],\n",
       " [3191, 65319, 21901, 4954, 26008, 41000, 2582],\n",
       " [3249, 43606, 28521, 37831, 1945, 30723, 19260, 27156, 30723],\n",
       " [12912, 42750, 41606, 52946, 41606, 6731, 62443, 26008],\n",
       " [11436, 14667, 41606, 4954, 50750, 65414, 52411, 56215, 28555],\n",
       " [33969, 33969, 33969, 48463, 38342, 59588, 34972, 13738, 31222, 28803],\n",
       " [35836,\n",
       "  4954,\n",
       "  9970,\n",
       "  16491,\n",
       "  42516,\n",
       "  35964,\n",
       "  66412,\n",
       "  64670,\n",
       "  68483,\n",
       "  32037,\n",
       "  67165,\n",
       "  55286,\n",
       "  33815,\n",
       "  26441,\n",
       "  8008,\n",
       "  39892,\n",
       "  49314,\n",
       "  12986,\n",
       "  23801,\n",
       "  6067,\n",
       "  5350,\n",
       "  20064,\n",
       "  55286,\n",
       "  58759,\n",
       "  40302,\n",
       "  28595,\n",
       "  4747,\n",
       "  28595,\n",
       "  16911,\n",
       "  52130,\n",
       "  29723,\n",
       "  16911,\n",
       "  69551,\n",
       "  33974,\n",
       "  3006,\n",
       "  59649,\n",
       "  42451,\n",
       "  6869,\n",
       "  32848,\n",
       "  34546,\n",
       "  28672],\n",
       " [27266, 36109, 55333, 66688, 45951, 33387, 32904],\n",
       " [11856, 65657, 53381, 65414, 56480],\n",
       " [43975,\n",
       "  43975,\n",
       "  46739,\n",
       "  67639,\n",
       "  66650,\n",
       "  23493,\n",
       "  37117,\n",
       "  35483,\n",
       "  5532,\n",
       "  66895,\n",
       "  38432,\n",
       "  58232,\n",
       "  66467,\n",
       "  27945,\n",
       "  1333,\n",
       "  1816,\n",
       "  10164,\n",
       "  14960,\n",
       "  10630],\n",
       " [53381, 19664, 64228, 37592, 15398, 57923, 869, 1641],\n",
       " [44921, 60135, 20525, 34935, 29950, 42451, 1346, 465, 62851],\n",
       " [20704, 29502, 44439, 179, 12158],\n",
       " [42750, 17547, 46168, 42750, 4188, 42750, 33478],\n",
       " [52441, 58564, 22390, 36383, 30004, 22390, 15956, 2466, 48191],\n",
       " [31823, 26008, 11450, 2021],\n",
       " [36035, 7754, 16744, 16344],\n",
       " [28336,\n",
       "  44278,\n",
       "  34374,\n",
       "  10791,\n",
       "  15407,\n",
       "  52766,\n",
       "  21489,\n",
       "  34768,\n",
       "  58634,\n",
       "  24259,\n",
       "  20477,\n",
       "  64557,\n",
       "  34287,\n",
       "  59417],\n",
       " [18295, 14776, 18697, 58338, 26008, 15054],\n",
       " [65475, 23786, 46877, 8806, 43853, 65942, 59937, 67838],\n",
       " [65462, 6731, 24264, 45579, 42750],\n",
       " [50796, 7113, 40268, 48492, 44374, 5389],\n",
       " [19396, 6387, 54142, 58634, 52606, 34308, 9436, 11630, 28113, 19884, 46797],\n",
       " [1508,\n",
       "  66639,\n",
       "  21823,\n",
       "  38167,\n",
       "  38230,\n",
       "  41211,\n",
       "  39635,\n",
       "  43538,\n",
       "  59618,\n",
       "  48492,\n",
       "  39635,\n",
       "  55206],\n",
       " [67115, 27340, 29371, 29712, 27939, 32264, 26008, 63117],\n",
       " [16744,\n",
       "  16344,\n",
       "  66639,\n",
       "  63145,\n",
       "  16744,\n",
       "  16344,\n",
       "  66639,\n",
       "  63145,\n",
       "  39202,\n",
       "  53819,\n",
       "  23597,\n",
       "  26008,\n",
       "  7842],\n",
       " [61898, 60570, 53047, 68852, 50173, 23296],\n",
       " [14843,\n",
       "  9191,\n",
       "  62696,\n",
       "  49923,\n",
       "  62241,\n",
       "  68055,\n",
       "  11993,\n",
       "  49522,\n",
       "  14843,\n",
       "  64787,\n",
       "  23578,\n",
       "  4954,\n",
       "  4392],\n",
       " [16952,\n",
       "  41606,\n",
       "  62788,\n",
       "  24903,\n",
       "  68812,\n",
       "  26759,\n",
       "  53712,\n",
       "  59586,\n",
       "  58906,\n",
       "  69363,\n",
       "  43496,\n",
       "  27086,\n",
       "  15956,\n",
       "  55781,\n",
       "  1333,\n",
       "  46823,\n",
       "  14975,\n",
       "  30692,\n",
       "  20525,\n",
       "  25508,\n",
       "  65414,\n",
       "  52411],\n",
       " [16291, 16744, 52010, 1490, 16744, 63145, 29671, 46510, 1490],\n",
       " [25240, 34396, 53381, 59226, 43942],\n",
       " [42822, 41211, 29502, 20784, 44098, 6338, 39102],\n",
       " [47128, 54451, 55800, 41211, 5003, 58539, 15530, 10281],\n",
       " [6731,\n",
       "  20694,\n",
       "  1629,\n",
       "  45528,\n",
       "  36943,\n",
       "  4954,\n",
       "  17395,\n",
       "  45579,\n",
       "  41606,\n",
       "  19081,\n",
       "  18919,\n",
       "  52464,\n",
       "  65446,\n",
       "  13444,\n",
       "  49228,\n",
       "  14245,\n",
       "  58382,\n",
       "  6731,\n",
       "  18010],\n",
       " [44374, 53920, 58270, 15311, 41457, 9516],\n",
       " [10040, 15248, 62909, 20031, 26008, 67979],\n",
       " [13764, 14837, 5350, 12912, 23262, 51342, 55523, 34300, 9946],\n",
       " [60528, 42102, 28685, 54854, 26226, 9324, 36984, 5538],\n",
       " [29110, 40308, 26008, 8037, 14861, 4104],\n",
       " [50750, 53381, 56215, 20525, 17514, 53381, 56215],\n",
       " [25436,\n",
       "  51473,\n",
       "  65186,\n",
       "  51723,\n",
       "  15155,\n",
       "  48654,\n",
       "  28169,\n",
       "  63161,\n",
       "  56589,\n",
       "  21096,\n",
       "  42193,\n",
       "  27729,\n",
       "  6574,\n",
       "  11207,\n",
       "  12439,\n",
       "  2591,\n",
       "  20787,\n",
       "  5162,\n",
       "  59457,\n",
       "  23801,\n",
       "  15345,\n",
       "  55925,\n",
       "  20787,\n",
       "  31952,\n",
       "  2262,\n",
       "  27817,\n",
       "  47466,\n",
       "  56412,\n",
       "  19517,\n",
       "  65699,\n",
       "  46787,\n",
       "  52722,\n",
       "  22869,\n",
       "  17051,\n",
       "  42141,\n",
       "  34940,\n",
       "  9811,\n",
       "  50196,\n",
       "  2398,\n",
       "  23685,\n",
       "  54170,\n",
       "  16664,\n",
       "  21672,\n",
       "  68464,\n",
       "  3135,\n",
       "  12462,\n",
       "  51365],\n",
       " [64097, 41211, 60559, 17204, 34936, 39598, 58667],\n",
       " [47231, 33876, 37622, 36397, 7947, 63993],\n",
       " [65170,\n",
       "  34317,\n",
       "  24126,\n",
       "  49522,\n",
       "  65170,\n",
       "  55791,\n",
       "  43253,\n",
       "  59236,\n",
       "  46168,\n",
       "  29536,\n",
       "  199,\n",
       "  34935,\n",
       "  25265],\n",
       " [24170, 61004, 47383, 45932, 45579, 49863],\n",
       " [66650, 52561, 12409, 21809, 15019, 12409],\n",
       " [53381, 372, 37192, 53806, 26008, 25399],\n",
       " [38691,\n",
       "  19464,\n",
       "  24657,\n",
       "  7579,\n",
       "  43524,\n",
       "  8831,\n",
       "  61506,\n",
       "  12462,\n",
       "  15970,\n",
       "  52071,\n",
       "  26226,\n",
       "  13896,\n",
       "  9324,\n",
       "  562,\n",
       "  14789],\n",
       " [13522,\n",
       "  49932,\n",
       "  48492,\n",
       "  6731,\n",
       "  20264,\n",
       "  57630,\n",
       "  5072,\n",
       "  5389,\n",
       "  6731,\n",
       "  20131,\n",
       "  65170,\n",
       "  45579,\n",
       "  6089,\n",
       "  34546,\n",
       "  42750],\n",
       " [10159,\n",
       "  51024,\n",
       "  42754,\n",
       "  42451,\n",
       "  57913,\n",
       "  41211,\n",
       "  20051,\n",
       "  62788,\n",
       "  56780,\n",
       "  42754,\n",
       "  7730,\n",
       "  41211,\n",
       "  57913,\n",
       "  37505,\n",
       "  56215,\n",
       "  38136,\n",
       "  18841],\n",
       " [59142, 26008, 15398, 7809, 26597],\n",
       " [54824,\n",
       "  39425,\n",
       "  1777,\n",
       "  21387,\n",
       "  43770,\n",
       "  26564,\n",
       "  41307,\n",
       "  16592,\n",
       "  16111,\n",
       "  32870,\n",
       "  51608,\n",
       "  44930,\n",
       "  32241,\n",
       "  56475,\n",
       "  28555],\n",
       " [42750, 20446, 44374, 26008],\n",
       " [21539, 30884, 11625, 35906, 64014, 49507],\n",
       " [52426, 51775, 19227, 10538, 3945, 30662],\n",
       " [8470, 16854, 1777, 35328, 25436, 53767, 33970, 25962, 9810, 66779],\n",
       " [10549, 66805, 45855, 54854, 26226, 13693, 14789],\n",
       " [68748, 34727, 6331, 34545, 65149, 43226],\n",
       " [59066, 48492, 16659, 52183, 31205, 41211, 39599, 16491, 64221],\n",
       " [24264, 45579, 53381, 61898, 46168, 5216],\n",
       " [26226, 17922, 23876, 56006, 3218],\n",
       " [39922, 25205, 61748, 42412, 6514, 36288],\n",
       " [65170, 65414, 52411, 32904, 51775, 27317],\n",
       " [20446, 68718, 6349, 41606, 24612, 6731],\n",
       " [40813, 49995, 6731, 64664, 3601, 39102, 55134, 28566],\n",
       " [26284,\n",
       "  48255,\n",
       "  46510,\n",
       "  25651,\n",
       "  10159,\n",
       "  49863,\n",
       "  48133,\n",
       "  10031,\n",
       "  48492,\n",
       "  13006,\n",
       "  15956,\n",
       "  65458,\n",
       "  41606,\n",
       "  9327,\n",
       "  25118,\n",
       "  42451,\n",
       "  38422,\n",
       "  54044,\n",
       "  34638,\n",
       "  33202],\n",
       " [41101, 46491, 31503, 38006, 11436, 30723],\n",
       " [15482, 25508, 14726, 1335, 10159, 62608, 60030, 51531, 65414],\n",
       " [21901, 4954, 26008, 40541, 29712, 14434, 14504, 51853],\n",
       " [64001, 39358, 18775, 49431, 14837, 10036, 25024, 18427, 39358],\n",
       " [27349, 6531, 29230, 3832, 68931, 19020],\n",
       " [63240,\n",
       "  10177,\n",
       "  50493,\n",
       "  10163,\n",
       "  69038,\n",
       "  58543,\n",
       "  621,\n",
       "  19514,\n",
       "  66718,\n",
       "  43524,\n",
       "  21672,\n",
       "  65408,\n",
       "  20451,\n",
       "  8621,\n",
       "  44703],\n",
       " [50750, 27393, 30723, 38342, 11436],\n",
       " [65414, 56480, 25508, 20356, 46168, 58521, 40308, 53105],\n",
       " [22527, 11528, 61193, 40443, 19143, 14093],\n",
       " [32330, 41211, 65414, 52411, 56215, 17622, 40563, 6731, 45579],\n",
       " [2865, 5734, 30533, 8222, 58176, 45899, 19064, 41606, 24915],\n",
       " [25508, 44150, 13006, 57500, 58636, 48492, 44795, 11436],\n",
       " [31547, 22594, 42754, 13493, 62423],\n",
       " [26226,\n",
       "  38810,\n",
       "  20342,\n",
       "  40015,\n",
       "  26203,\n",
       "  19143,\n",
       "  11639,\n",
       "  69243,\n",
       "  59184,\n",
       "  52729,\n",
       "  61020,\n",
       "  42320,\n",
       "  65955,\n",
       "  19668],\n",
       " [29712, 48904, 65207, 56475, 35152, 67018],\n",
       " [53945, 25708, 52423, 15931, 32462, 46117, 60166],\n",
       " [44374, 58819, 55639, 44374, 26008, 55749, 42750, 23578],\n",
       " [6731, 45579],\n",
       " [20359, 37874, 16202, 39968, 10644, 49072, 52418, 43575, 64334, 65545],\n",
       " [57933, 58260, 25820, 19583, 16744, 16344, 34089, 21652],\n",
       " [65170, 19878, 5027, 26008, 8541, 46231],\n",
       " [11436, 11436, 11436, 65170, 61004, 61004],\n",
       " [53834, 19008, 28685, 52729, 31943],\n",
       " [14843, 20730, 1225, 18217, 50720, 49282, 55841],\n",
       " [28599, 35136, 68562, 54854, 26226, 9324, 36984, 5538],\n",
       " [14843, 28336, 61545, 64418, 61811, 18190],\n",
       " [45285, 64612, 28555, 62788, 62344, 68812],\n",
       " [38089, 41211, 56475, 61545, 17622, 40563],\n",
       " [44374, 23244, 55783, 46511, 63301],\n",
       " [57856, 63280, 20510, 3359, 56527, 1333],\n",
       " [32904, 65170, 15956, 65170, 60570],\n",
       " [8367,\n",
       "  12595,\n",
       "  25828,\n",
       "  38118,\n",
       "  34546,\n",
       "  53591,\n",
       "  7253,\n",
       "  599,\n",
       "  17595,\n",
       "  46778,\n",
       "  46730,\n",
       "  56102],\n",
       " [14843,\n",
       "  65180,\n",
       "  42451,\n",
       "  41211,\n",
       "  17460,\n",
       "  20920,\n",
       "  62536,\n",
       "  36858,\n",
       "  34069,\n",
       "  23149,\n",
       "  42177,\n",
       "  40393,\n",
       "  45274,\n",
       "  37807,\n",
       "  21856,\n",
       "  21442],\n",
       " [69551,\n",
       "  33974,\n",
       "  39182,\n",
       "  35916,\n",
       "  32285,\n",
       "  1901,\n",
       "  42451,\n",
       "  8220,\n",
       "  35655,\n",
       "  49085,\n",
       "  62865,\n",
       "  49085,\n",
       "  50902,\n",
       "  58260],\n",
       " [53381, 58864, 51554, 65514, 49522, 814, 11850],\n",
       " [32330,\n",
       "  27709,\n",
       "  4954,\n",
       "  23149,\n",
       "  61818,\n",
       "  69250,\n",
       "  54481,\n",
       "  13711,\n",
       "  24283,\n",
       "  22120,\n",
       "  4954,\n",
       "  6731,\n",
       "  59105,\n",
       "  11737,\n",
       "  9148,\n",
       "  66172,\n",
       "  27560,\n",
       "  60368],\n",
       " [6583,\n",
       "  6731,\n",
       "  62443,\n",
       "  30723,\n",
       "  61898,\n",
       "  50720,\n",
       "  6583,\n",
       "  8667,\n",
       "  28350,\n",
       "  25202,\n",
       "  30723,\n",
       "  16133,\n",
       "  19258,\n",
       "  38268,\n",
       "  43562,\n",
       "  39200],\n",
       " [16325, 23086, 20342, 39447, 1658, 21041],\n",
       " [44374, 5389, 56140, 53712],\n",
       " [10549, 37518, 56953, 34685, 9811, 62679, 26403, 2979, 45693, 21788],\n",
       " [68475, 14442, 40199, 44059, 41606, 44014, 59912],\n",
       " [6731,\n",
       "  61545,\n",
       "  68724,\n",
       "  27462,\n",
       "  60288,\n",
       "  2062,\n",
       "  60288,\n",
       "  39237,\n",
       "  36288,\n",
       "  8796,\n",
       "  64432,\n",
       "  31908,\n",
       "  27381,\n",
       "  29062,\n",
       "  38136],\n",
       " [63966, 34196, 58636, 33057, 59006, 14612],\n",
       " [59184, 35372, 1177, 54854, 57137, 56910, 5538, 52246, 53053],\n",
       " [13006, 28536, 4889, 36473, 15437, 25870, 25043, 30723],\n",
       " [50935, 69416, 10386, 5389],\n",
       " [52801, 2949, 20356],\n",
       " [14843, 1614, 54177, 18462, 65319, 37813, 33563, 3777, 53619, 43853, 53712],\n",
       " [10159, 30258, 63289, 10159, 15467, 56187],\n",
       " [52071,\n",
       "  21834,\n",
       "  25436,\n",
       "  1352,\n",
       "  13764,\n",
       "  11639,\n",
       "  66779,\n",
       "  20787,\n",
       "  7101,\n",
       "  10897,\n",
       "  23801,\n",
       "  55974,\n",
       "  39210,\n",
       "  65517,\n",
       "  65517,\n",
       "  50541,\n",
       "  52813,\n",
       "  13100,\n",
       "  31286,\n",
       "  41457,\n",
       "  34611,\n",
       "  18840,\n",
       "  56476,\n",
       "  37829,\n",
       "  52460,\n",
       "  53379,\n",
       "  3251,\n",
       "  59566,\n",
       "  53461,\n",
       "  25788,\n",
       "  16501,\n",
       "  10856,\n",
       "  64524,\n",
       "  55557,\n",
       "  20787,\n",
       "  27346,\n",
       "  1350,\n",
       "  49065,\n",
       "  30461,\n",
       "  12995,\n",
       "  50738,\n",
       "  55557,\n",
       "  39549,\n",
       "  11639,\n",
       "  67887,\n",
       "  45499,\n",
       "  6370,\n",
       "  35435,\n",
       "  48780,\n",
       "  16501,\n",
       "  44566,\n",
       "  27913,\n",
       "  53834,\n",
       "  61395,\n",
       "  61226],\n",
       " [47085,\n",
       "  41384,\n",
       "  67500,\n",
       "  69551,\n",
       "  27051,\n",
       "  11291,\n",
       "  68931,\n",
       "  58869,\n",
       "  63809,\n",
       "  9788,\n",
       "  30664,\n",
       "  42451,\n",
       "  65345,\n",
       "  10159,\n",
       "  45448],\n",
       " [53381, 40813, 24421, 18157, 63145, 2813, 41606, 3093],\n",
       " [49742, 50720, 40472, 35450, 64456, 62877, 47829, 46127, 58382, 23292],\n",
       " [6089,\n",
       "  41606,\n",
       "  35272,\n",
       "  14976,\n",
       "  7963,\n",
       "  62624,\n",
       "  41606,\n",
       "  13006,\n",
       "  54864,\n",
       "  59028,\n",
       "  29502,\n",
       "  43588,\n",
       "  53712,\n",
       "  30462,\n",
       "  37584,\n",
       "  62443],\n",
       " [62756, 68030, 26008, 539, 28881, 54021, 59082],\n",
       " [59660, 2827, 49190, 38460, 9987],\n",
       " [2313, 52805, 44171, 53097, 62756, 69254],\n",
       " [20356,\n",
       "  67962,\n",
       "  67076,\n",
       "  21502,\n",
       "  10321,\n",
       "  30047,\n",
       "  4954,\n",
       "  56796,\n",
       "  28246,\n",
       "  54246,\n",
       "  67992,\n",
       "  20525,\n",
       "  9970,\n",
       "  3178,\n",
       "  28246,\n",
       "  62387,\n",
       "  16584],\n",
       " [45729, 16059, 4747, 58597, 66184],\n",
       " [55749, 55410, 44983, 40563, 4954, 49522, 50957, 49863, 40558],\n",
       " [52426, 5389, 11093, 63630],\n",
       " [32901, 26377, 56390, 14455, 37495, 7168],\n",
       " [55320,\n",
       "  27019,\n",
       "  18903,\n",
       "  26581,\n",
       "  26226,\n",
       "  2701,\n",
       "  9324,\n",
       "  562,\n",
       "  5538,\n",
       "  7391,\n",
       "  3102,\n",
       "  68562,\n",
       "  25691],\n",
       " [48714, 20787, 61281, 15168, 33003, 14422, 34296, 44703],\n",
       " [10159,\n",
       "  25508,\n",
       "  39577,\n",
       "  65475,\n",
       "  47922,\n",
       "  48033,\n",
       "  53502,\n",
       "  30285,\n",
       "  34336,\n",
       "  49522,\n",
       "  11625,\n",
       "  47085,\n",
       "  4954,\n",
       "  21839,\n",
       "  35525,\n",
       "  62076],\n",
       " [30388, 52561, 66729, 54854, 52071, 26226, 9324, 36984, 5538],\n",
       " [16952, 24903, 34935, 66309, 26008],\n",
       " [24264, 57500, 32330, 45813, 30723, 1178, 3148],\n",
       " [15398, 7809, 26597, 41606, 21410, 48492],\n",
       " [61289,\n",
       "  7520,\n",
       "  41428,\n",
       "  40593,\n",
       "  61564,\n",
       "  50842,\n",
       "  23292,\n",
       "  44923,\n",
       "  53381,\n",
       "  41211,\n",
       "  54305,\n",
       "  1474,\n",
       "  12202,\n",
       "  41222],\n",
       " [25436,\n",
       "  29850,\n",
       "  13409,\n",
       "  52071,\n",
       "  26226,\n",
       "  31803,\n",
       "  18023,\n",
       "  67602,\n",
       "  14228,\n",
       "  58257,\n",
       "  27241,\n",
       "  29961,\n",
       "  67741,\n",
       "  61126,\n",
       "  21506,\n",
       "  54931,\n",
       "  19208,\n",
       "  681,\n",
       "  31866,\n",
       "  26226,\n",
       "  9324,\n",
       "  36984,\n",
       "  29850,\n",
       "  48191,\n",
       "  54854,\n",
       "  5538],\n",
       " [55639, 51943, 21839, 22961, 55523, 61673, 15506, 18726, 15467, 54728, 56629],\n",
       " [21045, 45579, 32904, 40919, 34935, 66309, 12222, 26008, 7842],\n",
       " [54586, 54586, 30662, 54586, 30662, 2296, 64770, 28405, 68517],\n",
       " [58945, 29712, 6200, 6200, 1063, 53097, 54542, 28555, 36999],\n",
       " [60232,\n",
       "  19642,\n",
       "  65993,\n",
       "  48348,\n",
       "  62982,\n",
       "  22545,\n",
       "  44793,\n",
       "  52106,\n",
       "  24152,\n",
       "  63638,\n",
       "  20387,\n",
       "  57424,\n",
       "  26889,\n",
       "  35961,\n",
       "  28965],\n",
       " [3439, 33320, 52438, 39358, 32014],\n",
       " [32904, 65414, 52411, 4954, 48492, 36397, 26516, 26008, 7563],\n",
       " [42451,\n",
       "  15043,\n",
       "  63173,\n",
       "  24878,\n",
       "  16393,\n",
       "  4410,\n",
       "  43653,\n",
       "  52380,\n",
       "  23655,\n",
       "  13006,\n",
       "  13356,\n",
       "  39892,\n",
       "  42451,\n",
       "  19064,\n",
       "  61798,\n",
       "  43267,\n",
       "  12810],\n",
       " [27313, 5677, 52071, 6712, 24124, 44703, 42165, 5538],\n",
       " [31145, 14075, 56215, 7050, 31393, 31145, 483, 6412],\n",
       " [8574, 13475, 60733, 26252, 6731],\n",
       " [6731, 24264, 45579, 6731, 40563, 35152],\n",
       " [65170, 45148, 23244, 28916, 21909, 21909],\n",
       " [17815, 564, 42182, 20787, 19212, 10142, 66164, 43941, 34685],\n",
       " [34284, 2412, 55551, 58869, 4325, 5538, 61020, 47917, 50653],\n",
       " [17202, 44327, 42451, 51828, 17294, 6731, 16630, 66616],\n",
       " [48492, 24505, 42754, 42451, 49580, 20446, 48492],\n",
       " [64001, 57595, 66639, 63145, 16744, 16344, 58901, 3234, 16957],\n",
       " [57595, 16744, 16344, 12472, 20814],\n",
       " [20920,\n",
       "  27160,\n",
       "  57054,\n",
       "  49522,\n",
       "  25892,\n",
       "  4223,\n",
       "  44944,\n",
       "  12472,\n",
       "  1490,\n",
       "  42451,\n",
       "  41211,\n",
       "  60796,\n",
       "  10422,\n",
       "  17861,\n",
       "  18070,\n",
       "  4413,\n",
       "  44859,\n",
       "  4234,\n",
       "  34517,\n",
       "  47867,\n",
       "  18996,\n",
       "  38585,\n",
       "  28383,\n",
       "  2134],\n",
       " [6731, 49863, 65414, 29916, 41606, 4954],\n",
       " [48463, 843, 49609, 42754, 65414, 38994, 38578, 38452, 59110],\n",
       " [43404, 24563, 31503, 34895, 6436, 16400],\n",
       " [65170, 62492, 38161, 19423, 37204, 28747, 18231, 60450, 5962, 37204],\n",
       " [69526,\n",
       "  62756,\n",
       "  41606,\n",
       "  53381,\n",
       "  16344,\n",
       "  21515,\n",
       "  26192,\n",
       "  62799,\n",
       "  2561,\n",
       "  42684,\n",
       "  26555,\n",
       "  18295,\n",
       "  22757,\n",
       "  54505,\n",
       "  6670],\n",
       " [42750, 52969, 6200, 62009, 15747, 58351, 17923],\n",
       " [65170, 53381, 58636, 41211, 3824, 27705],\n",
       " [6731, 3945, 54062, 6731, 4182, 31656, 1490, 19230, 15916, 23924],\n",
       " [34026, 68030, 26008, 6764, 46766],\n",
       " [17403, 5607, 47220, 50750, 25202, 4954, 13264],\n",
       " [53097, 21243, 41211, 54198, 34875, 47029],\n",
       " [24878, 25508, 53735, 54246, 14843, 41457, 37451, 63280, 26008],\n",
       " [11436,\n",
       "  1490,\n",
       "  16111,\n",
       "  62957,\n",
       "  18637,\n",
       "  3544,\n",
       "  48567,\n",
       "  19701,\n",
       "  62957,\n",
       "  42131,\n",
       "  57668,\n",
       "  3780],\n",
       " [58036, 28070, 14335, 1177, 3479, 28685, 54854, 26226, 9324, 36984, 5538],\n",
       " [18111, 62344, 26008, 18111, 2865, 41056, 30723, 15437],\n",
       " [53809,\n",
       "  46168,\n",
       "  44620,\n",
       "  11436,\n",
       "  10590,\n",
       "  59730,\n",
       "  50090,\n",
       "  4954,\n",
       "  51081,\n",
       "  42466,\n",
       "  1490,\n",
       "  50935,\n",
       "  34935],\n",
       " [15889, 27019, 652, 42810, 54854, 5538],\n",
       " [16952, 45381, 32465],\n",
       " [6199,\n",
       "  53630,\n",
       "  50824,\n",
       "  46507,\n",
       "  47008,\n",
       "  57275,\n",
       "  55749,\n",
       "  12596,\n",
       "  430,\n",
       "  55749,\n",
       "  26434,\n",
       "  23158,\n",
       "  25436,\n",
       "  49403,\n",
       "  65777,\n",
       "  53538,\n",
       "  62527,\n",
       "  51055,\n",
       "  12800,\n",
       "  13927,\n",
       "  1590,\n",
       "  56928,\n",
       "  16725,\n",
       "  14317,\n",
       "  7141,\n",
       "  21939,\n",
       "  23606,\n",
       "  34685,\n",
       "  38554,\n",
       "  25436,\n",
       "  38554,\n",
       "  29597,\n",
       "  8621,\n",
       "  1003,\n",
       "  34685,\n",
       "  48133,\n",
       "  60333,\n",
       "  14682,\n",
       "  64431,\n",
       "  34685,\n",
       "  39210,\n",
       "  51055,\n",
       "  58634,\n",
       "  50785,\n",
       "  64222,\n",
       "  25436,\n",
       "  25436,\n",
       "  25436,\n",
       "  15157,\n",
       "  69277,\n",
       "  32141,\n",
       "  34890,\n",
       "  38432,\n",
       "  28974],\n",
       " [55749, 18157, 65170, 45579, 53381, 45579, 34936],\n",
       " [61898, 46168, 42073, 45579, 15440, 46168],\n",
       " [69317, 16952, 53381, 13885, 55401, 20356],\n",
       " [3575, 32132, 35478, 47956, 55933, 26226, 25181, 32932, 15199],\n",
       " [44059, 55345, 68386, 28761, 14327, 52909],\n",
       " [18778, 59575, 44059, 48426, 36458, 61122, 50656],\n",
       " [48806,\n",
       "  34936,\n",
       "  34912,\n",
       "  34936,\n",
       "  12912,\n",
       "  34936,\n",
       "  53049,\n",
       "  34936,\n",
       "  66718,\n",
       "  34936,\n",
       "  40457,\n",
       "  34936],\n",
       " [54451, 50015, 62443, 62344, 26008],\n",
       " [53381, 25086, 16258, 58186, 26008, 27837, 51293],\n",
       " [32904, 45579, 4741, 32860, 26008, 1819],\n",
       " [11429, 17244, 22040, 47977, 52729, 14789],\n",
       " [19525, 57274, 62443, 25270, 53359, 24354],\n",
       " [29712,\n",
       "  64753,\n",
       "  30723,\n",
       "  46840,\n",
       "  33098,\n",
       "  62241,\n",
       "  34829,\n",
       "  3730,\n",
       "  45420,\n",
       "  56833,\n",
       "  41211,\n",
       "  53519,\n",
       "  57932,\n",
       "  51081,\n",
       "  31222],\n",
       " [27349, 1565, 48442, 39360, 48699, 48191, 12240, 31206],\n",
       " [64682, 62107, 37075, 55574, 35204, 51155, 30723, 49281, 57932, 66955],\n",
       " [45579, 42750, 40531, 55749, 53712],\n",
       " [44098,\n",
       "  65414,\n",
       "  52411,\n",
       "  65170,\n",
       "  45579,\n",
       "  12506,\n",
       "  502,\n",
       "  40563,\n",
       "  2917,\n",
       "  29502,\n",
       "  25918,\n",
       "  53381,\n",
       "  65414,\n",
       "  52411,\n",
       "  39962,\n",
       "  59588,\n",
       "  55575],\n",
       " [21104, 27754, 21104, 41468, 15956],\n",
       " [3230, 33838, 54854, 30854, 9324, 36984, 31943],\n",
       " [41092,\n",
       "  41687,\n",
       "  36171,\n",
       "  50270,\n",
       "  41606,\n",
       "  15316,\n",
       "  53381,\n",
       "  51804,\n",
       "  7474,\n",
       "  13587,\n",
       "  23595,\n",
       "  41015,\n",
       "  36146],\n",
       " [44070, 39180, 42082, 54854, 14789],\n",
       " [20356,\n",
       "  53712,\n",
       "  19266,\n",
       "  42750,\n",
       "  39644,\n",
       "  20356,\n",
       "  62443,\n",
       "  34813,\n",
       "  26008,\n",
       "  60927,\n",
       "  53381,\n",
       "  58977,\n",
       "  61898,\n",
       "  62443,\n",
       "  60824],\n",
       " [20959, 64097, 22576, 410, 55601, 53381, 65673, 28090, 30723, 41787],\n",
       " [36288, 45932, 54051, 67638, 36288],\n",
       " [40873, 32652, 38840, 58205, 4954, 25532, 59563, 24713, 54005, 51081, 20056],\n",
       " [42466, 29712, 14434, 66713, 61022, 24351],\n",
       " [42451, 67358, 20525, 30673, 45579, 30444, 54485],\n",
       " [11739, 59256, 11436, 21039, 53712, 3811, 1496, 58268, 51411, 62443],\n",
       " [29712, 30723, 31435, 9516, 41427, 23435],\n",
       " [21045, 20224, 11878, 61004, 53105],\n",
       " [28488, 2949, 57738],\n",
       " [38823,\n",
       "  18498,\n",
       "  17815,\n",
       "  56790,\n",
       "  34216,\n",
       "  12236,\n",
       "  54405,\n",
       "  41645,\n",
       "  44505,\n",
       "  49279,\n",
       "  56384,\n",
       "  25386,\n",
       "  52071,\n",
       "  59993,\n",
       "  17815,\n",
       "  41473,\n",
       "  17567,\n",
       "  11069,\n",
       "  55334,\n",
       "  42257,\n",
       "  21202,\n",
       "  7358,\n",
       "  64681,\n",
       "  17611,\n",
       "  65671,\n",
       "  33599,\n",
       "  64681,\n",
       "  17426,\n",
       "  54039,\n",
       "  61099,\n",
       "  50348,\n",
       "  12622,\n",
       "  8213,\n",
       "  48370,\n",
       "  49798,\n",
       "  60611,\n",
       "  38048,\n",
       "  37829,\n",
       "  27039,\n",
       "  38432,\n",
       "  22951,\n",
       "  51039,\n",
       "  29012,\n",
       "  907,\n",
       "  42413,\n",
       "  24681,\n",
       "  16453,\n",
       "  43306,\n",
       "  60628,\n",
       "  12325,\n",
       "  753,\n",
       "  12511],\n",
       " [10142,\n",
       "  19212,\n",
       "  26226,\n",
       "  38667,\n",
       "  63792,\n",
       "  9324,\n",
       "  36984,\n",
       "  5538,\n",
       "  63396,\n",
       "  34763,\n",
       "  9387,\n",
       "  33614],\n",
       " [3994,\n",
       "  36529,\n",
       "  56537,\n",
       "  52813,\n",
       "  68028,\n",
       "  57101,\n",
       "  41235,\n",
       "  40934,\n",
       "  11639,\n",
       "  23916,\n",
       "  29860,\n",
       "  40934,\n",
       "  67827],\n",
       " [15467, 13586, 56187, 40563, 48967, 26008, 7842],\n",
       " [8524, 21345, 57485, 8524, 11639, 67718, 40336, 21, 31943],\n",
       " [2865, 56215, 22948, 39476, 45579, 48664],\n",
       " [8849, 46168, 45579, 41606, 54305, 1474, 23243],\n",
       " [28405, 42754, 37971, 7693, 6731, 66468, 33574, 7693, 6412, 16388],\n",
       " [41211,\n",
       "  8806,\n",
       "  46675,\n",
       "  6349,\n",
       "  1091,\n",
       "  15398,\n",
       "  27950,\n",
       "  16228,\n",
       "  50757,\n",
       "  19974,\n",
       "  50757,\n",
       "  12506],\n",
       " [62261,\n",
       "  34033,\n",
       "  50932,\n",
       "  67929,\n",
       "  43705,\n",
       "  3226,\n",
       "  31080,\n",
       "  8842,\n",
       "  35997,\n",
       "  9977,\n",
       "  55404,\n",
       "  14003,\n",
       "  31080],\n",
       " [48129,\n",
       "  69275,\n",
       "  28709,\n",
       "  14581,\n",
       "  26656,\n",
       "  39703,\n",
       "  10303,\n",
       "  21839,\n",
       "  51444,\n",
       "  34625,\n",
       "  12955,\n",
       "  36630],\n",
       " [1455, 26113, 51821, 45579, 56215, 48492],\n",
       " [42750, 40531, 51775, 42281, 65414, 52411, 46168],\n",
       " [45579, 45579, 45579, 45579, 24264, 45579, 4903, 6363, 42754, 72],\n",
       " [65762, 36082, 44703, 62344, 26008, 65762, 62443],\n",
       " [57663,\n",
       "  60265,\n",
       "  33903,\n",
       "  978,\n",
       "  10785,\n",
       "  4957,\n",
       "  47929,\n",
       "  36061,\n",
       "  40529,\n",
       "  19432,\n",
       "  52216,\n",
       "  61099,\n",
       "  42344,\n",
       "  56974,\n",
       "  3257,\n",
       "  52876,\n",
       "  30791,\n",
       "  43304,\n",
       "  57511,\n",
       "  21226,\n",
       "  20856,\n",
       "  59422,\n",
       "  49343,\n",
       "  32408,\n",
       "  13323,\n",
       "  27723,\n",
       "  17890,\n",
       "  39545,\n",
       "  62982,\n",
       "  52966,\n",
       "  10841,\n",
       "  40529,\n",
       "  19432,\n",
       "  48780,\n",
       "  61099],\n",
       " [45977, 59464, 66316, 51444, 59256],\n",
       " [31435, 56371, 39311, 30723, 12636, 3601],\n",
       " [3712, 42333, 24284, 12948, 3712, 57616, 12930, 32283, 44681],\n",
       " [6731, 45579, 17822, 4889],\n",
       " [43531,\n",
       "  19064,\n",
       "  57913,\n",
       "  68201,\n",
       "  43253,\n",
       "  18752,\n",
       "  12589,\n",
       "  57357,\n",
       "  57913,\n",
       "  58451,\n",
       "  44150,\n",
       "  41805,\n",
       "  6731],\n",
       " [24681,\n",
       "  60380,\n",
       "  44730,\n",
       "  7974,\n",
       "  14228,\n",
       "  3371,\n",
       "  34642,\n",
       "  38169,\n",
       "  11639,\n",
       "  13406,\n",
       "  23121,\n",
       "  49244,\n",
       "  23121,\n",
       "  41457,\n",
       "  51350,\n",
       "  29486,\n",
       "  35648,\n",
       "  45657,\n",
       "  65790,\n",
       "  25757,\n",
       "  15183,\n",
       "  60200,\n",
       "  17815,\n",
       "  46896],\n",
       " [23245, 43161, 42754, 58310, 14837, 2865, 12912, 31222],\n",
       " [948, 16388, 67376, 62813, 27484, 51068, 39312, 4954, 61911, 24264, 5389],\n",
       " [37982, 7857, 29712, 66524, 40532, 66460, 59626, 7787],\n",
       " [26622, 38970, 14621, 10897, 69269, 67002, 60399, 9324, 36984, 31943],\n",
       " [61423, 57506, 23578, 52426, 42750],\n",
       " [62427, 36165, 64080, 33142, 61594, 20446],\n",
       " [38082, 28071, 37204, 68562, 46029, 54854, 16952, 9324, 36984, 31943],\n",
       " [62788, 4019, 41211, 42750, 62344, 41211, 68812],\n",
       " [45863, 32861, 34821, 62756, 47572, 4168],\n",
       " [9687,\n",
       "  32050,\n",
       "  30149,\n",
       "  7782,\n",
       "  31843,\n",
       "  52071,\n",
       "  66000,\n",
       "  47929,\n",
       "  25436,\n",
       "  652,\n",
       "  60315,\n",
       "  53972,\n",
       "  66231,\n",
       "  2832,\n",
       "  17244,\n",
       "  19008,\n",
       "  17799,\n",
       "  22830],\n",
       " [975, 11875, 29767, 59586, 62443],\n",
       " [62756, 6731, 62443, 62344, 26008, 63145, 45637],\n",
       " [23206, 42451, 50693, 4848, 28812, 16682, 4848, 36109],\n",
       " [6731, 18157, 65170, 45579, 34935, 39512, 14245, 42451, 26008, 7842],\n",
       " [13764,\n",
       "  14837,\n",
       "  5350,\n",
       "  12912,\n",
       "  24616,\n",
       "  32271,\n",
       "  55523,\n",
       "  34300,\n",
       "  6367,\n",
       "  67829,\n",
       "  49863,\n",
       "  13064,\n",
       "  6731,\n",
       "  29133],\n",
       " [46904, 14632, 36228, 52411, 32050],\n",
       " [40841, 40841, 40841, 40841, 40841, 40841, 48206, 44620],\n",
       " [6731, 52411, 59660],\n",
       " [20541,\n",
       "  1901,\n",
       "  26617,\n",
       "  46151,\n",
       "  37839,\n",
       "  6381,\n",
       "  49178,\n",
       "  6839,\n",
       "  14434,\n",
       "  7699,\n",
       "  20152,\n",
       "  22304,\n",
       "  15414,\n",
       "  60506,\n",
       "  56617],\n",
       " [39962,\n",
       "  23854,\n",
       "  55575,\n",
       "  975,\n",
       "  56215,\n",
       "  57932,\n",
       "  2673,\n",
       "  53177,\n",
       "  37192,\n",
       "  38590,\n",
       "  2645,\n",
       "  4019,\n",
       "  36288,\n",
       "  42451,\n",
       "  31705,\n",
       "  14235],\n",
       " [6731, 11352, 44700, 35444, 42777, 8603, 10159, 53381, 8714, 50842, 65170],\n",
       " [63582, 28070, 52465, 42810, 54854, 44758, 13077],\n",
       " [62619, 9516, 4954, 12472, 23888],\n",
       " [47769, 31735, 25508, 66594, 6559, 64090, 13006, 47929, 66594, 52782],\n",
       " [10673, 82, 54854, 34287, 26226, 2701, 9324, 36984, 31943],\n",
       " [15956, 46168, 45579, 51444, 32904, 42750],\n",
       " [61201,\n",
       "  62338,\n",
       "  15956,\n",
       "  62443,\n",
       "  61848,\n",
       "  40591,\n",
       "  35451,\n",
       "  29357,\n",
       "  11450,\n",
       "  58189,\n",
       "  62443,\n",
       "  55639,\n",
       "  5933,\n",
       "  57071,\n",
       "  62338,\n",
       "  3811,\n",
       "  21901,\n",
       "  27013],\n",
       " [62648, 56480, 896, 44098, 62443, 26008],\n",
       " [61761, 42754, 9019, 61898, 42754, 58382, 12955, 19064, 27877, 24233],\n",
       " [68852,\n",
       "  57117,\n",
       "  63302,\n",
       "  9132,\n",
       "  17917,\n",
       "  2724,\n",
       "  39449,\n",
       "  22088,\n",
       "  54759,\n",
       "  17822,\n",
       "  50494,\n",
       "  66359,\n",
       "  45982,\n",
       "  22339,\n",
       "  30692],\n",
       " [14870, 14870, 14870, 12598, 44995, 49670, 41680, 58636, 60191, 12992, 32914],\n",
       " [57814, 19550, 2949, 53381, 12541, 26008, 61898],\n",
       " [55292, 11373, 43823, 8220, 6374, 34438],\n",
       " [46788, 21168, 45464, 53619, 55575, 8862],\n",
       " [41694, 54852, 10163, 41959, 41916, 51601, 61941, 36200, 34287],\n",
       " [20787, 45657, 47394, 35206, 68292, 45657, 30501, 35206, 28953, 18769, 47964],\n",
       " [15398, 32685, 56213, 27017, 35200, 49518, 41192, 6581, 69104, 44235],\n",
       " [5282, 16744, 52010, 1490, 69261, 58331, 10858, 15398, 5282, 62443, 30723],\n",
       " [29956,\n",
       "  18862,\n",
       "  39883,\n",
       "  31108,\n",
       "  69193,\n",
       "  53063,\n",
       "  22521,\n",
       "  39548,\n",
       "  36602,\n",
       "  35492,\n",
       "  4429,\n",
       "  41589,\n",
       "  38328,\n",
       "  51383],\n",
       " [18369, 27019, 60371, 27019, 43484, 52729, 34287, 30854, 9324, 36984, 5538],\n",
       " [20649, 45180, 62443, 62788, 10159, 53381, 19064, 11276, 18572, 15751],\n",
       " [25651, 41211, 23519, 16375, 3871, 9433, 11093, 65414, 62476, 28106],\n",
       " [15956, 29767, 59586, 62443, 26008],\n",
       " [27832, 6968, 53381, 2706, 57798, 14053],\n",
       " [36305, 36773, 62443, 5214, 26008],\n",
       " [52426, 45579, 31678, 32870, 36848, 58804],\n",
       " [10678, 28070, 85, 24859, 54854, 5538],\n",
       " [19529, 9341, 22853, 47866, 29325, 58819, 30375, 21525, 65647],\n",
       " [15437, 8499, 36018, 37616, 52976, 30723, 45863, 12867],\n",
       " [7323, 59228, 53381, 11093, 39587, 26008, 66224],\n",
       " [11093,\n",
       "  51116,\n",
       "  39862,\n",
       "  57595,\n",
       "  16980,\n",
       "  50015,\n",
       "  42177,\n",
       "  5389,\n",
       "  6256,\n",
       "  33421,\n",
       "  5705,\n",
       "  4926,\n",
       "  64337,\n",
       "  33656],\n",
       " [48311, 34923, 4606, 27640, 46651, 66650, 64359, 30889, 13406],\n",
       " [7266, 12060, 50914, 22282, 548, 8524, 11639],\n",
       " [6731, 28405, 21609, 28632, 16111, 54297, 57836, 26008],\n",
       " [24264, 61492, 15956, 14346, 13889, 57368],\n",
       " [47099, 45554, 9664, 62700, 58382, 14123],\n",
       " [2865, 66203, 4873, 32904, 20925, 68433, 58543],\n",
       " [69630, 46813, 54854, 26226, 50224, 9324, 36984, 5538],\n",
       " [36680, 53381, 50949, 10897, 13054, 49670, 24540],\n",
       " [58478, 41745, 26008, 36148, 64483, 18295, 41606, 36148, 33576],\n",
       " [32202, 8852, 41606, 60166, 47556],\n",
       " [6881, 42451, 58196, 45579, 12666, 48492, 19846, 59711, 49196],\n",
       " [54999, 30723, 2700, 20987, 65583],\n",
       " [59567, 24264, 20224, 25508, 28066, 36343],\n",
       " [60796, 28348, 51821, 26008, 7842],\n",
       " [14843,\n",
       "  65588,\n",
       "  32904,\n",
       "  9642,\n",
       "  23160,\n",
       "  51444,\n",
       "  61644,\n",
       "  11691,\n",
       "  3869,\n",
       "  50720,\n",
       "  14429,\n",
       "  55908,\n",
       "  17202],\n",
       " [22039, 36109, 66517, 64638, 45555, 51444, 14043],\n",
       " [17202, 34546, 65170, 45579, 34935, 39512, 42451, 26008, 7842],\n",
       " [9216,\n",
       "  49437,\n",
       "  47539,\n",
       "  65733,\n",
       "  20373,\n",
       "  34895,\n",
       "  57932,\n",
       "  8667,\n",
       "  45,\n",
       "  25125,\n",
       "  37337,\n",
       "  53456,\n",
       "  49620,\n",
       "  49975],\n",
       " [55206,\n",
       "  60401,\n",
       "  49786,\n",
       "  15990,\n",
       "  51252,\n",
       "  59402,\n",
       "  37263,\n",
       "  60046,\n",
       "  67028,\n",
       "  64001,\n",
       "  58952,\n",
       "  64162],\n",
       " [65414, 52411, 31145, 45579, 52964, 45579],\n",
       " [59236, 66718, 42754, 42451, 26008, 7842],\n",
       " [36705, 44059, 3143, 15449, 15054, 59907],\n",
       " [36358, 4954, 49522, 35267, 2374, 22189, 61898, 46168, 975],\n",
       " [14776, 18697, 62443, 26008, 43479, 6326],\n",
       " [38504, 13444, 53732, 19064, 18334],\n",
       " [52426, 52426, 52426, 52426, 47187, 8541],\n",
       " [58004,\n",
       "  54062,\n",
       "  41061,\n",
       "  4410,\n",
       "  63361,\n",
       "  40563,\n",
       "  31397,\n",
       "  5607,\n",
       "  55406,\n",
       "  10488,\n",
       "  41795,\n",
       "  153,\n",
       "  27393,\n",
       "  3817,\n",
       "  14843,\n",
       "  31928],\n",
       " [57668,\n",
       "  3780,\n",
       "  28555,\n",
       "  34935,\n",
       "  14245,\n",
       "  19064,\n",
       "  41848,\n",
       "  41211,\n",
       "  65414,\n",
       "  52411,\n",
       "  4954,\n",
       "  25470,\n",
       "  19230],\n",
       " [59730, 27232, 4954, 66856, 3914, 13994, 36848, 22581],\n",
       " [11856,\n",
       "  37514,\n",
       "  16258,\n",
       "  56323,\n",
       "  39764,\n",
       "  45118,\n",
       "  29671,\n",
       "  8667,\n",
       "  56215,\n",
       "  28837,\n",
       "  51853,\n",
       "  62568,\n",
       "  53823,\n",
       "  46453,\n",
       "  41844],\n",
       " [24446, 41606, 4954, 11436, 54926, 12289, 41606, 4954, 60062, 29384],\n",
       " [51444, 52811, 32904, 61585],\n",
       " [10678, 27019, 17244, 22040, 26747, 54854, 26226, 9324, 562, 31943],\n",
       " [948, 14442, 26008, 34336, 630, 41606],\n",
       " [45579, 45579, 45579, 6363, 66316, 51444],\n",
       " [16952, 9954, 44478, 61545, 15956, 46168, 26339, 10159, 1837, 14837, 25216],\n",
       " [58479, 3945, 30662, 35495, 10552],\n",
       " [43580, 3933, 49765, 39598, 18666, 12289, 57547],\n",
       " [48451, 34935, 50431, 42640, 37874, 41163],\n",
       " [65414, 52411, 53381, 32887, 51444, 6731],\n",
       " [27591,\n",
       "  32090,\n",
       "  40662,\n",
       "  3666,\n",
       "  37605,\n",
       "  44712,\n",
       "  58437,\n",
       "  68497,\n",
       "  31257,\n",
       "  47184,\n",
       "  44793,\n",
       "  56986,\n",
       "  38774,\n",
       "  7300,\n",
       "  32401,\n",
       "  68562,\n",
       "  16944,\n",
       "  48882,\n",
       "  41616,\n",
       "  67668,\n",
       "  32633,\n",
       "  62131,\n",
       "  12462],\n",
       " [63825, 16221, 57216, 32904, 59549],\n",
       " [5734, 45079, 9516, 4954, 60487, 55080, 41211, 34935, 14990],\n",
       " [53381, 52426, 58636, 48492, 59627, 55749, 62443],\n",
       " [14843, 58710, 58310, 20839, 26132, 9352],\n",
       " [12912, 9278, 34935, 36337],\n",
       " [13882, 18974, 49604, 29597, 66650, 11150, 67647, 64990, 64830, 52071, 25455],\n",
       " [15312, 53630, 3712, 26226, 55663, 62351, 3712, 26226, 8621],\n",
       " [50750,\n",
       "  58382,\n",
       "  38137,\n",
       "  11436,\n",
       "  59826,\n",
       "  62024,\n",
       "  30533,\n",
       "  29627,\n",
       "  37616,\n",
       "  41470,\n",
       "  6773,\n",
       "  31145,\n",
       "  38858,\n",
       "  13167],\n",
       " [5003, 67076, 33314, 45190, 40440, 33969],\n",
       " [42898, 10386, 5389, 5389, 5389, 46825, 16168],\n",
       " [13356, 410, 25328, 14843, 28242, 49522, 14504],\n",
       " [15990, 57871, 41211, 11450, 56215, 12443, 38136, 34935, 59280],\n",
       " [67359,\n",
       "  53994,\n",
       "  18569,\n",
       "  4954,\n",
       "  18669,\n",
       "  56475,\n",
       "  49863,\n",
       "  22099,\n",
       "  10159,\n",
       "  41606,\n",
       "  4954,\n",
       "  21482,\n",
       "  3715,\n",
       "  4873],\n",
       " [61898, 62443, 56577, 26008, 7842],\n",
       " [32086, 66916, 15956, 46168, 39102, 59642],\n",
       " [56371,\n",
       "  21149,\n",
       "  53820,\n",
       "  44768,\n",
       "  31397,\n",
       "  27038,\n",
       "  58636,\n",
       "  10159,\n",
       "  1427,\n",
       "  11436,\n",
       "  10159,\n",
       "  50478,\n",
       "  2860,\n",
       "  4954,\n",
       "  48528,\n",
       "  44037,\n",
       "  21977],\n",
       " [58478, 51548, 53381, 28066, 29822, 16388, 44264, 41642, 65139],\n",
       " [18157, 26008, 53097, 21243, 34128],\n",
       " [7434, 23071, 28572, 24782, 49072, 21927, 52229, 54198, 62160, 9958],\n",
       " [39301,\n",
       "  66172,\n",
       "  35201,\n",
       "  39958,\n",
       "  11891,\n",
       "  66594,\n",
       "  45693,\n",
       "  17888,\n",
       "  44566,\n",
       "  13229,\n",
       "  11032,\n",
       "  11458,\n",
       "  44867,\n",
       "  9139,\n",
       "  22373,\n",
       "  63973,\n",
       "  33051,\n",
       "  51665,\n",
       "  23227,\n",
       "  52471,\n",
       "  8478,\n",
       "  1352,\n",
       "  47871,\n",
       "  24998,\n",
       "  16412,\n",
       "  13089,\n",
       "  55122,\n",
       "  28985,\n",
       "  5538,\n",
       "  12462],\n",
       " [52426, 23578, 45579, 55749, 15631],\n",
       " [44703,\n",
       "  44703,\n",
       "  25436,\n",
       "  43689,\n",
       "  30625,\n",
       "  26226,\n",
       "  23638,\n",
       "  33137,\n",
       "  45693,\n",
       "  26226,\n",
       "  12462,\n",
       "  12462],\n",
       " [39764, 25281, 6881, 56475, 35412, 38565],\n",
       " [43853, 67792, 42451, 18176, 39635],\n",
       " [3440, 65414, 56480, 3016, 3440],\n",
       " [54062, 54062, 54062, 58914, 21854],\n",
       " [49742, 41606, 42754, 34852, 40996, 58186, 62344, 26008],\n",
       " [44795, 40211, 20356, 43575, 17287, 3611],\n",
       " [15956, 46168, 35365, 62443, 26008, 20784],\n",
       " [52831,\n",
       "  38452,\n",
       "  56475,\n",
       "  62648,\n",
       "  50966,\n",
       "  7405,\n",
       "  10108,\n",
       "  41715,\n",
       "  1335,\n",
       "  61545,\n",
       "  3278,\n",
       "  27691,\n",
       "  61384,\n",
       "  25270],\n",
       " [43524, 36809, 26929, 5538, 11891, 12462],\n",
       " [52426,\n",
       "  6514,\n",
       "  10027,\n",
       "  65414,\n",
       "  52411,\n",
       "  68480,\n",
       "  36288,\n",
       "  19064,\n",
       "  17622,\n",
       "  46168,\n",
       "  51853,\n",
       "  8667,\n",
       "  41061,\n",
       "  46168,\n",
       "  11739,\n",
       "  59256,\n",
       "  46168],\n",
       " [57631, 6989, 6905, 20201, 15345, 42947, 31678, 54198, 38695, 42921, 62344],\n",
       " [65414, 52411, 50750, 51444],\n",
       " [37598, 16258, 51444, 51849, 68030, 9243],\n",
       " [20925, 21652, 16744, 16344, 17922, 66639, 63145],\n",
       " [54209, 48699, 41606, 11639, 19212],\n",
       " [43524,\n",
       "  14959,\n",
       "  52071,\n",
       "  20342,\n",
       "  42320,\n",
       "  22040,\n",
       "  63746,\n",
       "  35681,\n",
       "  5538,\n",
       "  28953,\n",
       "  26875,\n",
       "  14889,\n",
       "  67768,\n",
       "  54405,\n",
       "  65699,\n",
       "  52071,\n",
       "  14889,\n",
       "  57511,\n",
       "  31243,\n",
       "  56476,\n",
       "  24496,\n",
       "  45486,\n",
       "  3618,\n",
       "  67887,\n",
       "  32408,\n",
       "  10378,\n",
       "  31745,\n",
       "  52071,\n",
       "  26226,\n",
       "  12462,\n",
       "  12462,\n",
       "  12462],\n",
       " [51180, 55315, 18760, 66639, 16344, 66639, 63145, 66639, 65440],\n",
       " [44374, 45180, 39102, 44374, 26008, 37874],\n",
       " [34066, 18157, 26008, 20621, 43173, 46231],\n",
       " [4957,\n",
       "  47929,\n",
       "  10897,\n",
       "  14460,\n",
       "  4534,\n",
       "  19438,\n",
       "  60641,\n",
       "  31077,\n",
       "  40529,\n",
       "  60886,\n",
       "  8621,\n",
       "  50157,\n",
       "  46603,\n",
       "  53524],\n",
       " [11399, 55678, 16718, 54451, 16952, 34935, 62945, 44478, 52831],\n",
       " [5734, 20694, 19799, 16889, 45863, 11436, 19799],\n",
       " [46348, 46348, 30681, 27684, 31222, 17202, 29270],\n",
       " [53381, 2865, 42750, 48492, 61668, 56215, 16528, 36018, 27553],\n",
       " [20356, 62443, 52801, 26517, 13885, 49138, 60570, 60755, 30166],\n",
       " [64334, 30723, 18124, 53105, 30723, 30723],\n",
       " [24264, 5389, 11436, 47454, 22576, 29502],\n",
       " [65170, 65414, 52411, 6731, 45579, 33478, 55639, 11270],\n",
       " [20959,\n",
       "  55601,\n",
       "  62756,\n",
       "  4954,\n",
       "  28837,\n",
       "  50720,\n",
       "  52795,\n",
       "  53603,\n",
       "  30723,\n",
       "  53603,\n",
       "  6731,\n",
       "  20851],\n",
       " [3316, 55531, 12633, 6535, 65414, 52411, 56215, 21839, 53899, 41606],\n",
       " [54451, 4410, 48390, 2851, 60135],\n",
       " [11450, 4731, 11450, 13444, 14592, 15631],\n",
       " [22272, 29502, 11168, 53381, 8535, 16765, 26008, 67979],\n",
       " [11856, 42262, 50992, 33188, 7592, 3305],\n",
       " [66639, 26008, 1945, 42905, 9642, 49030],\n",
       " [10159,\n",
       "  14780,\n",
       "  19580,\n",
       "  62667,\n",
       "  58864,\n",
       "  35200,\n",
       "  43956,\n",
       "  35827,\n",
       "  65414,\n",
       "  52411,\n",
       "  64642,\n",
       "  57751,\n",
       "  58864],\n",
       " [47401, 44637, 17074, 40969, 20769, 41211, 5003, 58539, 58869],\n",
       " [64334, 32904, 52426, 45579, 45787, 28555],\n",
       " [15437,\n",
       "  13493,\n",
       "  42387,\n",
       "  15467,\n",
       "  7409,\n",
       "  27818,\n",
       "  42402,\n",
       "  48492,\n",
       "  13356,\n",
       "  28954,\n",
       "  51849,\n",
       "  43643,\n",
       "  13049,\n",
       "  64418],\n",
       " [66090, 39922, 65414, 52411, 14164, 62344, 26008],\n",
       " [3490, 5692, 18793, 45579, 56215, 48492],\n",
       " [39662, 43853, 42750, 40531, 56215, 44013, 8730],\n",
       " [65475, 23786, 51821, 410, 1446, 58020, 25560, 20525],\n",
       " [32904, 26252, 51444],\n",
       " [52426, 24264, 20224, 53381, 65725, 51444, 38629, 15631],\n",
       " [4806, 27896, 1, 42810, 4708, 47996],\n",
       " [52831, 6089, 4954, 18427, 31867, 52426],\n",
       " [25270, 20356, 32093, 62344, 26008],\n",
       " [61898,\n",
       "  45395,\n",
       "  53712,\n",
       "  19695,\n",
       "  52843,\n",
       "  23368,\n",
       "  49777,\n",
       "  48492,\n",
       "  44374,\n",
       "  5389,\n",
       "  54451,\n",
       "  50015],\n",
       " [12992, 12992, 54439, 39662, 64050, 42392, 48244],\n",
       " [53381, 30692, 68477, 35910, 36288, 62788, 17923, 60758],\n",
       " [63223, 62788, 68699, 10159, 15467, 28267],\n",
       " [20356,\n",
       "  62443,\n",
       "  2816,\n",
       "  30723,\n",
       "  4198,\n",
       "  44729,\n",
       "  16344,\n",
       "  17922,\n",
       "  63145,\n",
       "  56215,\n",
       "  29371,\n",
       "  62676,\n",
       "  58260],\n",
       " [36262, 39295, 43587, 49202, 36839, 63093, 37280, 45800, 12240, 57543, 66427],\n",
       " [56420, 64023, 65289, 860, 42451, 57569, 59226, 17922],\n",
       " [7141,\n",
       "  44781,\n",
       "  19208,\n",
       "  681,\n",
       "  5538,\n",
       "  25365,\n",
       "  45486,\n",
       "  39210,\n",
       "  32332,\n",
       "  34225,\n",
       "  19884,\n",
       "  38432,\n",
       "  11639,\n",
       "  39811],\n",
       " [25946, 46311, 3871, 293, 13594, 64097, 58260],\n",
       " [65414, 52411, 17822, 4889, 49852, 41468],\n",
       " [51462, 37874, 20784, 41606, 51821, 44277, 52946, 6731, 50720, 37874, 63368],\n",
       " [58478, 41606, 20356, 52045, 20851, 22979, 26008],\n",
       " [65414, 52411, 52534, 37420, 30079, 13006],\n",
       " [13764, 14837, 43155, 12912, 49141, 36259, 55523, 34300, 6367],\n",
       " [44374, 26008, 59588, 41606, 64135, 49214],\n",
       " [62854, 17815, 40336, 19274, 20787, 9324, 26226, 47466, 16411],\n",
       " [6731, 52426, 6731, 51973, 51973, 51973],\n",
       " [9388,\n",
       "  26951,\n",
       "  13896,\n",
       "  11579,\n",
       "  57409,\n",
       "  40053,\n",
       "  7005,\n",
       "  32283,\n",
       "  25772,\n",
       "  9388,\n",
       "  17244,\n",
       "  63194],\n",
       " [37289,\n",
       "  7809,\n",
       "  54171,\n",
       "  60068,\n",
       "  19527,\n",
       "  60068,\n",
       "  33558,\n",
       "  67384,\n",
       "  67570,\n",
       "  15233,\n",
       "  15233,\n",
       "  57738,\n",
       "  20093,\n",
       "  13154,\n",
       "  45343,\n",
       "  2949,\n",
       "  53386,\n",
       "  54507,\n",
       "  49863,\n",
       "  13916,\n",
       "  4673,\n",
       "  6731,\n",
       "  42822,\n",
       "  15467,\n",
       "  29502,\n",
       "  20784,\n",
       "  58636],\n",
       " [41211,\n",
       "  64985,\n",
       "  62344,\n",
       "  26008,\n",
       "  41211,\n",
       "  11830,\n",
       "  13006,\n",
       "  20835,\n",
       "  24782,\n",
       "  62851,\n",
       "  30723,\n",
       "  57293,\n",
       "  20525,\n",
       "  13006,\n",
       "  12294,\n",
       "  45835,\n",
       "  41342,\n",
       "  21727],\n",
       " [52525, 53381, 57798, 7947, 49819, 26008, 25399],\n",
       " [509, 44478, 509, 62443, 62344, 26008],\n",
       " [54127, 52411, 15956, 48925, 975],\n",
       " [49858,\n",
       "  41687,\n",
       "  33162,\n",
       "  66468,\n",
       "  5194,\n",
       "  43534,\n",
       "  29796,\n",
       "  44920,\n",
       "  17890,\n",
       "  65790,\n",
       "  58077,\n",
       "  66468,\n",
       "  55871,\n",
       "  25442,\n",
       "  43534,\n",
       "  62705,\n",
       "  30803,\n",
       "  41653,\n",
       "  44920,\n",
       "  51849,\n",
       "  51444,\n",
       "  3930],\n",
       " [63704, 2865, 27095, 51849, 5389],\n",
       " [65149, 43857, 52071, 38432, 26226, 11434, 10163, 58762, 27871],\n",
       " [41211, 42750, 15956, 46168, 60570, 65414, 42628, 51444, 15956, 46168],\n",
       " [34829, 55841, 28041, 50029, 59226, 53712, 13885, 41468, 20356, 46168],\n",
       " [6731,\n",
       "  14290,\n",
       "  63290,\n",
       "  10546,\n",
       "  38342,\n",
       "  14103,\n",
       "  10159,\n",
       "  41211,\n",
       "  8212,\n",
       "  5072,\n",
       "  62372,\n",
       "  59868,\n",
       "  19230],\n",
       " [55749, 16388, 35437, 53381, 2279, 26008, 457],\n",
       " [29480, 11474, 3696, 41606, 40996, 14434, 7471],\n",
       " [45579, 25508, 11739, 34829, 59256, 20925, 11436, 1496, 61384],\n",
       " [42750, 42750, 55749, 54451, 12844, 2821, 34310, 470],\n",
       " [41101, 28405, 39102, 13356, 59586, 58906, 42754, 64018],\n",
       " [24971, 62387, 64879, 7809, 43895, 49274, 45420, 6581, 12445, 16659, 2335],\n",
       " [65414, 52411, 31145, 975, 51444],\n",
       " [19396,\n",
       "  49043,\n",
       "  51584,\n",
       "  41304,\n",
       "  19396,\n",
       "  32278,\n",
       "  41304,\n",
       "  47441,\n",
       "  9842,\n",
       "  21809,\n",
       "  31695,\n",
       "  28113,\n",
       "  24433,\n",
       "  4057,\n",
       "  58634,\n",
       "  11597],\n",
       " [10131, 22429, 62986, 26008, 19563],\n",
       " [12289, 12912, 66055, 55367, 8862, 31000, 58869],\n",
       " [41211, 45048, 17622, 40563, 948, 51722, 24334, 31478, 18684],\n",
       " [52525, 26008, 1361, 16258],\n",
       " [10143, 20446, 58190, 46561, 26008, 58029],\n",
       " [11093, 25508, 6731, 975],\n",
       " [42102, 42810, 54854, 52071, 26226, 13693, 31943],\n",
       " [6613, 30723, 62015, 5609, 7137, 66193, 24563, 51666],\n",
       " [8574, 30692, 54963, 64397, 5389, 23892, 24264, 68524],\n",
       " [13356,\n",
       "  40984,\n",
       "  43895,\n",
       "  8806,\n",
       "  60401,\n",
       "  43485,\n",
       "  29750,\n",
       "  10856,\n",
       "  52552,\n",
       "  58036,\n",
       "  47674,\n",
       "  20056,\n",
       "  20669,\n",
       "  28173],\n",
       " [15196, 64334, 24264, 5389],\n",
       " [27754, 27754, 27754, 27754, 32685, 32685, 30157, 32685],\n",
       " [53381, 3407, 52426, 25870, 6526],\n",
       " [18778, 51444, 37288, 4250, 49214, 54291, 14581, 34875, 48492],\n",
       " [63003,\n",
       "  30723,\n",
       "  65170,\n",
       "  65170,\n",
       "  30079,\n",
       "  64112,\n",
       "  54062,\n",
       "  9584,\n",
       "  48506,\n",
       "  26467,\n",
       "  21549,\n",
       "  12586,\n",
       "  22277],\n",
       " [33478, 53381, 630, 24939, 37383],\n",
       " [65414, 56480, 10946, 14776, 18697, 29949],\n",
       " [11739, 6731, 62443, 18874, 45530, 69447, 69447, 26008, 62334, 32681],\n",
       " [8732, 23894, 9811, 23801, 6731, 23894],\n",
       " [30462,\n",
       "  60038,\n",
       "  62024,\n",
       "  41606,\n",
       "  41653,\n",
       "  58687,\n",
       "  29439,\n",
       "  50690,\n",
       "  40191,\n",
       "  38396,\n",
       "  60038,\n",
       "  66468,\n",
       "  41606,\n",
       "  41653,\n",
       "  2306,\n",
       "  56241,\n",
       "  52556,\n",
       "  37089,\n",
       "  16086],\n",
       " [19064, 51992, 30723, 48492, 42884, 46901, 34935, 65475, 7199],\n",
       " [54198, 45579, 56215, 48492, 34963, 44937, 13199, 49738, 56215, 48492],\n",
       " [15956, 42750, 15956, 62443, 26008, 51293, 63485],\n",
       " [19310, 47917, 67480, 54854, 5538],\n",
       " [68852,\n",
       "  30419,\n",
       "  63302,\n",
       "  9132,\n",
       "  17917,\n",
       "  2724,\n",
       "  39449,\n",
       "  22088,\n",
       "  59001,\n",
       "  509,\n",
       "  39102,\n",
       "  66359,\n",
       "  67979],\n",
       " [37269,\n",
       "  42750,\n",
       "  40531,\n",
       "  53642,\n",
       "  53712,\n",
       "  975,\n",
       "  56821,\n",
       "  61429,\n",
       "  64891,\n",
       "  975,\n",
       "  65926,\n",
       "  53280],\n",
       " [65982, 49550, 59366, 62443, 26008],\n",
       " [2701, 9324, 36984, 5538, 24999],\n",
       " [29712, 24878, 3316, 21410, 42451, 39358, 57746],\n",
       " [41092, 18157, 26008, 46231, 64851],\n",
       " [24411, 24411, 24411, 24411, 24411, 65414, 52411, 53381],\n",
       " [12478, 8662, 35376, 50324, 23455, 59051, 51639, 51055, 19730, 18923, 24206],\n",
       " [43375, 2296, 52512, 975],\n",
       " [2191,\n",
       "  50785,\n",
       "  20787,\n",
       "  26226,\n",
       "  17119,\n",
       "  12240,\n",
       "  11939,\n",
       "  44703,\n",
       "  44703,\n",
       "  52782,\n",
       "  5538,\n",
       "  38967,\n",
       "  9784,\n",
       "  28908],\n",
       " [52524, 17883, 29502, 2912, 27081, 24384, 34935, 30706, 68706],\n",
       " [41187, 7410, 58233, 46588, 41187, 31215, 41187, 49515, 15422, 67622, 49429],\n",
       " [27060, 25442, 43575, 61765, 56843, 10897, 43853, 40222, 6558, 31943],\n",
       " [975, 44383, 57486, 35837, 27691, 53712, 27453, 64938],\n",
       " [15956, 53712, 18157, 45048, 28170, 64334, 54941, 42750, 5389, 16952],\n",
       " [24264, 45579, 15956, 46168, 25508],\n",
       " [24264, 5389, 41606, 42754, 53381, 45579, 11586, 48492],\n",
       " [44374, 28488, 27691, 26008, 65458, 49390, 24446, 65170, 45579],\n",
       " [29949,\n",
       "  13006,\n",
       "  4954,\n",
       "  25892,\n",
       "  12004,\n",
       "  14788,\n",
       "  11555,\n",
       "  53712,\n",
       "  9780,\n",
       "  63416,\n",
       "  54062,\n",
       "  8667,\n",
       "  18199,\n",
       "  13006,\n",
       "  26008,\n",
       "  20784],\n",
       " [11739, 65440, 69436, 6089, 34546, 43835, 53458],\n",
       " [66131,\n",
       "  61898,\n",
       "  39102,\n",
       "  53381,\n",
       "  45579,\n",
       "  48492,\n",
       "  60368,\n",
       "  41606,\n",
       "  45579,\n",
       "  17622,\n",
       "  56692,\n",
       "  52478,\n",
       "  4954,\n",
       "  28145,\n",
       "  52591,\n",
       "  45048,\n",
       "  35200,\n",
       "  60368,\n",
       "  35186,\n",
       "  62344],\n",
       " [44096, 1496, 54769, 25270, 39102],\n",
       " [37907, 4954, 25532, 64334, 16556, 56867, 21045, 45579, 32904],\n",
       " [24649, 32611, 56632, 7434],\n",
       " [48655, 53381, 42798, 23467, 14442, 17246],\n",
       " [59528, 41606, 57274, 65414, 39359, 42747],\n",
       " [46452, 56215, 30564, 16952, 45381, 10717, 57058],\n",
       " [52071,\n",
       "  26226,\n",
       "  22107,\n",
       "  30690,\n",
       "  56940,\n",
       "  1352,\n",
       "  57188,\n",
       "  23123,\n",
       "  12228,\n",
       "  17815,\n",
       "  30473,\n",
       "  45731,\n",
       "  28278,\n",
       "  28477,\n",
       "  39047,\n",
       "  13908,\n",
       "  38432,\n",
       "  21905,\n",
       "  19000,\n",
       "  32408,\n",
       "  47687,\n",
       "  60680,\n",
       "  40007,\n",
       "  9518],\n",
       " [28405, 62443, 26008, 6731, 62443, 16258],\n",
       " [24264, 20224, 31145, 8574, 33873, 4954, 32040, 58116, 35114],\n",
       " [23848, 65414, 22202, 13466, 57793, 58639],\n",
       " [65475, 36658, 23597, 14531, 7531, 58382, 6420],\n",
       " [19593, 41642, 62200, 2607, 41653, 12323, 26008, 21347, 60166],\n",
       " [5991, 28555, 61936, 13738, 58914, 4954, 6363, 58382, 45579],\n",
       " [56632, 17618, 50704, 66104, 5350, 45863, 4049, 28572, 4954, 7137, 56700],\n",
       " [29062,\n",
       "  3440,\n",
       "  53381,\n",
       "  38137,\n",
       "  46168,\n",
       "  45492,\n",
       "  45371,\n",
       "  33478,\n",
       "  50255,\n",
       "  975,\n",
       "  17547,\n",
       "  46168],\n",
       " [20787,\n",
       "  26226,\n",
       "  60798,\n",
       "  8842,\n",
       "  68925,\n",
       "  66843,\n",
       "  20551,\n",
       "  48780,\n",
       "  66650,\n",
       "  58156,\n",
       "  64238,\n",
       "  26226,\n",
       "  30669,\n",
       "  45790,\n",
       "  54007,\n",
       "  52352,\n",
       "  17526,\n",
       "  66329,\n",
       "  31889,\n",
       "  21887,\n",
       "  9811,\n",
       "  68135,\n",
       "  1111,\n",
       "  8524,\n",
       "  8621],\n",
       " [20359, 68396, 17135, 49846, 29502, 18295, 53280, 27992],\n",
       " [57571, 5190, 35101, 23747, 8290, 28444, 53712, 50435, 4954, 24870, 30804],\n",
       " [37148, 51849, 5389, 2949, 10096, 4236, 54825, 5192],\n",
       " [820, 36178, 44308, 69033, 37457, 46168],\n",
       " [35376, 59993, 28315, 52051, 17922, 39677],\n",
       " [20942, 20694, 37872, 46073, 29789],\n",
       " [56746, 40531, 13006, 42750, 40531, 58935],\n",
       " [55270, 35966, 37324, 55824, 3930],\n",
       " [17815, 26445, 58232, 27260, 50751, 55749, 47917, 6616, 36984, 43321, 58634],\n",
       " [60634, 49782, 41211, 68201, 13444, 4222],\n",
       " [58478, 41606, 14442, 26008, 69654, 53712, 41606],\n",
       " [52801, 45381, 53381],\n",
       " [1361, 58656, 57274, 46168],\n",
       " [63145, 46246, 33311, 59364, 58597, 27942],\n",
       " [37903, 502, 26875, 60656, 40472, 34423, 13483],\n",
       " [6430, 23761, 54854, 26226, 9324, 36984, 31943],\n",
       " [46452, 14164, 42747, 66090, 53712],\n",
       " [60877, 67799, 42451, 62756, 41211, 63866],\n",
       " [48925, 58105, 65414, 29916, 18427, 42451, 63722, 35321, 39358, 65414, 29916],\n",
       " [63696,\n",
       "  60039,\n",
       "  4785,\n",
       "  49802,\n",
       "  40100,\n",
       "  33183,\n",
       "  62889,\n",
       "  26242,\n",
       "  45789,\n",
       "  45789,\n",
       "  13054,\n",
       "  30723],\n",
       " [3460, 24264, 24264, 24264, 24264, 59711, 22281, 24264, 5389, 31222],\n",
       " [8574, 2529, 60733, 45932],\n",
       " [39525, 4954, 38614, 53223, 34852, 35868],\n",
       " [33526, 9219, 41977, 3491, 49829],\n",
       " [65414, 52411, 52946, 41606, 37815, 36848, 44150, 12992, 51465],\n",
       " [11436, 4954, 35751, 34935, 58620, 20525, 42451, 26693, 8667, 61545, 36195],\n",
       " [48714, 35483, 43857, 7974, 17736, 362],\n",
       " [62648, 52411, 36343],\n",
       " [1699, 64676, 39549, 54854, 30854, 2701, 29078, 28459, 56871, 5538],\n",
       " [14467,\n",
       "  42102,\n",
       "  47917,\n",
       "  38561,\n",
       "  31803,\n",
       "  16854,\n",
       "  52071,\n",
       "  20582,\n",
       "  42102,\n",
       "  42810,\n",
       "  12798,\n",
       "  17754,\n",
       "  37829,\n",
       "  63223,\n",
       "  26226,\n",
       "  9324,\n",
       "  36984,\n",
       "  42102,\n",
       "  54854,\n",
       "  5538],\n",
       " [65170, 46168, 65170, 46168, 65170, 46168],\n",
       " [52465, 35136, 54854, 5538, 9324, 5527],\n",
       " [50348,\n",
       "  17876,\n",
       "  38873,\n",
       "  58634,\n",
       "  10903,\n",
       "  10903,\n",
       "  3191,\n",
       "  5350,\n",
       "  65414,\n",
       "  4250,\n",
       "  25094,\n",
       "  38629,\n",
       "  26008,\n",
       "  57706],\n",
       " [31435, 21379, 37387, 26008],\n",
       " [14003, 53938, 61063, 38868, 26226, 9324, 26865],\n",
       " [62009, 45420, 52969, 21842, 56596, 55574],\n",
       " [11739, 25270, 15956, 62443],\n",
       " [34792, 3006, 61898, 62443, 38012, 36077, 45696, 28870],\n",
       " [6731, 13006, 45579, 6731, 58382, 30069],\n",
       " [21611,\n",
       "  12506,\n",
       "  40385,\n",
       "  4624,\n",
       "  42754,\n",
       "  3561,\n",
       "  16765,\n",
       "  9566,\n",
       "  864,\n",
       "  12034,\n",
       "  28242,\n",
       "  49716,\n",
       "  37949,\n",
       "  24612,\n",
       "  34935,\n",
       "  8775,\n",
       "  52757,\n",
       "  55784,\n",
       "  17291,\n",
       "  9293,\n",
       "  6731,\n",
       "  4019,\n",
       "  15467,\n",
       "  40393,\n",
       "  17994,\n",
       "  7120,\n",
       "  34948,\n",
       "  864,\n",
       "  7809,\n",
       "  7809,\n",
       "  39693,\n",
       "  40393,\n",
       "  46586],\n",
       " [52946, 42124, 66639, 66639, 66639, 66639, 66639, 16744, 63145],\n",
       " [7130, 9180, 26098, 41695, 58218, 28387],\n",
       " [38302,\n",
       "  31412,\n",
       "  31424,\n",
       "  26226,\n",
       "  12483,\n",
       "  6421,\n",
       "  62304,\n",
       "  60541,\n",
       "  49934,\n",
       "  26438,\n",
       "  19884,\n",
       "  22833,\n",
       "  67448],\n",
       " [63043, 60628, 19396, 17011, 12414, 22390, 63943, 63430, 12414, 22390],\n",
       " [11193, 56215, 26424, 53381, 56215, 9516, 31275, 11436, 42754, 4975],\n",
       " [6200,\n",
       "  38137,\n",
       "  37960,\n",
       "  38137,\n",
       "  58708,\n",
       "  33123,\n",
       "  69551,\n",
       "  33974,\n",
       "  28709,\n",
       "  7103,\n",
       "  13356,\n",
       "  34959,\n",
       "  28695,\n",
       "  55639,\n",
       "  28695,\n",
       "  45555,\n",
       "  17656,\n",
       "  6200,\n",
       "  38137,\n",
       "  60796,\n",
       "  28695,\n",
       "  37148,\n",
       "  40395,\n",
       "  37148,\n",
       "  36367,\n",
       "  26008,\n",
       "  14164,\n",
       "  37275,\n",
       "  66700,\n",
       "  5777,\n",
       "  42887,\n",
       "  59920,\n",
       "  31927,\n",
       "  1101,\n",
       "  63929,\n",
       "  24296,\n",
       "  25651,\n",
       "  32896,\n",
       "  46475,\n",
       "  27898,\n",
       "  51560,\n",
       "  25651,\n",
       "  39255,\n",
       "  9519,\n",
       "  31836,\n",
       "  51277],\n",
       " [47929, 51319, 32098, 6290, 28429, 57681, 47740, 44574, 47740, 19386, 54444],\n",
       " [15990, 28795, 41211, 26935, 44374, 55783],\n",
       " [52256, 34809, 28685, 54854, 5538, 42425],\n",
       " [55749, 32421, 33084, 40544, 1676],\n",
       " [13493, 6200, 64505, 36848, 63145, 26772, 57746],\n",
       " [740,\n",
       "  46399,\n",
       "  19227,\n",
       "  27362,\n",
       "  65808,\n",
       "  3411,\n",
       "  1901,\n",
       "  38452,\n",
       "  39312,\n",
       "  4954,\n",
       "  27868,\n",
       "  65513,\n",
       "  13167,\n",
       "  66855,\n",
       "  22500],\n",
       " [10159, 41211, 65414, 4954, 1490, 20356, 45381],\n",
       " [18369, 28070, 19008, 28685, 54854, 26226, 13693, 5538],\n",
       " [64682,\n",
       "  59920,\n",
       "  62756,\n",
       "  61898,\n",
       "  1919,\n",
       "  65414,\n",
       "  26966,\n",
       "  18791,\n",
       "  41211,\n",
       "  55551,\n",
       "  53742,\n",
       "  15467,\n",
       "  18832,\n",
       "  30723,\n",
       "  16325,\n",
       "  60074,\n",
       "  20344,\n",
       "  30723,\n",
       "  35101,\n",
       "  23206,\n",
       "  22830],\n",
       " [65657, 14442, 26008, 8574, 53381],\n",
       " [11739, 59256, 37420, 30079, 53712, 41211, 62788, 51068, 62344, 68812],\n",
       " [39662, 35507, 55898, 68052, 30001],\n",
       " [39662,\n",
       "  4747,\n",
       "  43855,\n",
       "  22058,\n",
       "  42451,\n",
       "  13589,\n",
       "  4954,\n",
       "  58931,\n",
       "  21294,\n",
       "  26943,\n",
       "  772,\n",
       "  67623,\n",
       "  4747,\n",
       "  6949,\n",
       "  16296,\n",
       "  13589,\n",
       "  4954,\n",
       "  54481,\n",
       "  25515,\n",
       "  33687,\n",
       "  42690,\n",
       "  42750],\n",
       " [6731, 52426, 6731, 3945, 54062, 6731, 6200, 38137, 38997, 6200, 19500, 6731],\n",
       " [40919, 15398, 8394, 4889, 56058, 6731, 53593],\n",
       " [65026, 15437, 62648, 52411, 10128, 3148, 11313],\n",
       " [17543, 25802, 63982, 27632, 20769, 58639],\n",
       " [19064, 15398, 40079, 7120, 66868, 40079, 20907, 32904, 57500],\n",
       " [53381,\n",
       "  19878,\n",
       "  28158,\n",
       "  39497,\n",
       "  18462,\n",
       "  31706,\n",
       "  67860,\n",
       "  10159,\n",
       "  54439,\n",
       "  34936,\n",
       "  45026,\n",
       "  28041,\n",
       "  38677,\n",
       "  58176],\n",
       " [65657, 56527, 1333, 59567],\n",
       " [42451, 15467, 15316, 12222, 29706, 788, 52843, 3184, 19389, 21770, 21430],\n",
       " [36798, 48242, 50210, 30723, 51971, 26252, 38629, 26252],\n",
       " [56320, 13532, 65093, 20787, 26008, 33762],\n",
       " [35675, 56215, 28068, 45579, 24421, 4954, 56842],\n",
       " [41211, 24612, 34935, 40393, 39587, 26008, 67979],\n",
       " [10159,\n",
       "  7785,\n",
       "  58812,\n",
       "  5350,\n",
       "  14245,\n",
       "  30723,\n",
       "  52319,\n",
       "  56215,\n",
       "  35779,\n",
       "  6381,\n",
       "  56215,\n",
       "  20529,\n",
       "  48767,\n",
       "  35200,\n",
       "  51992,\n",
       "  18726,\n",
       "  43152,\n",
       "  5350,\n",
       "  41890,\n",
       "  38970,\n",
       "  14922,\n",
       "  23020,\n",
       "  48033,\n",
       "  26564,\n",
       "  66055,\n",
       "  6381,\n",
       "  68135,\n",
       "  19064,\n",
       "  22195,\n",
       "  6200,\n",
       "  42451,\n",
       "  41606,\n",
       "  9566,\n",
       "  14213,\n",
       "  2907,\n",
       "  2907,\n",
       "  6381,\n",
       "  33974,\n",
       "  44717,\n",
       "  11625,\n",
       "  31435,\n",
       "  28595,\n",
       "  20136,\n",
       "  27086,\n",
       "  41890,\n",
       "  44420,\n",
       "  40919,\n",
       "  30723,\n",
       "  45628,\n",
       "  24351],\n",
       " [61898, 61429, 46168, 52426, 57269, 52411],\n",
       " [69551, 44450, 34131, 68477, 44495, 57932, 66019],\n",
       " [20018, 2859, 56147, 11618, 4250, 49214],\n",
       " [16744, 54586, 54586, 54062, 54586, 54062, 37305],\n",
       " [65149, 48699, 18369, 14141, 46553, 17601, 5538, 37773, 25041],\n",
       " [42659,\n",
       "  32278,\n",
       "  50018,\n",
       "  25764,\n",
       "  38389,\n",
       "  66985,\n",
       "  53163,\n",
       "  58247,\n",
       "  22053,\n",
       "  4057,\n",
       "  26226,\n",
       "  9324,\n",
       "  36984,\n",
       "  5538],\n",
       " [25436, 30773, 18802, 30411, 30625, 58166, 10142],\n",
       " [53047,\n",
       "  26008,\n",
       "  43925,\n",
       "  65414,\n",
       "  41606,\n",
       "  26339,\n",
       "  38342,\n",
       "  41606,\n",
       "  26339,\n",
       "  42570,\n",
       "  67149,\n",
       "  26008],\n",
       " [39128,\n",
       "  64676,\n",
       "  3712,\n",
       "  54854,\n",
       "  52071,\n",
       "  9352,\n",
       "  67518,\n",
       "  39602,\n",
       "  25436,\n",
       "  41457,\n",
       "  3712,\n",
       "  52071,\n",
       "  3712,\n",
       "  10428,\n",
       "  64676,\n",
       "  3712,\n",
       "  45486,\n",
       "  3712,\n",
       "  63943,\n",
       "  39210,\n",
       "  36266,\n",
       "  5464,\n",
       "  44331],\n",
       " [6731, 67076, 45579, 66316, 51444, 26464],\n",
       " [66787, 37305, 61961, 21892, 24635, 28405, 61384, 39635],\n",
       " [62756,\n",
       "  18971,\n",
       "  32452,\n",
       "  9867,\n",
       "  2981,\n",
       "  33638,\n",
       "  9451,\n",
       "  33638,\n",
       "  62756,\n",
       "  55959,\n",
       "  39577,\n",
       "  13006,\n",
       "  33638],\n",
       " [17287, 3611, 39102, 26008, 62344],\n",
       " [25436, 7664, 22727, 20791, 34570, 52246, 13687],\n",
       " [10897, 52216, 8092, 11639, 52071, 26226, 28676, 10897, 9436, 23830],\n",
       " [10386, 5389, 20356, 46168, 41606, 16952, 9243, 66359],\n",
       " [51958, 44374, 65671, 15956, 232],\n",
       " [48206, 5182, 20595, 41211, 63194, 32860],\n",
       " [68625, 68030, 26008, 5786, 654, 20621],\n",
       " [62035,\n",
       "  15503,\n",
       "  63814,\n",
       "  50881,\n",
       "  6997,\n",
       "  10316,\n",
       "  48881,\n",
       "  20670,\n",
       "  2616,\n",
       "  63824,\n",
       "  6884,\n",
       "  22216,\n",
       "  62402,\n",
       "  42386,\n",
       "  16775,\n",
       "  30826,\n",
       "  41873,\n",
       "  27739,\n",
       "  27069,\n",
       "  66650,\n",
       "  15781,\n",
       "  7014,\n",
       "  32248,\n",
       "  1650,\n",
       "  21788,\n",
       "  23938,\n",
       "  65588,\n",
       "  13302,\n",
       "  16501,\n",
       "  42810,\n",
       "  12496,\n",
       "  54007,\n",
       "  7189,\n",
       "  51257,\n",
       "  16435,\n",
       "  16501,\n",
       "  28868,\n",
       "  23801,\n",
       "  59179,\n",
       "  26670,\n",
       "  21788,\n",
       "  18482,\n",
       "  67152,\n",
       "  49740,\n",
       "  17707,\n",
       "  49425,\n",
       "  35689,\n",
       "  33059,\n",
       "  15636,\n",
       "  47140,\n",
       "  49343,\n",
       "  26030,\n",
       "  23761,\n",
       "  5359,\n",
       "  37462,\n",
       "  17852,\n",
       "  10856,\n",
       "  38746,\n",
       "  51621],\n",
       " [32904, 34694, 65170, 45579],\n",
       " [9440, 2371, 38342, 58597, 28532],\n",
       " [14776, 18697, 18295, 62443, 62344, 26008],\n",
       " [19064,\n",
       "  68981,\n",
       "  49877,\n",
       "  11691,\n",
       "  51821,\n",
       "  53381,\n",
       "  42754,\n",
       "  1063,\n",
       "  25914,\n",
       "  58864,\n",
       "  57580,\n",
       "  48206,\n",
       "  68981,\n",
       "  58652,\n",
       "  53425,\n",
       "  28322],\n",
       " [35102, 65414, 52411, 60570, 17403, 22183],\n",
       " [9516,\n",
       "  4954,\n",
       "  62249,\n",
       "  4954,\n",
       "  54399,\n",
       "  13006,\n",
       "  51351,\n",
       "  49742,\n",
       "  53381,\n",
       "  53735,\n",
       "  58382,\n",
       "  13154],\n",
       " [4019,\n",
       "  53381,\n",
       "  42754,\n",
       "  12222,\n",
       "  39764,\n",
       "  54056,\n",
       "  33478,\n",
       "  67775,\n",
       "  53381,\n",
       "  55410,\n",
       "  65440,\n",
       "  27447,\n",
       "  55639,\n",
       "  58176,\n",
       "  26325,\n",
       "  62443,\n",
       "  65940],\n",
       " [44374, 11586, 39102, 17547, 10710],\n",
       " [16478, 28145, 30564, 15292, 49863, 65170, 37345, 27691, 49863],\n",
       " [29712, 41501, 49522, 35756, 19247, 36698],\n",
       " [39959, 66340, 15654, 20662, 11121, 30723, 62160, 18254, 53488, 20369],\n",
       " [28405, 6461, 56215, 31435, 10143, 6672, 10143, 14434, 49975],\n",
       " [59113, 26008, 16023, 50992, 27051, 45863, 58451, 31451, 32833, 54941],\n",
       " [6731,\n",
       "  65170,\n",
       "  58273,\n",
       "  28170,\n",
       "  45579,\n",
       "  13356,\n",
       "  1721,\n",
       "  69153,\n",
       "  19586,\n",
       "  2865,\n",
       "  28916,\n",
       "  56215,\n",
       "  28170,\n",
       "  26008,\n",
       "  35770,\n",
       "  6731],\n",
       " [67813, 47305, 15196, 15956, 64334],\n",
       " [26008, 46285, 63989, 18157, 26008, 59442],\n",
       " [63594, 68517, 65414, 52411, 35222],\n",
       " [6731, 42750, 26008, 29619, 24393, 20131],\n",
       " [26403, 1350, 6448, 10186, 48780, 44842, 7141, 24664, 30758],\n",
       " [24681,\n",
       "  63678,\n",
       "  3976,\n",
       "  14058,\n",
       "  24065,\n",
       "  14003,\n",
       "  4444,\n",
       "  11769,\n",
       "  42193,\n",
       "  47359,\n",
       "  11639,\n",
       "  2591,\n",
       "  37928,\n",
       "  66329,\n",
       "  43127,\n",
       "  39210,\n",
       "  50770,\n",
       "  58634,\n",
       "  29921],\n",
       " [26775, 63145, 21901, 13775, 33974, 4954, 27553],\n",
       " [52801, 4889, 15124, 15956, 14442, 26008, 12289, 55749],\n",
       " [35486, 3940, 24903, 51024, 38845],\n",
       " [40449,\n",
       "  9970,\n",
       "  18797,\n",
       "  58281,\n",
       "  39312,\n",
       "  4954,\n",
       "  11093,\n",
       "  47434,\n",
       "  7947,\n",
       "  62372,\n",
       "  44310,\n",
       "  1090,\n",
       "  24264,\n",
       "  20224,\n",
       "  49681,\n",
       "  65513,\n",
       "  44051,\n",
       "  46168],\n",
       " [12309, 17310, 46453, 13153, 51675, 58639],\n",
       " [30701, 9667, 62525, 44517, 31211],\n",
       " [36117, 30723, 53381, 42754, 6514, 36288, 42754, 45148, 54066],\n",
       " [10571, 44374, 975, 24264, 45579, 53381],\n",
       " [63308, 26008, 15188, 39190, 13395, 10274, 67049, 19395, 30723],\n",
       " [18729, 50329, 49621, 15956, 46168, 58869, 6731, 62443],\n",
       " [19974, 43853, 58310, 28595, 53047, 8290],\n",
       " [44374, 31068, 55639, 61673, 18569, 30723, 42750],\n",
       " [33543,\n",
       "  69420,\n",
       "  4954,\n",
       "  21045,\n",
       "  27499,\n",
       "  32871,\n",
       "  12649,\n",
       "  16401,\n",
       "  47025,\n",
       "  49863,\n",
       "  19053,\n",
       "  52984,\n",
       "  47922,\n",
       "  41412,\n",
       "  38695,\n",
       "  38136],\n",
       " [14651,\n",
       "  30258,\n",
       "  14651,\n",
       "  22848,\n",
       "  14651,\n",
       "  50838,\n",
       "  65414,\n",
       "  52411,\n",
       "  4954,\n",
       "  42451,\n",
       "  19064,\n",
       "  43236,\n",
       "  28555],\n",
       " [46452,\n",
       "  56215,\n",
       "  33451,\n",
       "  36669,\n",
       "  740,\n",
       "  52426,\n",
       "  60324,\n",
       "  67076,\n",
       "  29712,\n",
       "  51068,\n",
       "  19389,\n",
       "  3891,\n",
       "  56215,\n",
       "  57424,\n",
       "  54031,\n",
       "  65370],\n",
       " [975, 31118, 6674, 62443, 42750],\n",
       " [48925, 68217, 2879, 19463, 13531],\n",
       " [21409, 39549, 54854, 26226, 9324, 36984, 5538],\n",
       " [48490, 66926, 65458, 43226, 26008, 25893, 58457, 49112, 4994],\n",
       " [42451, 47674, 40191, 30662, 45020, 53381, 45579, 36732, 12289, 23980, 49782],\n",
       " [59184, 29409, 1177, 54854, 26226, 2701, 13693, 5538],\n",
       " [36117,\n",
       "  28405,\n",
       "  39102,\n",
       "  56215,\n",
       "  68201,\n",
       "  10159,\n",
       "  53381,\n",
       "  42754,\n",
       "  39569,\n",
       "  8360,\n",
       "  38136,\n",
       "  53381,\n",
       "  56215,\n",
       "  10159,\n",
       "  24411,\n",
       "  12529,\n",
       "  41211,\n",
       "  1369],\n",
       " [6089, 49846, 65414, 52411],\n",
       " [52071, 20582, 61020, 13896, 30338, 17244, 40756],\n",
       " [26226,\n",
       "  19495,\n",
       "  67889,\n",
       "  60798,\n",
       "  52071,\n",
       "  6331,\n",
       "  31225,\n",
       "  67889,\n",
       "  52196,\n",
       "  60753,\n",
       "  60200,\n",
       "  56810,\n",
       "  17122,\n",
       "  17922,\n",
       "  37829],\n",
       " [62992,\n",
       "  20335,\n",
       "  33921,\n",
       "  7531,\n",
       "  22273,\n",
       "  29229,\n",
       "  53381,\n",
       "  26471,\n",
       "  40023,\n",
       "  32904,\n",
       "  65414,\n",
       "  52411],\n",
       " [50606, 52976, 51171, 42754, 7634, 48426, 41211],\n",
       " [27945, 1333, 33941, 35615, 54405, 67746, 6257],\n",
       " [48699, 12864, 11538, 30424, 19212, 3287, 62821],\n",
       " [31113,\n",
       "  12483,\n",
       "  37204,\n",
       "  64122,\n",
       "  36275,\n",
       "  3569,\n",
       "  50728,\n",
       "  37193,\n",
       "  37204,\n",
       "  66650,\n",
       "  36275,\n",
       "  53799,\n",
       "  8621,\n",
       "  53872,\n",
       "  53799,\n",
       "  20988,\n",
       "  55270,\n",
       "  21901,\n",
       "  67142,\n",
       "  64097],\n",
       " [55639, 58176, 54936, 12289, 52831, 26966, 25387],\n",
       " [31733,\n",
       "  61480,\n",
       "  20227,\n",
       "  40111,\n",
       "  61686,\n",
       "  52684,\n",
       "  15569,\n",
       "  8087,\n",
       "  19884,\n",
       "  54856,\n",
       "  19212,\n",
       "  7141,\n",
       "  47119,\n",
       "  38363,\n",
       "  13764,\n",
       "  12228,\n",
       "  6796,\n",
       "  54517,\n",
       "  1348,\n",
       "  32501,\n",
       "  18498,\n",
       "  56603,\n",
       "  5538,\n",
       "  20034,\n",
       "  26226,\n",
       "  19884,\n",
       "  54856,\n",
       "  54405],\n",
       " [3318,\n",
       "  37989,\n",
       "  34948,\n",
       "  61686,\n",
       "  60265,\n",
       "  5532,\n",
       "  48079,\n",
       "  56007,\n",
       "  52493,\n",
       "  32120,\n",
       "  62372,\n",
       "  62372,\n",
       "  66285,\n",
       "  67951,\n",
       "  13039,\n",
       "  7140,\n",
       "  11963,\n",
       "  9327,\n",
       "  61471,\n",
       "  58906,\n",
       "  53878,\n",
       "  61686,\n",
       "  34203,\n",
       "  49241,\n",
       "  66699,\n",
       "  24876],\n",
       " [16893,\n",
       "  28278,\n",
       "  11785,\n",
       "  38205,\n",
       "  66717,\n",
       "  11369,\n",
       "  37829,\n",
       "  53811,\n",
       "  27749,\n",
       "  52071,\n",
       "  36760,\n",
       "  978,\n",
       "  46447,\n",
       "  67468,\n",
       "  46019,\n",
       "  9196,\n",
       "  11891,\n",
       "  52071,\n",
       "  37744,\n",
       "  26411,\n",
       "  2403,\n",
       "  12462,\n",
       "  5538,\n",
       "  18773,\n",
       "  52071,\n",
       "  20342,\n",
       "  13337],\n",
       " [44620, 49535, 28595, 48023, 2912, 55413],\n",
       " [34287, 9324, 36984, 5538, 32283, 66329, 49043, 34287],\n",
       " [6731, 13006, 6731, 27393, 65414, 52411, 37248],\n",
       " [4747, 58812, 45579, 22094, 55339, 13695, 53381, 39730],\n",
       " [41101, 14245, 60468, 44599],\n",
       " [61898,\n",
       "  25508,\n",
       "  2865,\n",
       "  19064,\n",
       "  48492,\n",
       "  15188,\n",
       "  42451,\n",
       "  25508,\n",
       "  29671,\n",
       "  13006,\n",
       "  31586,\n",
       "  46293,\n",
       "  56664,\n",
       "  56650,\n",
       "  46293,\n",
       "  27060,\n",
       "  41606,\n",
       "  29671,\n",
       "  19064,\n",
       "  17622,\n",
       "  68326,\n",
       "  5389],\n",
       " [26464, 32590, 42124, 18070, 25217, 12879, 759],\n",
       " [27890, 24095, 30723, 13775, 22120, 5350, 49830, 52227],\n",
       " [61898, 62443, 8667, 26339, 10159, 62756, 20316, 31621, 12600, 1370],\n",
       " [948, 6089, 25883, 9216, 50055, 55230],\n",
       " [67132, 4793, 34935, 41804, 55126, 37874, 57926, 14434, 38695],\n",
       " [13764, 14837, 12912, 27595, 62927, 54772, 6367],\n",
       " [11173, 27577, 53381, 55639, 25708, 25442, 48225],\n",
       " [50224,\n",
       "  49043,\n",
       "  45786,\n",
       "  65093,\n",
       "  57322,\n",
       "  59787,\n",
       "  29223,\n",
       "  66329,\n",
       "  10897,\n",
       "  4608,\n",
       "  11639,\n",
       "  19396,\n",
       "  10897,\n",
       "  65235,\n",
       "  59235,\n",
       "  23792,\n",
       "  57322,\n",
       "  32705,\n",
       "  68336,\n",
       "  54910,\n",
       "  36626],\n",
       " [36815, 45579, 36815, 58382, 9566, 51004, 37831, 1945, 12912, 53593, 23801],\n",
       " [11436, 1335, 46706, 13824, 134, 12529, 12705, 26153],\n",
       " [68852, 57117, 14795, 17917, 2724, 12283, 15412, 9419, 33489, 59776],\n",
       " [19310, 47917, 67480, 39549, 54854, 26226, 9324, 36984, 31943],\n",
       " [27185, 17395, 29671, 128, 35841, 42640],\n",
       " [19310, 47917, 67480, 46813, 54854, 26226, 9324, 36984, 5538],\n",
       " [24612, 56215, 38136, 34935, 21759, 36300],\n",
       " [31243, 54369, 38823, 5453, 19838, 66718],\n",
       " [65475, 27837, 11113, 44596],\n",
       " [20883, 26008, 15956, 32685, 3093],\n",
       " [42659, 10785, 20787, 65358, 8842, 39210, 51055, 3590, 16893, 64727],\n",
       " [51100, 1901, 57926, 51406, 42750, 59407, 65170],\n",
       " [26804, 13263, 51859, 55783, 27879, 34336, 58176],\n",
       " [40701, 12992, 55999, 22183, 66460, 44260, 42726, 33478, 33987, 13505],\n",
       " [28595, 1496, 27964, 36117, 23245, 11436, 47781, 19861],\n",
       " [4275, 66650, 25113, 55723, 38320, 19670],\n",
       " [13378, 43205, 34935, 48532, 7556, 26890, 7809, 42451],\n",
       " [59046, 67966, 2236, 68562, 54854, 5538],\n",
       " [2591, 57915, 51786, 58341, 54455, 31451, 7964, 6709],\n",
       " [33111, 29737, 45420, 53047, 212, 4485, 6731, 40563, 35152, 7192, 53381],\n",
       " [14843, 41606, 62344, 43424, 52415],\n",
       " [50643, 66639, 16258, 1945, 66639, 26008, 1945, 29444, 4681, 1945],\n",
       " [40037, 32904, 37907, 64334, 65384, 60656],\n",
       " [54500, 16501, 23595, 10897, 46130, 48731, 4957, 47929, 36251, 54500, 16501],\n",
       " [6363,\n",
       "  62443,\n",
       "  53223,\n",
       "  18421,\n",
       "  45579,\n",
       "  20925,\n",
       "  24809,\n",
       "  58478,\n",
       "  16258,\n",
       "  6363,\n",
       "  45579,\n",
       "  34798,\n",
       "  58478,\n",
       "  7125,\n",
       "  53381,\n",
       "  6363,\n",
       "  24421,\n",
       "  18778,\n",
       "  25990],\n",
       " [28402, 42750, 40531, 13379, 33007, 62443, 62344, 26008],\n",
       " [44374, 5389, 65414, 52411, 53381, 28066, 36343],\n",
       " [22967,\n",
       "  45579,\n",
       "  11978,\n",
       "  20356,\n",
       "  48925,\n",
       "  42451,\n",
       "  1660,\n",
       "  56600,\n",
       "  32904,\n",
       "  22967,\n",
       "  199,\n",
       "  16405,\n",
       "  62624,\n",
       "  41211,\n",
       "  61131,\n",
       "  62344,\n",
       "  22391],\n",
       " [53381, 4954, 24264, 55207, 11208, 66497, 64042, 20925, 28405, 39102],\n",
       " [6363, 54451, 50015, 54894, 46938],\n",
       " [44374,\n",
       "  5287,\n",
       "  17147,\n",
       "  15934,\n",
       "  42798,\n",
       "  41606,\n",
       "  26008,\n",
       "  36841,\n",
       "  41572,\n",
       "  62344,\n",
       "  26008,\n",
       "  58260,\n",
       "  3930],\n",
       " [66639, 63145, 34798, 60442, 26284],\n",
       " [5403,\n",
       "  56543,\n",
       "  35993,\n",
       "  11077,\n",
       "  38530,\n",
       "  1731,\n",
       "  14568,\n",
       "  68620,\n",
       "  28828,\n",
       "  8831,\n",
       "  22216,\n",
       "  50234,\n",
       "  22582],\n",
       " [5003,\n",
       "  34736,\n",
       "  11903,\n",
       "  35011,\n",
       "  6535,\n",
       "  17662,\n",
       "  12222,\n",
       "  4747,\n",
       "  58708,\n",
       "  53781,\n",
       "  69392,\n",
       "  49975,\n",
       "  56029],\n",
       " [28170, 30481, 68931, 1092, 63453, 36389, 8450, 41211],\n",
       " [10159, 41211, 16952, 13199, 34492, 66498, 50156, 29790, 48391],\n",
       " [65513, 10190, 19157, 62143, 63150, 63868, 47567, 53151, 16816],\n",
       " [66639,\n",
       "  65440,\n",
       "  27818,\n",
       "  36494,\n",
       "  5350,\n",
       "  23149,\n",
       "  14843,\n",
       "  53381,\n",
       "  20525,\n",
       "  25651,\n",
       "  23149,\n",
       "  59920,\n",
       "  30941,\n",
       "  10570,\n",
       "  25470,\n",
       "  61409,\n",
       "  68764],\n",
       " [46452, 14164, 42750, 31145],\n",
       " [66070, 2136, 43534, 26362, 3328, 16086],\n",
       " [62107,\n",
       "  17934,\n",
       "  64333,\n",
       "  41896,\n",
       "  38996,\n",
       "  37418,\n",
       "  39662,\n",
       "  37622,\n",
       "  56101,\n",
       "  31766,\n",
       "  13729,\n",
       "  41211,\n",
       "  69328,\n",
       "  42619,\n",
       "  36117,\n",
       "  58106,\n",
       "  41687,\n",
       "  50750],\n",
       " [53595, 68113, 54854, 26226, 9324, 36984, 5538],\n",
       " [24668, 28416, 65733, 15312],\n",
       " [16952,\n",
       "  55639,\n",
       "  11270,\n",
       "  43060,\n",
       "  1611,\n",
       "  34336,\n",
       "  43060,\n",
       "  15956,\n",
       "  65414,\n",
       "  52411,\n",
       "  45579,\n",
       "  24264,\n",
       "  5389],\n",
       " [5389, 4954, 54542, 11113, 19696, 30723, 41211, 1490],\n",
       " [20374,\n",
       "  48353,\n",
       "  16775,\n",
       "  58980,\n",
       "  34606,\n",
       "  67140,\n",
       "  14830,\n",
       "  12810,\n",
       "  52071,\n",
       "  38432,\n",
       "  4957,\n",
       "  216,\n",
       "  58551,\n",
       "  20787,\n",
       "  15000,\n",
       "  22813,\n",
       "  8621,\n",
       "  7141,\n",
       "  46421,\n",
       "  68798,\n",
       "  35376,\n",
       "  52071,\n",
       "  21030,\n",
       "  26226,\n",
       "  9324,\n",
       "  36984,\n",
       "  5538],\n",
       " [57734, 12060, 67807, 69081, 42311, 65538, 44089, 28405, 39102, 21414],\n",
       " [37420, 30079, 43548, 66534, 59588, 41211, 24903, 53059, 34829, 59256],\n",
       " [17245, 44059, 48472, 56521, 4954, 60696, 4001],\n",
       " [5527, 10125, 66029, 53522, 57531, 16107],\n",
       " [4944,\n",
       "  23004,\n",
       "  35200,\n",
       "  47914,\n",
       "  6694,\n",
       "  35200,\n",
       "  14922,\n",
       "  39238,\n",
       "  14245,\n",
       "  4944,\n",
       "  35200,\n",
       "  29379,\n",
       "  49975],\n",
       " [63573, 50015, 46168, 54062, 14843, 41606, 43345, 27440, 19064, 28555],\n",
       " [19379,\n",
       "  27019,\n",
       "  54854,\n",
       "  34287,\n",
       "  30854,\n",
       "  9324,\n",
       "  36984,\n",
       "  5538,\n",
       "  19514,\n",
       "  12948,\n",
       "  8831,\n",
       "  12462],\n",
       " [51908, 62443, 24342, 53712, 62443],\n",
       " [6363, 32926, 62443, 57176, 26008],\n",
       " [49863, 52525],\n",
       " [9688,\n",
       "  19064,\n",
       "  15956,\n",
       "  54062,\n",
       "  8699,\n",
       "  21927,\n",
       "  61889,\n",
       "  42754,\n",
       "  51821,\n",
       "  55789,\n",
       "  48492,\n",
       "  16952,\n",
       "  35809],\n",
       " [25436,\n",
       "  58113,\n",
       "  46593,\n",
       "  18773,\n",
       "  38823,\n",
       "  23952,\n",
       "  21226,\n",
       "  49343,\n",
       "  15098,\n",
       "  62826,\n",
       "  12945,\n",
       "  563,\n",
       "  58232,\n",
       "  38967,\n",
       "  52561,\n",
       "  22654,\n",
       "  42210,\n",
       "  8621,\n",
       "  1255,\n",
       "  53141,\n",
       "  52561,\n",
       "  16710,\n",
       "  52561],\n",
       " [49190, 26008, 48167, 48919, 41342, 45932],\n",
       " [16618, 48073, 52796, 57010, 56763, 52071, 16258, 65093, 40266, 40963],\n",
       " [948, 16258, 39116, 45401, 11586, 37584],\n",
       " [7323, 45282, 16952, 53381, 33718, 26008],\n",
       " [60263, 36358, 58382, 65412, 37674, 31118, 61898, 62629, 30662, 17684, 30662],\n",
       " [14843,\n",
       "  53381,\n",
       "  29671,\n",
       "  65475,\n",
       "  19107,\n",
       "  18232,\n",
       "  7809,\n",
       "  62443,\n",
       "  56215,\n",
       "  50255,\n",
       "  9601,\n",
       "  9688,\n",
       "  56580,\n",
       "  32840,\n",
       "  21231,\n",
       "  61,\n",
       "  26961],\n",
       " [61898, 61429, 62443, 62344, 26008],\n",
       " [20356,\n",
       "  46168,\n",
       "  60570,\n",
       "  62364,\n",
       "  51849,\n",
       "  36943,\n",
       "  16952,\n",
       "  24903,\n",
       "  24805,\n",
       "  26501,\n",
       "  64334,\n",
       "  45579],\n",
       " [57386, 48452, 16437, 45579, 53447],\n",
       " [37089, 36429, 41606, 16086, 50884, 33084, 41046, 16086],\n",
       " [62608, 52510, 26657, 48714, 6929, 50824, 26226, 24797, 54016],\n",
       " [9516, 66359, 46548],\n",
       " [53030, 5231, 85, 54854, 52071, 14809, 9324, 36984, 5538],\n",
       " [21045, 38072, 37710, 65414, 56480, 11436],\n",
       " [3350,\n",
       "  65420,\n",
       "  51665,\n",
       "  61020,\n",
       "  3181,\n",
       "  3102,\n",
       "  26747,\n",
       "  54854,\n",
       "  9324,\n",
       "  36984,\n",
       "  5538,\n",
       "  40690,\n",
       "  41222,\n",
       "  57511,\n",
       "  6282,\n",
       "  47421,\n",
       "  2432,\n",
       "  57511],\n",
       " [20920, 3640, 62372, 44258, 24264, 5389],\n",
       " [45057, 29681, 61450, 26884, 20866, 65198, 40046],\n",
       " [41457,\n",
       "  66639,\n",
       "  62992,\n",
       "  2240,\n",
       "  19495,\n",
       "  18432,\n",
       "  26657,\n",
       "  14033,\n",
       "  49604,\n",
       "  62413,\n",
       "  18136,\n",
       "  66008,\n",
       "  13226,\n",
       "  58785],\n",
       " [10746, 62443, 62344, 26008],\n",
       " [55674,\n",
       "  42451,\n",
       "  2302,\n",
       "  41211,\n",
       "  34936,\n",
       "  27393,\n",
       "  9688,\n",
       "  57754,\n",
       "  42754,\n",
       "  64228,\n",
       "  22749,\n",
       "  29372,\n",
       "  16592,\n",
       "  31793,\n",
       "  28595,\n",
       "  30564,\n",
       "  4954,\n",
       "  23888],\n",
       " [66639, 63145, 1723, 66639, 63145],\n",
       " [51444, 58260, 40192, 64863],\n",
       " [57500, 53381, 42750, 2296, 45180, 46168, 4772, 42750, 26576, 57500],\n",
       " [54062, 54062, 23511, 13689, 25508, 46168, 18190, 25547, 21770, 18521],\n",
       " [19008, 9115, 9783, 51411, 26226, 46576],\n",
       " [42750, 46168, 50750, 50750, 50750, 24292],\n",
       " [35435, 9970, 31276, 30723, 57500, 30723],\n",
       " [19650, 57855, 26612, 65577, 65009, 1796],\n",
       " [44374, 53120, 2136],\n",
       " [66639, 65475, 11121, 30723, 39662, 4019, 53381, 42754, 45863, 30723, 53387],\n",
       " [28320,\n",
       "  1178,\n",
       "  28381,\n",
       "  3148,\n",
       "  38137,\n",
       "  30706,\n",
       "  51775,\n",
       "  11574,\n",
       "  49511,\n",
       "  65475,\n",
       "  47565,\n",
       "  65733,\n",
       "  64097,\n",
       "  14959,\n",
       "  410,\n",
       "  27159,\n",
       "  15398,\n",
       "  58701,\n",
       "  66831,\n",
       "  27393,\n",
       "  19550,\n",
       "  17517,\n",
       "  44260,\n",
       "  53137],\n",
       " [4019, 41211, 11855, 30723, 35725, 10917, 30723],\n",
       " [42898, 23635, 41687, 3419, 42754, 24264, 5389],\n",
       " [28039,\n",
       "  34190,\n",
       "  60825,\n",
       "  13307,\n",
       "  35841,\n",
       "  28428,\n",
       "  13921,\n",
       "  14667,\n",
       "  47531,\n",
       "  60825,\n",
       "  13307,\n",
       "  57500,\n",
       "  9390,\n",
       "  29712],\n",
       " [44921, 29062, 28555, 53389, 51327],\n",
       " [65414, 52411, 3016, 17202],\n",
       " [42281, 32926, 18030, 45579, 51701, 44358, 31222, 4889, 26008],\n",
       " [59184, 29409, 5443, 52729, 5538],\n",
       " [65475, 588, 6445, 62443, 156, 59622, 3349, 64506, 1901, 51276],\n",
       " [20787, 5528, 20790, 61505, 30491, 10163, 9239, 9811, 9324, 41028],\n",
       " [14291, 24511, 23146, 27686, 50740, 49975, 53097, 11450, 49863],\n",
       " [65414, 52411, 30252, 26008, 5791],\n",
       " [44983,\n",
       "  42754,\n",
       "  4954,\n",
       "  33687,\n",
       "  4954,\n",
       "  17341,\n",
       "  8859,\n",
       "  19064,\n",
       "  502,\n",
       "  34935,\n",
       "  65178,\n",
       "  26008,\n",
       "  7842],\n",
       " [61811, 44098, 63280, 25817, 20851, 41606, 975, 43042],\n",
       " [30079, 46168, 44374, 975, 51444, 35770],\n",
       " [750, 38323, 68931, 5003, 10756, 1702],\n",
       " [66868, 6412, 15058, 4954, 410, 48167, 58382, 6437],\n",
       " [55574, 1155, 44807, 65942, 46168, 10303, 55406, 26708],\n",
       " [19947, 37592, 39102, 13006, 15956, 39102, 19947],\n",
       " [14843, 41606, 4954, 55406, 39190, 16409, 62344, 59594, 41606, 52426, 56621],\n",
       " [12831, 64407, 61898, 13006, 36010, 32590, 51992, 31222],\n",
       " [41677,\n",
       "  27019,\n",
       "  11431,\n",
       "  45525,\n",
       "  63435,\n",
       "  64676,\n",
       "  3479,\n",
       "  28685,\n",
       "  54854,\n",
       "  26226,\n",
       "  9324,\n",
       "  36984,\n",
       "  31943],\n",
       " [54194, 62443, 62344, 26008],\n",
       " [44374, 24638, 68852, 50210, 12992, 63929, 7444],\n",
       " [26226, 2701, 9324, 31382, 20833, 34407, 14076],\n",
       " [27890, 6731, 13006, 6731, 27393, 65414, 29916, 25870],\n",
       " [41266, 10908, 54894, 46938, 32904, 52426],\n",
       " [55991, 56185, 53049, 18295, 4954, 50720, 16963, 53381, 49670],\n",
       " [55574,\n",
       "  20787,\n",
       "  39549,\n",
       "  38746,\n",
       "  9775,\n",
       "  46985,\n",
       "  31768,\n",
       "  25788,\n",
       "  51022,\n",
       "  63179,\n",
       "  29138,\n",
       "  8232,\n",
       "  3688,\n",
       "  15960,\n",
       "  39877,\n",
       "  18773,\n",
       "  60736,\n",
       "  14973],\n",
       " [48111, 17427, 61563, 68931, 5003, 21856, 65668],\n",
       " [9995, 14776, 18697, 19641, 56780, 58636, 51273, 63929, 67519, 14363],\n",
       " [21881, 47029, 58636, 65725, 47486, 51293],\n",
       " [9866,\n",
       "  27019,\n",
       "  43522,\n",
       "  63435,\n",
       "  67480,\n",
       "  39549,\n",
       "  46846,\n",
       "  40770,\n",
       "  30473,\n",
       "  1290,\n",
       "  9500,\n",
       "  39800,\n",
       "  61733,\n",
       "  34332,\n",
       "  52141,\n",
       "  20447,\n",
       "  47199,\n",
       "  40756,\n",
       "  46846,\n",
       "  44775,\n",
       "  9013,\n",
       "  67486,\n",
       "  20787,\n",
       "  45486,\n",
       "  47545,\n",
       "  33691,\n",
       "  44775,\n",
       "  8715,\n",
       "  63906],\n",
       " [15956, 46168, 65414, 52411, 33478, 30723],\n",
       " ...]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_repr=[one_hot(words,vocab_size)for words in Train_Data.Msg_without_Stopwords] \n",
    "onehot_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  914 16033 62443 ...     0     0     0]\n",
      " [44374   975 62756 ...     0     0     0]\n",
      " [12370 53381 42754 ...     0     0     0]\n",
      " ...\n",
      " [44208 38479 64864 ...     0     0     0]\n",
      " [68625 68030 26008 ...     0     0     0]\n",
      " [67213 17890 47931 ...     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "embedded_docs=pad_sequences(onehot_repr,padding='post',maxlen=195)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35656, 195), (35656, 5))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_docs.shape, y_train1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3962"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_repr1=[one_hot(words,vocab_size)for words in Dev_Data.Msg_without_Stopwords] \n",
    "len(onehot_repr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3962"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_docs_dev=pad_sequences(onehot_repr1,padding='post',maxlen=195)\n",
    "len(embedded_docs_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_final=np.array(embedded_docs)\n",
    "y_final=np.array(y_train1)\n",
    "\n",
    "x_dev_final=np.array(embedded_docs_dev)\n",
    "y_dev_final=np.array(y_dev1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3962"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_dev_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35656, 195), (35656, 5), (3962, 195), (3962, 5))"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.shape, y_final.shape, x_dev_final.shape, y_dev_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot convert a symbolic Tensor (bidirectional/forward_lstm/strided_slice:0) to a numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-211-4f14f5bfd84f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaxPool1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m ])\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, layers, name)\u001b[0m\n\u001b[0;32m    112\u001b[0m       \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    194\u001b[0m       \u001b[1;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\wrappers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# Applies the same workaround as in `RNN.__call__`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    840\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[0;32m    841\u001b[0m                   \u001b[1;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 842\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    843\u001b[0m                     \u001b[1;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m                     \u001b[1;31m# circular dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\wrappers.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask, initial_state, constants)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m       y = self.forward_layer(forward_inputs,\n\u001b[1;32m--> 642\u001b[1;33m                              initial_state=forward_state, **kwargs)\n\u001b[0m\u001b[0;32m    643\u001b[0m       y_rev = self.backward_layer(backward_inputs,\n\u001b[0;32m    644\u001b[0m                                   initial_state=backward_state, **kwargs)\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 623\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    840\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[0;32m    841\u001b[0m                   \u001b[1;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 842\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    843\u001b[0m                     \u001b[1;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m                     \u001b[1;31m# circular dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m   2547\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_recurrent_dropout_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2548\u001b[0m     return super(LSTM, self).call(\n\u001b[1;32m-> 2549\u001b[1;33m         inputs, mask=mask, training=training, initial_state=initial_state)\n\u001b[0m\u001b[0;32m   2550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2551\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state, constants)\u001b[0m\n\u001b[0;32m    680\u001b[0m            constants=None):\n\u001b[0;32m    681\u001b[0m     inputs, initial_state, constants = self._process_inputs(\n\u001b[1;32m--> 682\u001b[1;33m         inputs, initial_state, constants)\n\u001b[0m\u001b[0;32m    683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(self, inputs, initial_state, constants)\u001b[0m\n\u001b[0;32m    796\u001b[0m       \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 798\u001b[1;33m       \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_initial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mget_initial_state_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m       init_state = get_initial_state_fn(\n\u001b[1;32m--> 606\u001b[1;33m           inputs=None, batch_size=batch_size, dtype=dtype)\n\u001b[0m\u001b[0;32m    607\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m       init_state = _generate_zero_filled_state(batch_size, self.cell.state_size,\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[1;34m(self, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   2312\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_initial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2313\u001b[0m     return list(_generate_zero_filled_state_for_cell(\n\u001b[1;32m-> 2314\u001b[1;33m         self, inputs, batch_size, dtype))\n\u001b[0m\u001b[0;32m   2315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_generate_zero_filled_state_for_cell\u001b[1;34m(cell, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   2750\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2751\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2752\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_generate_zero_filled_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2753\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_generate_zero_filled_state\u001b[1;34m(batch_size_tensor, state_size, dtype)\u001b[0m\n\u001b[0;32m   2766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2767\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2768\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_zeros\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2769\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2770\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_zeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 535\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 535\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mcreate_zeros\u001b[1;34m(unnested_state_size)\u001b[0m\n\u001b[0;32m   2763\u001b[0m     \u001b[0mflat_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munnested_state_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2764\u001b[0m     \u001b[0minit_state_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_size_tensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mflat_dims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2765\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_state_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2767\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mzeros\u001b[1;34m(shape, dtype, name)\u001b[0m\n\u001b[0;32m   2347\u001b[0m         \u001b[1;31m# Create a constant if it won't be very big. Otherwise create a fill op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2348\u001b[0m         \u001b[1;31m# to prevent serialized GraphDefs from becoming too large.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2349\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzero\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2350\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2351\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_constant_if_small\u001b[1;34m(value, shape, dtype, name)\u001b[0m\n\u001b[0;32m   2304\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2305\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2306\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2307\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2308\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   3050\u001b[0m     \"\"\"\n\u001b[0;32m   3051\u001b[0m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[1;32m-> 3052\u001b[1;33m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[0;32m   3053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    734\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m     raise NotImplementedError(\"Cannot convert a symbolic Tensor ({}) to a numpy\"\n\u001b[1;32m--> 736\u001b[1;33m                               \" array.\".format(self.name))\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Cannot convert a symbolic Tensor (bidirectional/forward_lstm/strided_slice:0) to a numpy array."
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.layers import Dropout, Dense, Embedding, LSTM, Bidirectional\n",
    "model_CNN1 = keras.Sequential([\n",
    "    keras.layers.Embedding(vocab_size, 50, input_length=max_length),\n",
    "   # keras.layers.GlobalAveragePooling1D(),\n",
    "    # convolutional filters=128,  kernel size=3: it means length_long_sentence size of 65 we are luking for 3 words at a time\n",
    "    keras.layers.Conv1D(756, 7, activation='relu'),\n",
    "    keras.layers.Conv1D(756, 7, activation='relu'),\n",
    "    keras.layers.MaxPool1D(),\n",
    "    keras.layers.Conv1D(256, 3, activation='relu'),\n",
    "    keras.layers.Conv1D(256, 3, activation='relu'),\n",
    "    keras.layers.MaxPool1D(),\n",
    "    keras.layers.Bidirectional(LSTM(400)),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model_CNN1.compile(loss='sparse_categorical_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "model_CNN1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CNN1.fit(X_final,y_final,epochs=10,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 195, 40)           1609200   \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 200)               112800    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 1005      \n",
      "=================================================================\n",
      "Total params: 1,723,005\n",
      "Trainable params: 1,723,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vector_features=40\n",
    "model1=Sequential()\n",
    "model1.add(Embedding(vocab_size,embedding_vector_features,input_length=195))\n",
    "model1.add(Bidirectional(LSTM(100)))\n",
    "model1.add(Dropout(0.3))\n",
    "model1.add(Dense(5,activation='sigmoid'))\n",
    "model1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15888 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000277F4F64EE8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000277F4F64EE8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "15888/15888 [==============================] - 2813s 177ms/sample - loss: 0.4279 - accuracy: 0.8112\n",
      "Epoch 2/10\n",
      "15888/15888 [==============================] - 1174s 74ms/sample - loss: 0.2807 - accuracy: 0.8847\n",
      "Epoch 3/10\n",
      "15888/15888 [==============================] - 1182s 74ms/sample - loss: 0.1715 - accuracy: 0.9341\n",
      "Epoch 4/10\n",
      "15888/15888 [==============================] - 2292s 144ms/sample - loss: 0.1099 - accuracy: 0.9619\n",
      "Epoch 5/10\n",
      "15888/15888 [==============================] - 1207s 76ms/sample - loss: 0.0656 - accuracy: 0.9788\n",
      "Epoch 6/10\n",
      "15888/15888 [==============================] - 1194s 75ms/sample - loss: 0.0479 - accuracy: 0.9850\n",
      "Epoch 7/10\n",
      "15888/15888 [==============================] - 1190s 75ms/sample - loss: 0.0377 - accuracy: 0.9888\n",
      "Epoch 8/10\n",
      "15888/15888 [==============================] - 812s 51ms/sample - loss: 0.0311 - accuracy: 0.9900\n",
      "Epoch 9/10\n",
      "15888/15888 [==============================] - 803s 51ms/sample - loss: 0.0261 - accuracy: 0.9917\n",
      "Epoch 10/10\n",
      "15888/15888 [==============================] - 807s 51ms/sample - loss: 0.0231 - accuracy: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x277f4faef08>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_final,y_final,epochs=10,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.557204\n",
      "Loss: 55.181224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.37      0.35       102\n",
      "           1       0.64      0.43      0.51       237\n",
      "           2       0.69      0.74      0.71       706\n",
      "           3       0.71      0.68      0.69       141\n",
      "           4       0.65      0.67      0.66       580\n",
      "\n",
      "    accuracy                           0.65      1766\n",
      "   macro avg       0.60      0.58      0.59      1766\n",
      "weighted avg       0.65      0.65      0.65      1766\n",
      "\n",
      "Cohen Score:  0.495450229923202\n"
     ]
    }
   ],
   "source": [
    "emoji(y_dev_final, x_dev_final, model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15888, 195), (15888, 5), (1766, 5), (1766, 195))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_padded_sentences.shape, y_train1.shape, y_dev1.shape, Dev_padded_sentences.shape"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP8geQdUqy6mvn4zRsyX2jU",
   "collapsed_sections": [],
   "name": "Malayalam 3 Offensive ML.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
